Output files are saved in results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a
Old observation space Box(-inf, inf, (4,), float64)
Old action space Box(-1.0, 1.0, (1,), float32)
Observation space: Box(-inf, inf, (5,), float64)
Action space: Box(-1.0, 1.0, (1,), float32)
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1000 episode:171 last_R: -0.06148386001586914 average_R:-0.11663674354553223
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', nan), ('average_q2', nan), ('average_q_func1_loss', nan), ('average_q_func2_loss', nan), ('n_updates', 0), ('average_entropy', nan), ('temperature', 1.0)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:2000 episode:350 last_R: 0.14307928085327148 average_R:-0.054407639503479
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', nan), ('average_q2', nan), ('average_q_func1_loss', nan), ('average_q_func2_loss', nan), ('n_updates', 0), ('average_entropy', nan), ('temperature', 1.0)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:3000 episode:531 last_R: 0.03488945960998535 average_R:-0.05838304042816162
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', nan), ('average_q2', nan), ('average_q_func1_loss', nan), ('average_q_func2_loss', nan), ('n_updates', 0), ('average_entropy', nan), ('temperature', 1.0)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:4000 episode:709 last_R: -0.001795053482055664 average_R:-0.09403178453445435
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', nan), ('average_q2', nan), ('average_q_func1_loss', nan), ('average_q_func2_loss', nan), ('n_updates', 0), ('average_entropy', nan), ('temperature', 1.0)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:5000 episode:888 last_R: -0.3122572898864746 average_R:-0.027133069038391112
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', nan), ('average_q2', nan), ('average_q_func1_loss', nan), ('average_q_func2_loss', nan), ('n_updates', 0), ('average_entropy', nan), ('temperature', 1.0)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:6000 episode:1067 last_R: -0.327728271484375 average_R:-0.019394285678863525
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', nan), ('average_q2', nan), ('average_q_func1_loss', nan), ('average_q_func2_loss', nan), ('n_updates', 0), ('average_entropy', nan), ('temperature', 1.0)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:7000 episode:1241 last_R: 0.12296748161315918 average_R:-0.035543015003204344
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', nan), ('average_q2', nan), ('average_q_func1_loss', nan), ('average_q_func2_loss', nan), ('n_updates', 0), ('average_entropy', nan), ('temperature', 1.0)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:8000 episode:1411 last_R: 0.39423394203186035 average_R:-0.0036809492111206056
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', nan), ('average_q2', nan), ('average_q_func1_loss', nan), ('average_q_func2_loss', nan), ('n_updates', 0), ('average_entropy', nan), ('temperature', 1.0)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:9000 episode:1593 last_R: 0.11065912246704102 average_R:0.013304104804992676
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', nan), ('average_q2', nan), ('average_q_func1_loss', nan), ('average_q_func2_loss', nan), ('n_updates', 0), ('average_entropy', nan), ('temperature', 1.0)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:10000 episode:1770 last_R: -0.16351556777954102 average_R:-0.044681429862976074
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', nan), ('average_q2', nan), ('average_q_func1_loss', nan), ('average_q_func2_loss', nan), ('n_updates', 0), ('average_entropy', nan), ('temperature', 1.0)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:11000 episode:1958 last_R: 0.023921489715576172 average_R:-0.012644896507263184
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.33550042), ('average_q2', 0.35306275), ('average_q_func1_loss', 0.08823783501982689), ('average_q_func2_loss', 0.0936135571449995), ('n_updates', 999), ('average_entropy', 0.676412), ('temperature', 0.7531384825706482)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:12000 episode:2123 last_R: 0.10848045349121094 average_R:0.004928596019744873
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.23263699), ('average_q2', 0.24788171), ('average_q_func1_loss', 0.05366480354219675), ('average_q_func2_loss', 0.056209121085703376), ('n_updates', 1999), ('average_entropy', 0.6664651), ('temperature', 0.5831409692764282)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:13000 episode:2279 last_R: 0.1535193920135498 average_R:-0.0402903962135315
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.19786166), ('average_q2', 0.20121507), ('average_q_func1_loss', 0.038716489151120186), ('average_q_func2_loss', 0.04023628450930119), ('n_updates', 2999), ('average_entropy', 0.67314005), ('temperature', 0.4583005905151367)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:14000 episode:2458 last_R: -0.15767669677734375 average_R:-0.008177857398986816
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.16476534), ('average_q2', 0.15866235), ('average_q_func1_loss', 0.02932411599904299), ('average_q_func2_loss', 0.030243335757404566), ('n_updates', 3999), ('average_entropy', 0.6741007), ('temperature', 0.36317968368530273)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:15000 episode:2606 last_R: -0.15968561172485352 average_R:-0.013970835208892822
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.120018125), ('average_q2', 0.11605503), ('average_q_func1_loss', 0.023482530359178782), ('average_q_func2_loss', 0.023861078079789877), ('n_updates', 4999), ('average_entropy', 0.67082644), ('temperature', 0.28913751244544983)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:16000 episode:2752 last_R: -0.042922019958496094 average_R:-2.543926239013672e-05
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.09706503), ('average_q2', 0.08572023), ('average_q_func1_loss', 0.02031516583636403), ('average_q_func2_loss', 0.020377632565796375), ('n_updates', 5999), ('average_entropy', 0.67765063), ('temperature', 0.23079364001750946)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:17000 episode:2893 last_R: 0.36063623428344727 average_R:-0.014279417991638184
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.06412746), ('average_q2', 0.067998715), ('average_q_func1_loss', 0.01787771111354232), ('average_q_func2_loss', 0.017856334950774908), ('n_updates', 6999), ('average_entropy', 0.66229135), ('temperature', 0.18445676565170288)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:18000 episode:3041 last_R: 0.5660820007324219 average_R:-0.003421330451965332
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.071691014), ('average_q2', 0.06802671), ('average_q_func1_loss', 0.016644286131486295), ('average_q_func2_loss', 0.016604601666331292), ('n_updates', 7999), ('average_entropy', 0.6565441), ('temperature', 0.14751844108104706)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:19000 episode:3182 last_R: 0.06252288818359375 average_R:-0.045850815773010256
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.050798625), ('average_q2', 0.05259607), ('average_q_func1_loss', 0.016461192145943642), ('average_q_func2_loss', 0.01647721080109477), ('n_updates', 8999), ('average_entropy', 0.6527984), ('temperature', 0.11802763491868973)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:20000 episode:3323 last_R: 0.06692266464233398 average_R:-0.018212831020355223
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.03649272), ('average_q2', 0.03542761), ('average_q_func1_loss', 0.014710616823285817), ('average_q_func2_loss', 0.014688728963956238), ('n_updates', 9999), ('average_entropy', 0.64396715), ('temperature', 0.0944480374455452)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:21000 episode:3459 last_R: 0.1474466323852539 average_R:-0.013831019401550293
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.04260168), ('average_q2', 0.04178178), ('average_q_func1_loss', 0.014283486548811198), ('average_q_func2_loss', 0.014292545663192869), ('n_updates', 10999), ('average_entropy', 0.64076716), ('temperature', 0.07558716833591461)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:22000 episode:3605 last_R: 0.29421472549438477 average_R:-0.016705305576324464
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.011648308), ('average_q2', 0.012595877), ('average_q_func1_loss', 0.013704673312604427), ('average_q_func2_loss', 0.013720345441251993), ('n_updates', 11999), ('average_entropy', 0.6514694), ('temperature', 0.06051180139183998)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:23000 episode:3726 last_R: 0.27454638481140137 average_R:-0.025177879333496092
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', -0.024160484), ('average_q2', -0.01924392), ('average_q_func1_loss', 0.013163688564673067), ('average_q_func2_loss', 0.013105647377669812), ('n_updates', 12999), ('average_entropy', 0.6160608), ('temperature', 0.04844918102025986)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:24000 episode:3858 last_R: -0.009882926940917969 average_R:0.013548457622528076
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.015700992), ('average_q2', 0.011099506), ('average_q_func1_loss', 0.01246244104579091), ('average_q_func2_loss', 0.012386563662439586), ('n_updates', 13999), ('average_entropy', 0.61700916), ('temperature', 0.038791898638010025)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:25000 episode:3989 last_R: -0.030803203582763672 average_R:-0.0048985123634338375
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', -0.0065438165), ('average_q2', -0.010199624), ('average_q_func1_loss', 0.012052490329369902), ('average_q_func2_loss', 0.012018420873209834), ('n_updates', 14999), ('average_entropy', 0.6123867), ('temperature', 0.031063970178365707)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 21 R: 21.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 21 R: 21.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 22 R: 22.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 22 R: 22.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 20 R: 20.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 21 R: 21.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 23 R: 23.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 19 R: 19.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 21 R: 21.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 20 R: 20.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 20 R: 20.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 20 R: 20.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 20 R: 20.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 20 R: 20.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 26 R: 26.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 18 R: 18.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 18 R: 18.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 21 R: 21.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 22 R: 22.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 21 R: 21.0
INFO:diayn_sim:true z: tensor([14, 14, 14, 14], device='cuda:0')
INFO:diayn_sim:disc z: tensor([35, 34, 48, 13])
INFO:diayn_sim:disc loss: 3.879256248474121
INFO:diayn_sim:top extrinsic: [41. 26. 38. 39.]
INFO:diayn_sim:last intrinsic: [-0.01007867  0.05299687  0.03889322  0.0490551 ]
INFO:pfrl.experiments.train_agent_batch:The best score is updated -3.4028235e+38 -> 20.8
INFO:pfrl.experiments.train_agent_batch:Saved the agent to results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a/best
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:26000 episode:4102 last_R: -0.29376864433288574 average_R:-0.043591518402099606
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', -0.01585882), ('average_q2', -0.014874176), ('average_q_func1_loss', 0.011959695219993592), ('average_q_func2_loss', 0.011948903305456043), ('n_updates', 15999), ('average_entropy', 0.6038207), ('temperature', 0.02487889677286148)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:27000 episode:4226 last_R: -0.01906561851501465 average_R:0.001845874786376953
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', -0.019842215), ('average_q2', -0.031002918), ('average_q_func1_loss', 0.012126839021220803), ('average_q_func2_loss', 0.012115760752931238), ('n_updates', 16999), ('average_entropy', 0.60472804), ('temperature', 0.01991928555071354)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:28000 episode:4349 last_R: 0.5857911109924316 average_R:-0.03404548645019531
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.0014479395), ('average_q2', -0.0018321059), ('average_q_func1_loss', 0.011794100478291512), ('average_q_func2_loss', 0.011756335450336337), ('n_updates', 17999), ('average_entropy', 0.6158584), ('temperature', 0.015936989337205887)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:29000 episode:4478 last_R: 0.3571310043334961 average_R:0.04226924180984497
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', -0.0033587145), ('average_q2', -0.0063468283), ('average_q_func1_loss', 0.011920362142845989), ('average_q_func2_loss', 0.01187256901524961), ('n_updates', 18999), ('average_entropy', 0.581997), ('temperature', 0.012755471281707287)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:30000 episode:4593 last_R: -0.2503354549407959 average_R:-0.04195457220077515
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', -0.014220073), ('average_q2', -0.018732762), ('average_q_func1_loss', 0.012146922312676906), ('average_q_func2_loss', 0.012102054674178362), ('n_updates', 19999), ('average_entropy', 0.5865587), ('temperature', 0.010209818370640278)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:31000 episode:4705 last_R: 0.2904782295227051 average_R:0.00592726469039917
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', -0.015960103), ('average_q2', -0.016682766), ('average_q_func1_loss', 0.011368657639250159), ('average_q_func2_loss', 0.01133404157590121), ('n_updates', 20999), ('average_entropy', 0.5760433), ('temperature', 0.008177141658961773)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:32000 episode:4840 last_R: -0.04714632034301758 average_R:0.015456995964050292
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', -0.016725814), ('average_q2', -0.012685625), ('average_q_func1_loss', 0.011641028970479965), ('average_q_func2_loss', 0.011679332787171006), ('n_updates', 21999), ('average_entropy', 0.54176784), ('temperature', 0.006552061531692743)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:33000 episode:4952 last_R: 0.10875916481018066 average_R:0.017565910816192628
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', -0.0135491155), ('average_q2', -0.010582395), ('average_q_func1_loss', 0.01172914552502334), ('average_q_func2_loss', 0.011691114781424403), ('n_updates', 22999), ('average_entropy', 0.4904189), ('temperature', 0.005270074121654034)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:34000 episode:5091 last_R: -0.29787707328796387 average_R:0.06350412130355836
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', -0.033942867), ('average_q2', -0.028404659), ('average_q_func1_loss', 0.011995653407648205), ('average_q_func2_loss', 0.011999333323910833), ('n_updates', 23999), ('average_entropy', 0.4684948), ('temperature', 0.004242768976837397)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:35000 episode:5250 last_R: -0.1578218936920166 average_R:0.10877223014831543
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', -0.023334106), ('average_q2', -0.023596982), ('average_q_func1_loss', 0.01249468520283699), ('average_q_func2_loss', 0.01245265464298427), ('n_updates', 24999), ('average_entropy', 0.38978016), ('temperature', 0.0034419710282236338)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:36000 episode:5443 last_R: 0.1259012222290039 average_R:0.255292067527771
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', -0.026119556), ('average_q2', -0.020592561), ('average_q_func1_loss', 0.013162361308932304), ('average_q_func2_loss', 0.013081012349575758), ('n_updates', 25999), ('average_entropy', 0.16942887), ('temperature', 0.002815806306898594)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:37000 episode:5679 last_R: 1.2962255477905273 average_R:0.5294905686378479
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', -0.005063838), ('average_q2', -0.001353346), ('average_q_func1_loss', 0.01535947997123003), ('average_q_func2_loss', 0.015361744835972786), ('n_updates', 26999), ('average_entropy', -0.3771665), ('temperature', 0.002410565037280321)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:38000 episode:5948 last_R: 0.6302323341369629 average_R:0.7805909061431885
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.048993804), ('average_q2', 0.05143611), ('average_q_func1_loss', 0.01970920629799366), ('average_q_func2_loss', 0.019623796911910175), ('n_updates', 27999), ('average_entropy', -0.8216548), ('temperature', 0.0022263170685619116)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:39000 episode:6229 last_R: 0.6035826206207275 average_R:1.0247389364242554
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.06285343), ('average_q2', 0.07003237), ('average_q_func1_loss', 0.02665262809023261), ('average_q_func2_loss', 0.026541376048699022), ('n_updates', 28999), ('average_entropy', -1.239323), ('temperature', 0.002231371821835637)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:40000 episode:6515 last_R: 0.9680595397949219 average_R:1.106915864944458
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.08571567), ('average_q2', 0.07885208), ('average_q_func1_loss', 0.03584296911023557), ('average_q_func2_loss', 0.03582056855782866), ('n_updates', 29999), ('average_entropy', -1.3094312), ('temperature', 0.0026205594185739756)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:41000 episode:6810 last_R: 1.2448432445526123 average_R:1.0479804706573486
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.13405968), ('average_q2', 0.13435026), ('average_q_func1_loss', 0.04210644613951445), ('average_q_func2_loss', 0.0421080950088799), ('n_updates', 30999), ('average_entropy', -1.4277756), ('temperature', 0.003477094927802682)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:42000 episode:7099 last_R: 5.101759433746338 average_R:1.1835179090499879
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.13284208), ('average_q2', 0.14446649), ('average_q_func1_loss', 0.05165531922131777), ('average_q_func2_loss', 0.05186006881296635), ('n_updates', 31999), ('average_entropy', -1.2809073), ('temperature', 0.004906157962977886)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:43000 episode:7389 last_R: 1.3175263404846191 average_R:1.4286426949501037
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.16828287), ('average_q2', 0.16482145), ('average_q_func1_loss', 0.060140350610017775), ('average_q_func2_loss', 0.060505653768777846), ('n_updates', 32999), ('average_entropy', -1.1826994), ('temperature', 0.0067339190281927586)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:44000 episode:7676 last_R: 2.9728264808654785 average_R:1.459640588760376
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.21873447), ('average_q2', 0.21667264), ('average_q_func1_loss', 0.06790988497436047), ('average_q_func2_loss', 0.06845679428428411), ('n_updates', 33999), ('average_entropy', -1.063504), ('temperature', 0.008632167242467403)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:45000 episode:7964 last_R: 0.6659564971923828 average_R:1.5141301321983338
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.20787005), ('average_q2', 0.22323824), ('average_q_func1_loss', 0.07479932006448507), ('average_q_func2_loss', 0.07564542382955551), ('n_updates', 34999), ('average_entropy', -1.144198), ('temperature', 0.010549862869083881)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:46000 episode:8237 last_R: -0.11908125877380371 average_R:1.6123442506790162
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.29778507), ('average_q2', 0.2874785), ('average_q_func1_loss', 0.08578395549207926), ('average_q_func2_loss', 0.08652669783681631), ('n_updates', 35999), ('average_entropy', -0.9173627), ('temperature', 0.012263020500540733)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:47000 episode:8506 last_R: 0.708369255065918 average_R:1.5892537331581116
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.32208648), ('average_q2', 0.31086186), ('average_q_func1_loss', 0.09208272684365511), ('average_q_func2_loss', 0.09295745797455311), ('n_updates', 36999), ('average_entropy', -0.9319878), ('temperature', 0.013767746277153492)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:48000 episode:8782 last_R: 1.3024704456329346 average_R:1.5635880208015442
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.3041776), ('average_q2', 0.3152955), ('average_q_func1_loss', 0.10219857648015022), ('average_q_func2_loss', 0.10343988925218582), ('n_updates', 37999), ('average_entropy', -1.0587151), ('temperature', 0.01528608426451683)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:49000 episode:9043 last_R: 4.012959241867065 average_R:1.7130029249191283
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.37887776), ('average_q2', 0.38026184), ('average_q_func1_loss', 0.10767245389521123), ('average_q_func2_loss', 0.10892462573945522), ('n_updates', 38999), ('average_entropy', -0.979905), ('temperature', 0.016991423442959785)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:50000 episode:9304 last_R: 1.5996034145355225 average_R:1.7097723436355592
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.42499283), ('average_q2', 0.42312083), ('average_q_func1_loss', 0.12170492358505726), ('average_q_func2_loss', 0.12342380397021771), ('n_updates', 39999), ('average_entropy', -1.0751319), ('temperature', 0.018581798300147057)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 10 R: 10.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 7 R: 7.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 2 R: 2.0
INFO:diayn_sim:true z: tensor([42, 42, 42,  9], device='cuda:0')
INFO:diayn_sim:disc z: tensor([40, 47, 45,  7])
INFO:diayn_sim:disc loss: 3.231231451034546
INFO:diayn_sim:top extrinsic: [10. 21. 26. 48.]
INFO:diayn_sim:last intrinsic: [0.57373023 0.64164066 0.5382061  0.96938896]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:51000 episode:9548 last_R: 1.0841474533081055 average_R:1.9004970073699952
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.44250414), ('average_q2', 0.430256), ('average_q_func1_loss', 0.12402708031237125), ('average_q_func2_loss', 0.125769846662879), ('n_updates', 40999), ('average_entropy', -0.94119), ('temperature', 0.020173976197838783)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:52000 episode:9794 last_R: -0.03970479965209961 average_R:1.9328861904144288
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.4013967), ('average_q2', 0.399597), ('average_q_func1_loss', 0.13438419692218304), ('average_q_func2_loss', 0.13646395787596702), ('n_updates', 41999), ('average_entropy', -1.0274372), ('temperature', 0.021876508370041847)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:53000 episode:10044 last_R: 1.7995414733886719 average_R:1.937151563167572
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.48125577), ('average_q2', 0.49125743), ('average_q_func1_loss', 0.14423727847635745), ('average_q_func2_loss', 0.1461658167093992), ('n_updates', 42999), ('average_entropy', -0.9266921), ('temperature', 0.023563262075185776)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:54000 episode:10294 last_R: 2.5780091285705566 average_R:1.9824660086631776
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.46767828), ('average_q2', 0.47380823), ('average_q_func1_loss', 0.14703264452517031), ('average_q_func2_loss', 0.14885940797626973), ('n_updates', 43999), ('average_entropy', -1.034835), ('temperature', 0.025029951706528664)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:55000 episode:10534 last_R: 1.3252043724060059 average_R:1.9588889765739441
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.5433884), ('average_q2', 0.5413681), ('average_q_func1_loss', 0.15990413047373295), ('average_q_func2_loss', 0.1620354722440243), ('n_updates', 44999), ('average_entropy', -0.99686646), ('temperature', 0.026546481996774673)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:56000 episode:10774 last_R: 1.385796308517456 average_R:1.8264434456825256
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.47165525), ('average_q2', 0.4798216), ('average_q_func1_loss', 0.1675216057896614), ('average_q_func2_loss', 0.1696658881008625), ('n_updates', 45999), ('average_entropy', -0.99851114), ('temperature', 0.028217904269695282)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:57000 episode:11013 last_R: 1.9148073196411133 average_R:1.95075980424881
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.5622994), ('average_q2', 0.5421111), ('average_q_func1_loss', 0.1696912617981434), ('average_q_func2_loss', 0.17149110220372676), ('n_updates', 46999), ('average_entropy', -1.0342679), ('temperature', 0.02974938228726387)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:58000 episode:11245 last_R: 1.0305678844451904 average_R:1.968814673423767
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.61882913), ('average_q2', 0.6248983), ('average_q_func1_loss', 0.1842194088548422), ('average_q_func2_loss', 0.18595860674977302), ('n_updates', 47999), ('average_entropy', -1.0355173), ('temperature', 0.03097808174788952)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:59000 episode:11483 last_R: 1.113100528717041 average_R:1.8912737798690795
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.6161005), ('average_q2', 0.62700635), ('average_q_func1_loss', 0.18474139288067817), ('average_q_func2_loss', 0.18611726701259612), ('n_updates', 48999), ('average_entropy', -0.94339454), ('temperature', 0.0327938087284565)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:60000 episode:11701 last_R: 2.475209951400757 average_R:2.061211574077606
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.6188646), ('average_q2', 0.6198309), ('average_q_func1_loss', 0.19309907734394074), ('average_q_func2_loss', 0.1944562740623951), ('n_updates', 49999), ('average_entropy', -1.0883772), ('temperature', 0.03413521870970726)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:61000 episode:11928 last_R: 1.3678436279296875 average_R:1.9754067492485046
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.61583424), ('average_q2', 0.6078788), ('average_q_func1_loss', 0.2018014533817768), ('average_q_func2_loss', 0.20351437449455262), ('n_updates', 50999), ('average_entropy', -1.0409973), ('temperature', 0.035149481147527695)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:62000 episode:12157 last_R: 6.896340847015381 average_R:2.2083748817443847
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.66482687), ('average_q2', 0.6778949), ('average_q_func1_loss', 0.20680829539895057), ('average_q_func2_loss', 0.20834497943520547), ('n_updates', 51999), ('average_entropy', -0.97338), ('temperature', 0.036491625010967255)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:63000 episode:12375 last_R: 0.17709970474243164 average_R:2.1164294981956484
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.63258266), ('average_q2', 0.63302237), ('average_q_func1_loss', 0.2201046033203602), ('average_q_func2_loss', 0.22117717772722245), ('n_updates', 52999), ('average_entropy', -0.96647805), ('temperature', 0.037749744951725006)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:64000 episode:12605 last_R: 1.726891279220581 average_R:2.1508738875389097
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.6328529), ('average_q2', 0.64277697), ('average_q_func1_loss', 0.2201013845205307), ('average_q_func2_loss', 0.22212202101945877), ('n_updates', 53999), ('average_entropy', -0.97488284), ('temperature', 0.03898123279213905)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:65000 episode:12823 last_R: 2.7333364486694336 average_R:2.119850904941559
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.72138405), ('average_q2', 0.7076961), ('average_q_func1_loss', 0.22735756009817124), ('average_q_func2_loss', 0.22895085141062738), ('n_updates', 54999), ('average_entropy', -0.9850838), ('temperature', 0.03958102688193321)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:66000 episode:13041 last_R: 2.9852447509765625 average_R:2.499632520675659
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.730191), ('average_q2', 0.76622623), ('average_q_func1_loss', 0.23145019739866257), ('average_q_func2_loss', 0.23335028931498528), ('n_updates', 55999), ('average_entropy', -1.0174459), ('temperature', 0.040770646184682846)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:67000 episode:13257 last_R: 1.0903077125549316 average_R:2.405540051460266
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.7565324), ('average_q2', 0.75475156), ('average_q_func1_loss', 0.23847146734595298), ('average_q_func2_loss', 0.24000143259763718), ('n_updates', 56999), ('average_entropy', -1.0072579), ('temperature', 0.041742533445358276)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:68000 episode:13476 last_R: 4.900867700576782 average_R:2.170054838657379
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.7742649), ('average_q2', 0.788369), ('average_q_func1_loss', 0.2392999641597271), ('average_q_func2_loss', 0.2411094120144844), ('n_updates', 57999), ('average_entropy', -0.94666797), ('temperature', 0.04295721650123596)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:69000 episode:13689 last_R: 1.0002598762512207 average_R:2.4413429164886473
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.7595824), ('average_q2', 0.7662048), ('average_q_func1_loss', 0.24792566195130347), ('average_q_func2_loss', 0.24980500102043152), ('n_updates', 58999), ('average_entropy', -1.0446564), ('temperature', 0.04418924078345299)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:70000 episode:13913 last_R: 1.9667487144470215 average_R:2.3213615727424624
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.7716067), ('average_q2', 0.78808385), ('average_q_func1_loss', 0.2521273718774319), ('average_q_func2_loss', 0.25407049104571344), ('n_updates', 59999), ('average_entropy', -1.0428941), ('temperature', 0.04504510760307312)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:71000 episode:14125 last_R: 0.9206554889678955 average_R:2.388527555465698
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.7597928), ('average_q2', 0.76837784), ('average_q_func1_loss', 0.2646717083454132), ('average_q_func2_loss', 0.26666921824216844), ('n_updates', 60999), ('average_entropy', -1.0151347), ('temperature', 0.04662461578845978)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:72000 episode:14333 last_R: 2.224500894546509 average_R:2.365214865207672
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.8104596), ('average_q2', 0.82160586), ('average_q_func1_loss', 0.2702619010210037), ('average_q_func2_loss', 0.2722154857218266), ('n_updates', 61999), ('average_entropy', -1.0260626), ('temperature', 0.047764576971530914)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:73000 episode:14555 last_R: 1.337003231048584 average_R:2.6179580020904543
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.8512104), ('average_q2', 0.8589659), ('average_q_func1_loss', 0.26839336976408956), ('average_q_func2_loss', 0.2701405890285969), ('n_updates', 62999), ('average_entropy', -1.0669669), ('temperature', 0.048469968140125275)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:74000 episode:14762 last_R: 2.0198028087615967 average_R:2.5711866664886474
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.83484364), ('average_q2', 0.8453766), ('average_q_func1_loss', 0.2781510974466801), ('average_q_func2_loss', 0.27997367322444916), ('n_updates', 63999), ('average_entropy', -0.98571265), ('temperature', 0.049877364188432693)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:75000 episode:14967 last_R: 2.1899142265319824 average_R:2.5730571699142457
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.9163755), ('average_q2', 0.91798174), ('average_q_func1_loss', 0.2834384939074516), ('average_q_func2_loss', 0.2858078965544701), ('n_updates', 64999), ('average_entropy', -1.0485456), ('temperature', 0.05095582827925682)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 6 R: 6.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 6 R: 6.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 3 R: 3.0
INFO:diayn_sim:true z: tensor([17, 17,  5, 39], device='cuda:0')
INFO:diayn_sim:disc z: tensor([26, 23, 11, 46])
INFO:diayn_sim:disc loss: 3.2017805576324463
INFO:diayn_sim:top extrinsic: [10. 21.  8. 15.]
INFO:diayn_sim:last intrinsic: [0.75261354 0.62019897 0.8996177  0.56834054]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:76000 episode:15176 last_R: 1.8361482620239258 average_R:2.4931758999824525
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.9121312), ('average_q2', 0.9151317), ('average_q_func1_loss', 0.2797750608623028), ('average_q_func2_loss', 0.2823948785662651), ('n_updates', 65999), ('average_entropy', -0.9686519), ('temperature', 0.05214548483490944)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:77000 episode:15387 last_R: 1.8459343910217285 average_R:2.497038996219635
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.89846486), ('average_q2', 0.89706105), ('average_q_func1_loss', 0.2874005605280399), ('average_q_func2_loss', 0.28939892545342444), ('n_updates', 66999), ('average_entropy', -0.8803544), ('temperature', 0.05396765470504761)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:78000 episode:15594 last_R: 3.8281829357147217 average_R:2.484967842102051
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.9245873), ('average_q2', 0.9325348), ('average_q_func1_loss', 0.299224328994751), ('average_q_func2_loss', 0.30306818425655363), ('n_updates', 67999), ('average_entropy', -1.0060523), ('temperature', 0.05496211349964142)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:79000 episode:15797 last_R: 3.878657341003418 average_R:2.719926450252533
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.9833848), ('average_q2', 0.99981415), ('average_q_func1_loss', 0.3036770749092102), ('average_q_func2_loss', 0.30722591653466225), ('n_updates', 68999), ('average_entropy', -1.0448056), ('temperature', 0.056140512228012085)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:80000 episode:16004 last_R: 3.1587698459625244 average_R:2.577612867355347
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.0072114), ('average_q2', 1.0162688), ('average_q_func1_loss', 0.31006651639938354), ('average_q_func2_loss', 0.31144944682717324), ('n_updates', 69999), ('average_entropy', -0.95978713), ('temperature', 0.05685238167643547)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:81000 episode:16201 last_R: 0.5742311477661133 average_R:2.970944368839264
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.9990566), ('average_q2', 1.0164776), ('average_q_func1_loss', 0.3148780778050423), ('average_q_func2_loss', 0.31713846534490586), ('n_updates', 70999), ('average_entropy', -0.9972043), ('temperature', 0.05780397355556488)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:82000 episode:16416 last_R: 1.4595434665679932 average_R:2.4208158683776855
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.0082302), ('average_q2', 1.0070707), ('average_q_func1_loss', 0.3240197342634201), ('average_q_func2_loss', 0.327229879796505), ('n_updates', 71999), ('average_entropy', -1.0336568), ('temperature', 0.059841834008693695)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:83000 episode:16605 last_R: 2.9229800701141357 average_R:2.831539568901062
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.0685608), ('average_q2', 1.0569488), ('average_q_func1_loss', 0.32360815033316614), ('average_q_func2_loss', 0.3257004417479038), ('n_updates', 72999), ('average_entropy', -0.9813047), ('temperature', 0.06027495488524437)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:84000 episode:16811 last_R: 1.6483242511749268 average_R:2.4438626742362977
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 0.9921168), ('average_q2', 1.0088855), ('average_q_func1_loss', 0.3214217394590378), ('average_q_func2_loss', 0.32312870636582375), ('n_updates', 73999), ('average_entropy', -0.95224106), ('temperature', 0.061509713530540466)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:85000 episode:17005 last_R: 1.9210939407348633 average_R:2.8271315836906434
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.0435148), ('average_q2', 1.0202097), ('average_q_func1_loss', 0.33795234233140947), ('average_q_func2_loss', 0.34017836809158325), ('n_updates', 74999), ('average_entropy', -1.0135757), ('temperature', 0.06231958419084549)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:86000 episode:17202 last_R: 3.464099407196045 average_R:2.883348479270935
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.0559425), ('average_q2', 1.0448166), ('average_q_func1_loss', 0.34472586154937745), ('average_q_func2_loss', 0.3473363751173019), ('n_updates', 75999), ('average_entropy', -1.0420773), ('temperature', 0.06333069503307343)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:87000 episode:17389 last_R: 2.1075751781463623 average_R:2.9791160678863524
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.0576929), ('average_q2', 1.0573183), ('average_q_func1_loss', 0.3458314236998558), ('average_q_func2_loss', 0.3486447417736053), ('n_updates', 76999), ('average_entropy', -1.0321902), ('temperature', 0.06484105437994003)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:88000 episode:17599 last_R: 0.21802735328674316 average_R:2.811366631984711
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.0564029), ('average_q2', 1.0484293), ('average_q_func1_loss', 0.3557398122549057), ('average_q_func2_loss', 0.3578105893731117), ('n_updates', 77999), ('average_entropy', -1.0181895), ('temperature', 0.06572380661964417)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:89000 episode:17803 last_R: 1.982412338256836 average_R:2.7243269443511964
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.091741), ('average_q2', 1.0792994), ('average_q_func1_loss', 0.35688517600297925), ('average_q_func2_loss', 0.3584946784377098), ('n_updates', 78999), ('average_entropy', -0.97665256), ('temperature', 0.06647007167339325)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:90000 episode:17999 last_R: 2.1876847743988037 average_R:2.873598234653473
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.1195943), ('average_q2', 1.0897201), ('average_q_func1_loss', 0.35276215732097627), ('average_q_func2_loss', 0.3543061278760433), ('n_updates', 79999), ('average_entropy', -1.1282398), ('temperature', 0.06809481978416443)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:91000 episode:18188 last_R: 2.1779212951660156 average_R:3.0844063782691955
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.0971917), ('average_q2', 1.1194307), ('average_q_func1_loss', 0.3618103611469269), ('average_q_func2_loss', 0.3643386885523796), ('n_updates', 80999), ('average_entropy', -0.95409995), ('temperature', 0.06854227185249329)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:92000 episode:18382 last_R: 0.5497722625732422 average_R:2.8613452196121214
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.2132531), ('average_q2', 1.2124908), ('average_q_func1_loss', 0.3679573023319244), ('average_q_func2_loss', 0.3705398815870285), ('n_updates', 81999), ('average_entropy', -0.98926526), ('temperature', 0.06879400461912155)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:93000 episode:18577 last_R: 1.7117891311645508 average_R:3.1645897889137267
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.0995798), ('average_q2', 1.1119976), ('average_q_func1_loss', 0.3761537861824036), ('average_q_func2_loss', 0.3775795811414719), ('n_updates', 82999), ('average_entropy', -0.928798), ('temperature', 0.07058724015951157)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:94000 episode:18782 last_R: 3.290992498397827 average_R:2.9096191573143004
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.0899768), ('average_q2', 1.0612642), ('average_q_func1_loss', 0.3805469635128975), ('average_q_func2_loss', 0.3821578350663185), ('n_updates', 83999), ('average_entropy', -1.0338113), ('temperature', 0.07118458300828934)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:95000 episode:18966 last_R: 3.340487241744995 average_R:3.157999005317688
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.1675993), ('average_q2', 1.1919448), ('average_q_func1_loss', 0.38975928366184237), ('average_q_func2_loss', 0.39133081555366517), ('n_updates', 84999), ('average_entropy', -0.9608749), ('temperature', 0.07279393821954727)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:96000 episode:19154 last_R: 7.823378086090088 average_R:3.1761679530143736
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.1947517), ('average_q2', 1.1999696), ('average_q_func1_loss', 0.38626562029123307), ('average_q_func2_loss', 0.3887981078028679), ('n_updates', 85999), ('average_entropy', -0.99429995), ('temperature', 0.07382049411535263)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:97000 episode:19345 last_R: 2.3200979232788086 average_R:3.093589673042297
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.265157), ('average_q2', 1.2353902), ('average_q_func1_loss', 0.4047819486260414), ('average_q_func2_loss', 0.4070494392514229), ('n_updates', 86999), ('average_entropy', -1.0870212), ('temperature', 0.07449807226657867)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:98000 episode:19534 last_R: 2.60945463180542 average_R:2.9944296932220458
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.1363945), ('average_q2', 1.1188686), ('average_q_func1_loss', 0.408137149810791), ('average_q_func2_loss', 0.40990115851163866), ('n_updates', 87999), ('average_entropy', -1.0887351), ('temperature', 0.07467515021562576)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:99000 episode:19718 last_R: 2.004082679748535 average_R:3.1961208629608153
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.2471724), ('average_q2', 1.2688209), ('average_q_func1_loss', 0.4121518248319626), ('average_q_func2_loss', 0.41384417355060577), ('n_updates', 88999), ('average_entropy', -0.9490509), ('temperature', 0.0751747265458107)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:100000 episode:19907 last_R: 3.173231363296509 average_R:3.1456027579307557
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.249265), ('average_q2', 1.2539246), ('average_q_func1_loss', 0.4200176787376404), ('average_q_func2_loss', 0.42087788999080655), ('n_updates', 89999), ('average_entropy', -0.97351956), ('temperature', 0.07727421075105667)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 12 R: 12.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 7 R: 7.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 7 R: 7.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 8 R: 8.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 7 R: 7.0
INFO:diayn_sim:true z: tensor([29, 29, 29, 29], device='cuda:0')
INFO:diayn_sim:disc z: tensor([33, 35, 43, 36])
INFO:diayn_sim:disc loss: 3.1830129623413086
INFO:diayn_sim:top extrinsic: [12. 20. 10. 15.]
INFO:diayn_sim:last intrinsic: [0.8070457  0.8420017  0.8114896  0.45530367]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:101000 episode:20099 last_R: 5.934528112411499 average_R:2.990042600631714
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.2045459), ('average_q2', 1.2075408), ('average_q_func1_loss', 0.41884324938058853), ('average_q_func2_loss', 0.41944865584373475), ('n_updates', 90999), ('average_entropy', -0.9825462), ('temperature', 0.07765178382396698)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:102000 episode:20296 last_R: 2.0368080139160156 average_R:3.2183935403823853
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.2416369), ('average_q2', 1.2275426), ('average_q_func1_loss', 0.4223116499185562), ('average_q_func2_loss', 0.42356044113636016), ('n_updates', 91999), ('average_entropy', -0.998592), ('temperature', 0.07816224545240402)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:103000 episode:20478 last_R: 2.191633462905884 average_R:2.8411034965515136
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.3231927), ('average_q2', 1.2993194), ('average_q_func1_loss', 0.4422489520907402), ('average_q_func2_loss', 0.4435893008112907), ('n_updates', 92999), ('average_entropy', -1.0560638), ('temperature', 0.07814398407936096)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:104000 episode:20674 last_R: 0.6487932205200195 average_R:3.089166102409363
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.2481269), ('average_q2', 1.2070613), ('average_q_func1_loss', 0.4389967581629753), ('average_q_func2_loss', 0.440241112112999), ('n_updates', 93999), ('average_entropy', -0.9513811), ('temperature', 0.07737446576356888)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:105000 episode:20867 last_R: 2.789644956588745 average_R:3.461142563819885
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.255597), ('average_q2', 1.2563323), ('average_q_func1_loss', 0.4444559445977211), ('average_q_func2_loss', 0.44498425304889677), ('n_updates', 94999), ('average_entropy', -1.0812106), ('temperature', 0.07947174459695816)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:106000 episode:21055 last_R: 5.5596699714660645 average_R:3.436559433937073
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.3334348), ('average_q2', 1.3290372), ('average_q_func1_loss', 0.4433322250843048), ('average_q_func2_loss', 0.4446053582429886), ('n_updates', 95999), ('average_entropy', -1.0498438), ('temperature', 0.08031220734119415)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:107000 episode:21233 last_R: 2.147838592529297 average_R:3.485298500061035
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.304144), ('average_q2', 1.3130747), ('average_q_func1_loss', 0.46156944513320924), ('average_q_func2_loss', 0.46219909518957136), ('n_updates', 96999), ('average_entropy', -0.835651), ('temperature', 0.08096632361412048)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:108000 episode:21414 last_R: 2.076000690460205 average_R:3.7149127602577208
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.3500978), ('average_q2', 1.3236841), ('average_q_func1_loss', 0.46075074285268786), ('average_q_func2_loss', 0.4617939615249634), ('n_updates', 97999), ('average_entropy', -1.0667573), ('temperature', 0.08159037679433823)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:109000 episode:21584 last_R: 0.6152865886688232 average_R:3.659846885204315
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.3644533), ('average_q2', 1.354265), ('average_q_func1_loss', 0.47203168481588365), ('average_q_func2_loss', 0.4727609059214592), ('n_updates', 98999), ('average_entropy', -1.1530205), ('temperature', 0.0835830494761467)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:110000 episode:21773 last_R: 8.52871036529541 average_R:3.2774934720993043
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.3005525), ('average_q2', 1.2842039), ('average_q_func1_loss', 0.48776164650917053), ('average_q_func2_loss', 0.48966032147407534), ('n_updates', 99999), ('average_entropy', -1.0809817), ('temperature', 0.08330317586660385)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:111000 episode:21955 last_R: 2.227022171020508 average_R:3.4675308060646057
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.4383321), ('average_q2', 1.4343909), ('average_q_func1_loss', 0.4906838148832321), ('average_q_func2_loss', 0.49163611978292465), ('n_updates', 100999), ('average_entropy', -1.0490873), ('temperature', 0.08496402204036713)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:112000 episode:22142 last_R: 6.515895366668701 average_R:3.453035469055176
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.4382051), ('average_q2', 1.4538655), ('average_q_func1_loss', 0.5094734665751457), ('average_q_func2_loss', 0.5103885573148728), ('n_updates', 101999), ('average_entropy', -0.9550347), ('temperature', 0.08474373072385788)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:113000 episode:22333 last_R: 2.2778732776641846 average_R:2.9307831716537476
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.397272), ('average_q2', 1.44292), ('average_q_func1_loss', 0.5034012100100518), ('average_q_func2_loss', 0.5038115033507347), ('n_updates', 102999), ('average_entropy', -1.0791968), ('temperature', 0.08356589078903198)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:114000 episode:22511 last_R: 1.8377480506896973 average_R:3.5915200328826904
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.406151), ('average_q2', 1.368667), ('average_q_func1_loss', 0.5129595637321472), ('average_q_func2_loss', 0.5147369256615639), ('n_updates', 103999), ('average_entropy', -1.110774), ('temperature', 0.08607162535190582)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:115000 episode:22699 last_R: 0.6869137287139893 average_R:3.6286726713180544
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.4013628), ('average_q2', 1.3388599), ('average_q_func1_loss', 0.5205875235795975), ('average_q_func2_loss', 0.5206750449538231), ('n_updates', 104999), ('average_entropy', -0.84622884), ('temperature', 0.0868958905339241)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:116000 episode:22867 last_R: 8.687514781951904 average_R:4.165178472995758
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.4003962), ('average_q2', 1.3840395), ('average_q_func1_loss', 0.5317572611570358), ('average_q_func2_loss', 0.5318515938520432), ('n_updates', 105999), ('average_entropy', -1.0864371), ('temperature', 0.08621008694171906)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:117000 episode:23045 last_R: 3.391138792037964 average_R:3.5759010410308836
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.3600221), ('average_q2', 1.4205632), ('average_q_func1_loss', 0.550308800637722), ('average_q_func2_loss', 0.5502145195007324), ('n_updates', 106999), ('average_entropy', -0.9533431), ('temperature', 0.08798126131296158)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:118000 episode:23211 last_R: 1.0775516033172607 average_R:4.064143266677856
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.3933009), ('average_q2', 1.3729097), ('average_q_func1_loss', 0.5509832963347435), ('average_q_func2_loss', 0.550526260137558), ('n_updates', 107999), ('average_entropy', -1.1134609), ('temperature', 0.08731644600629807)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:119000 episode:23386 last_R: 3.0509376525878906 average_R:4.092235491275788
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.4509718), ('average_q2', 1.5044247), ('average_q_func1_loss', 0.5517709031701088), ('average_q_func2_loss', 0.5533591869473458), ('n_updates', 108999), ('average_entropy', -0.9602246), ('temperature', 0.08972815424203873)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:120000 episode:23554 last_R: 1.8039755821228027 average_R:4.039727561473846
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.507769), ('average_q2', 1.489288), ('average_q_func1_loss', 0.5818310922384262), ('average_q_func2_loss', 0.5828053516149521), ('n_updates', 109999), ('average_entropy', -0.94766307), ('temperature', 0.09023255854845047)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:121000 episode:23737 last_R: 2.1257190704345703 average_R:3.6880105566978454
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.452951), ('average_q2', 1.4690915), ('average_q_func1_loss', 0.5695626223087311), ('average_q_func2_loss', 0.5705138513445854), ('n_updates', 110999), ('average_entropy', -1.0022267), ('temperature', 0.09175842255353928)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:122000 episode:23909 last_R: 2.334031343460083 average_R:4.110715215206146
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.4037471), ('average_q2', 1.4117674), ('average_q_func1_loss', 0.5721013852953911), ('average_q_func2_loss', 0.5746530619263649), ('n_updates', 111999), ('average_entropy', -0.8983207), ('temperature', 0.08822191506624222)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:123000 episode:24073 last_R: 6.73915433883667 average_R:4.1768324756622315
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.4468919), ('average_q2', 1.4317234), ('average_q_func1_loss', 0.5972224447131157), ('average_q_func2_loss', 0.5997721046209336), ('n_updates', 112999), ('average_entropy', -1.0003034), ('temperature', 0.0901218131184578)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:124000 episode:24239 last_R: 5.589150667190552 average_R:4.06481486082077
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.4710572), ('average_q2', 1.5340464), ('average_q_func1_loss', 0.6072057342529297), ('average_q_func2_loss', 0.6076702618598938), ('n_updates', 113999), ('average_entropy', -0.9098918), ('temperature', 0.08919092267751694)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:125000 episode:24401 last_R: 2.6892852783203125 average_R:4.390988571643829
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.6310744), ('average_q2', 1.5457295), ('average_q_func1_loss', 0.6163640570640564), ('average_q_func2_loss', 0.6174380448460579), ('n_updates', 114999), ('average_entropy', -1.0270326), ('temperature', 0.09032155573368073)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 7 R: 7.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 6 R: 6.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 14 R: 14.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 7 R: 7.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 6 R: 6.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 4 R: 4.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 7 R: 7.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 6 R: 6.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 3 R: 3.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 9 R: 9.0
INFO:diayn_sim:true z: tensor([ 9, 29, 14, 29], device='cuda:0')
INFO:diayn_sim:disc z: tensor([ 4, 38, 14, 41])
INFO:diayn_sim:disc loss: 3.070247173309326
INFO:diayn_sim:top extrinsic: [20. 23. 11.  7.]
INFO:diayn_sim:last intrinsic: [0.75430775 0.8955703  1.0999432  0.6170833 ]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:126000 episode:24562 last_R: 6.784799575805664 average_R:3.794280505180359
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.6104834), ('average_q2', 1.5910621), ('average_q_func1_loss', 0.6178772044181824), ('average_q_func2_loss', 0.620367976129055), ('n_updates', 115999), ('average_entropy', -0.8945991), ('temperature', 0.09029556810855865)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:127000 episode:24727 last_R: 0.3911166191101074 average_R:3.8171976685523985
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.5271436), ('average_q2', 1.5567589), ('average_q_func1_loss', 0.622099132835865), ('average_q_func2_loss', 0.6240507394075394), ('n_updates', 116999), ('average_entropy', -0.9470349), ('temperature', 0.08970541507005692)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:128000 episode:24890 last_R: 7.452844858169556 average_R:4.420223259925843
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.5210663), ('average_q2', 1.5377305), ('average_q_func1_loss', 0.63256711602211), ('average_q_func2_loss', 0.6338889455795288), ('n_updates', 117999), ('average_entropy', -0.9924602), ('temperature', 0.08795984834432602)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:129000 episode:25063 last_R: 8.96946406364441 average_R:4.0610360288619995
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.526842), ('average_q2', 1.5211014), ('average_q_func1_loss', 0.6429740995168686), ('average_q_func2_loss', 0.6447496062517166), ('n_updates', 118999), ('average_entropy', -0.8907605), ('temperature', 0.08962758630514145)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:130000 episode:25235 last_R: 1.5068607330322266 average_R:4.090119335651398
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.6159315), ('average_q2', 1.6082693), ('average_q_func1_loss', 0.6590004652738571), ('average_q_func2_loss', 0.6612408041954041), ('n_updates', 119999), ('average_entropy', -0.9696576), ('temperature', 0.08768189698457718)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:131000 episode:25380 last_R: 19.6513888835907 average_R:5.061012890338898
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.7022595), ('average_q2', 1.6897173), ('average_q_func1_loss', 0.6733977234363556), ('average_q_func2_loss', 0.6757571595907211), ('n_updates', 120999), ('average_entropy', -0.9962135), ('temperature', 0.0896056592464447)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:132000 episode:25537 last_R: 2.01235294342041 average_R:4.079528903961181
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.5754956), ('average_q2', 1.6359204), ('average_q_func1_loss', 0.6721692681312561), ('average_q_func2_loss', 0.6719769990444183), ('n_updates', 121999), ('average_entropy', -0.9694467), ('temperature', 0.08990439027547836)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:133000 episode:25672 last_R: 2.8810553550720215 average_R:5.22842054605484
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.8229162), ('average_q2', 1.811848), ('average_q_func1_loss', 0.7013916140794754), ('average_q_func2_loss', 0.7021812361478805), ('n_updates', 122999), ('average_entropy', -0.9508181), ('temperature', 0.08767980337142944)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:134000 episode:25829 last_R: 3.100087881088257 average_R:4.88565719127655
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.6449666), ('average_q2', 1.6973337), ('average_q_func1_loss', 0.700780199766159), ('average_q_func2_loss', 0.7024021416902542), ('n_updates', 123999), ('average_entropy', -1.0960985), ('temperature', 0.08892311900854111)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:135000 episode:25977 last_R: 4.074408531188965 average_R:4.674327416419983
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.8198172), ('average_q2', 1.8084834), ('average_q_func1_loss', 0.706892055273056), ('average_q_func2_loss', 0.7099902635812759), ('n_updates', 124999), ('average_entropy', -1.064355), ('temperature', 0.0886736735701561)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:136000 episode:26133 last_R: 6.6930012702941895 average_R:4.312053911685943
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.8207651), ('average_q2', 1.8334371), ('average_q_func1_loss', 0.7221369135379792), ('average_q_func2_loss', 0.7236931198835372), ('n_updates', 125999), ('average_entropy', -0.9161855), ('temperature', 0.08639930933713913)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:137000 episode:26275 last_R: 6.40581750869751 average_R:4.939977905750275
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.6813002), ('average_q2', 1.7188015), ('average_q_func1_loss', 0.7321680849790573), ('average_q_func2_loss', 0.7369700014591217), ('n_updates', 126999), ('average_entropy', -0.8928209), ('temperature', 0.08698154240846634)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:138000 episode:26417 last_R: 2.175689458847046 average_R:4.658545508384704
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.8380117), ('average_q2', 1.7729946), ('average_q_func1_loss', 0.7414902710914612), ('average_q_func2_loss', 0.743353500366211), ('n_updates', 127999), ('average_entropy', -1.1043062), ('temperature', 0.08405236899852753)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:139000 episode:26556 last_R: 2.631913185119629 average_R:5.135685071945191
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.7087715), ('average_q2', 1.7674224), ('average_q_func1_loss', 0.7549862796068192), ('average_q_func2_loss', 0.7573656713962555), ('n_updates', 128999), ('average_entropy', -1.0088377), ('temperature', 0.08537903428077698)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:140000 episode:26702 last_R: 4.027385473251343 average_R:4.431453351974487
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.8074588), ('average_q2', 1.8013183), ('average_q_func1_loss', 0.7492202240228653), ('average_q_func2_loss', 0.7514627796411514), ('n_updates', 129999), ('average_entropy', -1.0047263), ('temperature', 0.08578883856534958)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:141000 episode:26828 last_R: 2.1635477542877197 average_R:5.60268696308136
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.7474897), ('average_q2', 1.7789783), ('average_q_func1_loss', 0.7889654445648193), ('average_q_func2_loss', 0.7890940618515014), ('n_updates', 130999), ('average_entropy', -0.9739918), ('temperature', 0.08601859211921692)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:142000 episode:26952 last_R: 2.008814811706543 average_R:5.4248706293106075
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.7249926), ('average_q2', 1.7980462), ('average_q_func1_loss', 0.7975722634792328), ('average_q_func2_loss', 0.7949906408786773), ('n_updates', 131999), ('average_entropy', -0.95977503), ('temperature', 0.08384843170642853)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:143000 episode:27078 last_R: 2.224182367324829 average_R:5.065584778785706
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.8389891), ('average_q2', 1.783252), ('average_q_func1_loss', 0.7877354329824447), ('average_q_func2_loss', 0.787773380279541), ('n_updates', 132999), ('average_entropy', -0.8705555), ('temperature', 0.08191758394241333)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:144000 episode:27201 last_R: 2.2118489742279053 average_R:5.754637265205384
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.8745933), ('average_q2', 1.8875335), ('average_q_func1_loss', 0.8129472780227661), ('average_q_func2_loss', 0.8127160519361496), ('n_updates', 133999), ('average_entropy', -1.0411507), ('temperature', 0.08403082937002182)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:145000 episode:27308 last_R: 9.784080266952515 average_R:6.1836326217651365
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.7391099), ('average_q2', 1.7721367), ('average_q_func1_loss', 0.8236273217201233), ('average_q_func2_loss', 0.8278958988189697), ('n_updates', 134999), ('average_entropy', -0.9658673), ('temperature', 0.0816132202744484)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:146000 episode:27431 last_R: 3.0142698287963867 average_R:5.46966293334961
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.966167), ('average_q2', 1.9521224), ('average_q_func1_loss', 0.831812019944191), ('average_q_func2_loss', 0.8324008893966675), ('n_updates', 135999), ('average_entropy', -0.9068479), ('temperature', 0.08333954960107803)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:147000 episode:27538 last_R: 3.091865301132202 average_R:5.69416023015976
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.9304086), ('average_q2', 1.9918914), ('average_q_func1_loss', 0.8546869015693664), ('average_q_func2_loss', 0.8553240013122558), ('n_updates', 136999), ('average_entropy', -1.0147682), ('temperature', 0.08018287271261215)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:148000 episode:27626 last_R: 16.506135940551758 average_R:6.044633169174194
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.9096038), ('average_q2', 1.9538252), ('average_q_func1_loss', 0.8479856717586517), ('average_q_func2_loss', 0.8496038788557052), ('n_updates', 137999), ('average_entropy', -0.91156226), ('temperature', 0.07848917692899704)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:149000 episode:27728 last_R: 9.270191192626953 average_R:5.5211030626297
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.9143755), ('average_q2', 1.8887188), ('average_q_func1_loss', 0.8661294668912888), ('average_q_func2_loss', 0.866325843334198), ('n_updates', 138999), ('average_entropy', -1.089969), ('temperature', 0.07972293347120285)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:150000 episode:27803 last_R: 7.300192356109619 average_R:6.512614641189575
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.8852155), ('average_q2', 1.8540249), ('average_q_func1_loss', 0.9058069884777069), ('average_q_func2_loss', 0.9070167565345764), ('n_updates', 139999), ('average_entropy', -1.018068), ('temperature', 0.08298147469758987)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 6 R: 6.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 8 R: 8.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 17 R: 17.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 25 R: 25.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 12 R: 12.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 17 R: 17.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 14 R: 14.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 14 R: 14.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 21 R: 21.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 11 R: 11.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 18 R: 18.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 5 R: 5.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 7 R: 7.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 18 R: 18.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 21 R: 21.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 14 R: 14.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 27 R: 27.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 15 R: 15.0
INFO:diayn_sim:true z: tensor([29, 10, 21, 17], device='cuda:0')
INFO:diayn_sim:disc z: tensor([32, 46, 22, 17])
INFO:diayn_sim:disc loss: 3.4022140502929688
INFO:diayn_sim:top extrinsic: [28. 30. 33. 26.]
INFO:diayn_sim:last intrinsic: [ 0.14349365 -0.6165533   1.157795    1.3543007 ]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:151000 episode:27867 last_R: 13.28372049331665 average_R:7.706362082958221
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.9702172), ('average_q2', 1.974702), ('average_q_func1_loss', 0.8758221733570098), ('average_q_func2_loss', 0.8778070211410522), ('n_updates', 140999), ('average_entropy', -0.90644985), ('temperature', 0.08536887168884277)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:152000 episode:27930 last_R: 12.2832670211792 average_R:7.352037010192871
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.0624442), ('average_q2', 2.0791693), ('average_q_func1_loss', 0.8907557839155197), ('average_q_func2_loss', 0.8918336552381515), ('n_updates', 141999), ('average_entropy', -1.1009668), ('temperature', 0.08648740500211716)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:153000 episode:28004 last_R: 7.644836187362671 average_R:7.5304739785194394
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.911247), ('average_q2', 1.9008389), ('average_q_func1_loss', 0.9067564624547958), ('average_q_func2_loss', 0.9081676471233368), ('n_updates', 142999), ('average_entropy', -0.92876023), ('temperature', 0.08869846165180206)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:154000 episode:28060 last_R: 5.3448991775512695 average_R:8.281049289703368
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.1169963), ('average_q2', 2.042935), ('average_q_func1_loss', 0.9466757786273956), ('average_q_func2_loss', 0.9456563657522201), ('n_updates', 143999), ('average_entropy', -1.052158), ('temperature', 0.09115574508905411)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:155000 episode:28112 last_R: 4.211055755615234 average_R:8.870767230987548
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.8938818), ('average_q2', 1.8623797), ('average_q_func1_loss', 0.9277316635847092), ('average_q_func2_loss', 0.9296566730737686), ('n_updates', 144999), ('average_entropy', -0.9311952), ('temperature', 0.09451545774936676)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:156000 episode:28159 last_R: 23.036875247955322 average_R:9.67795723438263
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.8914807), ('average_q2', 1.8594956), ('average_q_func1_loss', 0.9282363653182983), ('average_q_func2_loss', 0.9300142163038254), ('n_updates', 145999), ('average_entropy', -0.97190833), ('temperature', 0.0964994877576828)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:157000 episode:28213 last_R: 17.81732487678528 average_R:10.042134482860565
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.9271488), ('average_q2', 1.9275669), ('average_q_func1_loss', 0.9275892829895019), ('average_q_func2_loss', 0.9283284121751785), ('n_updates', 146999), ('average_entropy', -0.9971665), ('temperature', 0.0977388247847557)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:158000 episode:28264 last_R: -0.01683354377746582 average_R:9.623148443698883
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.1447349), ('average_q2', 2.1407099), ('average_q_func1_loss', 0.9566124320030213), ('average_q_func2_loss', 0.957701353430748), ('n_updates', 147999), ('average_entropy', -0.94284475), ('temperature', 0.09903314709663391)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:159000 episode:28314 last_R: 12.772363185882568 average_R:10.37478728055954
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.1290033), ('average_q2', 2.1089091), ('average_q_func1_loss', 0.9695096278190612), ('average_q_func2_loss', 0.9714415097236633), ('n_updates', 148999), ('average_entropy', -0.98627573), ('temperature', 0.10147138684988022)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:160000 episode:28360 last_R: 9.687235832214355 average_R:10.252260534763336
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.124267), ('average_q2', 2.057584), ('average_q_func1_loss', 0.9810498160123825), ('average_q_func2_loss', 0.9820388334989548), ('n_updates', 149999), ('average_entropy', -0.9997058), ('temperature', 0.10320865362882614)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:161000 episode:28405 last_R: 13.551339626312256 average_R:10.177944173812866
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.139149), ('average_q2', 2.1128159), ('average_q_func1_loss', 0.9817622059583664), ('average_q_func2_loss', 0.9812732547521591), ('n_updates', 150999), ('average_entropy', -1.0435302), ('temperature', 0.1031971126794815)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:162000 episode:28444 last_R: 24.866091012954712 average_R:11.811522641181945
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.1184676), ('average_q2', 2.1445577), ('average_q_func1_loss', 0.9988951104879379), ('average_q_func2_loss', 0.9983663308620453), ('n_updates', 151999), ('average_entropy', -1.0261694), ('temperature', 0.10445002466440201)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:163000 episode:28477 last_R: 8.848386764526367 average_R:12.555896430015563
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 1.978833), ('average_q2', 2.019984), ('average_q_func1_loss', 1.0160403686761856), ('average_q_func2_loss', 1.015591853260994), ('n_updates', 152999), ('average_entropy', -0.93447375), ('temperature', 0.10710924118757248)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:164000 episode:28513 last_R: 15.968205451965332 average_R:13.156066427230835
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.1429434), ('average_q2', 2.181687), ('average_q_func1_loss', 1.0059857696294785), ('average_q_func2_loss', 1.0058499145507813), ('n_updates', 153999), ('average_entropy', -1.0381063), ('temperature', 0.11265387386083603)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:165000 episode:28547 last_R: 23.92259955406189 average_R:12.780907340049744
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.1990058), ('average_q2', 2.283883), ('average_q_func1_loss', 1.042177735567093), ('average_q_func2_loss', 1.0428010576963425), ('n_updates', 154999), ('average_entropy', -0.95329624), ('temperature', 0.1133112981915474)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:166000 episode:28574 last_R: 5.212971448898315 average_R:13.38438363790512
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.1555665), ('average_q2', 2.1545503), ('average_q_func1_loss', 1.0543510687351227), ('average_q_func2_loss', 1.0534977775812149), ('n_updates', 155999), ('average_entropy', -1.0653392), ('temperature', 0.11238458007574081)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:167000 episode:28601 last_R: 14.155911684036255 average_R:14.830183460712433
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.0866153), ('average_q2', 2.1653671), ('average_q_func1_loss', 1.032835967540741), ('average_q_func2_loss', 1.0314463937282563), ('n_updates', 156999), ('average_entropy', -0.9312867), ('temperature', 0.11542177200317383)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:168000 episode:28626 last_R: 38.905850648880005 average_R:16.611792106628418
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.2645469), ('average_q2', 2.245034), ('average_q_func1_loss', 1.0629179561138153), ('average_q_func2_loss', 1.061375516653061), ('n_updates', 157999), ('average_entropy', -0.94868565), ('temperature', 0.11681367456912994)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:169000 episode:28652 last_R: 5.837541818618774 average_R:17.168312673568725
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.2625182), ('average_q2', 2.2843843), ('average_q_func1_loss', 1.0822136569023133), ('average_q_func2_loss', 1.0815213859081267), ('n_updates', 158999), ('average_entropy', -1.098288), ('temperature', 0.11740675568580627)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:170000 episode:28677 last_R: 12.34453296661377 average_R:18.030444378852845
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.2996945), ('average_q2', 2.285083), ('average_q_func1_loss', 1.1204232197999955), ('average_q_func2_loss', 1.121200954914093), ('n_updates', 159999), ('average_entropy', -0.9574347), ('temperature', 0.1208387017250061)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:171000 episode:28700 last_R: 5.134705543518066 average_R:18.699426546096802
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.1150541), ('average_q2', 2.0955079), ('average_q_func1_loss', 1.0917002433538436), ('average_q_func2_loss', 1.0906970930099487), ('n_updates', 160999), ('average_entropy', -1.0099369), ('temperature', 0.1226310059428215)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:172000 episode:28724 last_R: 29.830668687820435 average_R:19.136310880184173
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.3971534), ('average_q2', 2.4272535), ('average_q_func1_loss', 1.1178000503778458), ('average_q_func2_loss', 1.1233908230066298), ('n_updates', 161999), ('average_entropy', -0.9340283), ('temperature', 0.12463241815567017)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:173000 episode:28741 last_R: 22.0615017414093 average_R:19.417702040672303
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.448773), ('average_q2', 2.4773285), ('average_q_func1_loss', 1.1368861067295075), ('average_q_func2_loss', 1.139335354566574), ('n_updates', 162999), ('average_entropy', -0.9873867), ('temperature', 0.1258375197649002)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:174000 episode:28761 last_R: 11.532820224761963 average_R:20.30767664194107
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.158512), ('average_q2', 2.1848974), ('average_q_func1_loss', 1.1678008460998535), ('average_q_func2_loss', 1.1683224707841873), ('n_updates', 163999), ('average_entropy', -1.0398306), ('temperature', 0.1267436444759369)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:175000 episode:28781 last_R: 20.72813844680786 average_R:20.786374769210816
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.460168), ('average_q2', 2.4611046), ('average_q_func1_loss', 1.1687457448244094), ('average_q_func2_loss', 1.1713385969400405), ('n_updates', 164999), ('average_entropy', -0.9502749), ('temperature', 0.1278643012046814)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 105 R: 105.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 61 R: 61.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 64 R: 64.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 75 R: 75.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 50 R: 50.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 49 R: 49.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 71 R: 71.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 83 R: 83.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 73 R: 73.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 72 R: 72.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 31 R: 31.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 55 R: 55.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 73 R: 73.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 45 R: 45.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 51 R: 51.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 59 R: 59.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 44 R: 44.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 84 R: 84.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 57 R: 57.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 115 R: 115.0
INFO:diayn_sim:true z: tensor([12,  5, 30, 29], device='cuda:0')
INFO:diayn_sim:disc z: tensor([12, 49, 34, 16])
INFO:diayn_sim:disc loss: 3.8792507648468018
INFO:diayn_sim:top extrinsic: [134. 130. 160. 102.]
INFO:diayn_sim:last intrinsic: [ 1.2958269  -0.7084007   0.09308529 -0.54962254]
INFO:pfrl.experiments.train_agent_batch:The best score is updated 20.8 -> 65.85
INFO:pfrl.experiments.train_agent_batch:Saved the agent to results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a/best
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:176000 episode:28801 last_R: 18.55379295349121 average_R:21.072961597442628
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.327557), ('average_q2', 2.2756667), ('average_q_func1_loss', 1.1588005048036576), ('average_q_func2_loss', 1.1602982079982758), ('n_updates', 165999), ('average_entropy', -1.0477915), ('temperature', 0.1312687247991562)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:177000 episode:28819 last_R: 16.33249545097351 average_R:22.1340882396698
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.2982705), ('average_q2', 2.3195965), ('average_q_func1_loss', 1.1807341331243515), ('average_q_func2_loss', 1.184291433095932), ('n_updates', 166999), ('average_entropy', -0.96354365), ('temperature', 0.1320488154888153)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:178000 episode:28837 last_R: 46.58144211769104 average_R:23.175945034027098
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.4129672), ('average_q2', 2.4506116), ('average_q_func1_loss', 1.2083032429218292), ('average_q_func2_loss', 1.2086956954002381), ('n_updates', 167999), ('average_entropy', -0.9722238), ('temperature', 0.13486942648887634)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:179000 episode:28852 last_R: 16.74776005744934 average_R:23.705892748832703
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.5056045), ('average_q2', 2.5374284), ('average_q_func1_loss', 1.203710191845894), ('average_q_func2_loss', 1.205324082970619), ('n_updates', 168999), ('average_entropy', -0.9805097), ('temperature', 0.13928991556167603)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:180000 episode:28865 last_R: 47.54858088493347 average_R:24.937597506046295
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.4263816), ('average_q2', 2.3617938), ('average_q_func1_loss', 1.2453184884786606), ('average_q_func2_loss', 1.2484930491447448), ('n_updates', 169999), ('average_entropy', -1.0795414), ('temperature', 0.1418052613735199)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:181000 episode:28882 last_R: 44.21068048477173 average_R:26.533627750873567
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.5860689), ('average_q2', 2.613258), ('average_q_func1_loss', 1.2302559673786164), ('average_q_func2_loss', 1.227619975209236), ('n_updates', 170999), ('average_entropy', -1.0323735), ('temperature', 0.14362399280071259)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:182000 episode:28896 last_R: 31.15093970298767 average_R:27.843421432971954
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.4324336), ('average_q2', 2.4649487), ('average_q_func1_loss', 1.2313877618312836), ('average_q_func2_loss', 1.2314626014232635), ('n_updates', 171999), ('average_entropy', -0.9791974), ('temperature', 0.14624154567718506)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:183000 episode:28910 last_R: 35.36049818992615 average_R:29.489975550174712
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.5388348), ('average_q2', 2.5241787), ('average_q_func1_loss', 1.241942080259323), ('average_q_func2_loss', 1.243499356508255), ('n_updates', 172999), ('average_entropy', -1.0556177), ('temperature', 0.14826913177967072)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:184000 episode:28925 last_R: 35.01112222671509 average_R:30.73645919084549
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.539399), ('average_q2', 2.5305474), ('average_q_func1_loss', 1.2598741787672043), ('average_q_func2_loss', 1.2596932935714722), ('n_updates', 173999), ('average_entropy', -1.1161913), ('temperature', 0.149991974234581)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:185000 episode:28938 last_R: 39.83595538139343 average_R:32.5930020236969
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.6009986), ('average_q2', 2.6612895), ('average_q_func1_loss', 1.2807245302200316), ('average_q_func2_loss', 1.2818318140506744), ('n_updates', 174999), ('average_entropy', -0.96381754), ('temperature', 0.15439073741436005)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:186000 episode:28952 last_R: 31.988201141357422 average_R:32.64937876462936
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.7794423), ('average_q2', 2.7216234), ('average_q_func1_loss', 1.2753610813617706), ('average_q_func2_loss', 1.2736678063869475), ('n_updates', 175999), ('average_entropy', -0.9421412), ('temperature', 0.1568361222743988)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:187000 episode:28962 last_R: 70.51366424560547 average_R:34.478478941917416
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.631704), ('average_q2', 2.625349), ('average_q_func1_loss', 1.2854959660768508), ('average_q_func2_loss', 1.2848819762468338), ('n_updates', 176999), ('average_entropy', -0.9444241), ('temperature', 0.15810170769691467)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:188000 episode:28975 last_R: 36.91707515716553 average_R:34.876045718193055
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.759576), ('average_q2', 2.8237846), ('average_q_func1_loss', 1.3180725014209747), ('average_q_func2_loss', 1.3215396678447724), ('n_updates', 177999), ('average_entropy', -1.0092844), ('temperature', 0.16100184619426727)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:189000 episode:28987 last_R: 55.2658154964447 average_R:35.713962559700015
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.7347271), ('average_q2', 2.762106), ('average_q_func1_loss', 1.3225418162345886), ('average_q_func2_loss', 1.322901041507721), ('n_updates', 178999), ('average_entropy', -0.948688), ('temperature', 0.16420826315879822)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:190000 episode:28997 last_R: 36.031110525131226 average_R:37.36950162887573
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.7617865), ('average_q2', 2.8398497), ('average_q_func1_loss', 1.336779990196228), ('average_q_func2_loss', 1.3379369759559632), ('n_updates', 179999), ('average_entropy', -0.99686605), ('temperature', 0.16892722249031067)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:191000 episode:29011 last_R: 20.568652629852295 average_R:37.54834062576294
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.7049606), ('average_q2', 2.6763794), ('average_q_func1_loss', 1.3604468035697936), ('average_q_func2_loss', 1.35897181391716), ('n_updates', 180999), ('average_entropy', -0.9284745), ('temperature', 0.17100369930267334)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:192000 episode:29024 last_R: 40.68771553039551 average_R:38.17502078056336
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.8418832), ('average_q2', 2.8145657), ('average_q_func1_loss', 1.3427692782878875), ('average_q_func2_loss', 1.3451765620708465), ('n_updates', 181999), ('average_entropy', -0.93842983), ('temperature', 0.1712825894355774)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:193000 episode:29035 last_R: 34.213998556137085 average_R:38.775649898052215
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.7365444), ('average_q2', 2.6735098), ('average_q_func1_loss', 1.3692778825759888), ('average_q_func2_loss', 1.3718817800283432), ('n_updates', 182999), ('average_entropy', -0.9307992), ('temperature', 0.17405830323696136)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:194000 episode:29046 last_R: 45.092939615249634 average_R:41.17141531467438
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.7943513), ('average_q2', 2.801087), ('average_q_func1_loss', 1.3879861044883728), ('average_q_func2_loss', 1.3901479363441467), ('n_updates', 183999), ('average_entropy', -1.0277202), ('temperature', 0.17655310034751892)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:195000 episode:29055 last_R: 35.23496389389038 average_R:41.99665526151657
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.7657304), ('average_q2', 2.7639546), ('average_q_func1_loss', 1.354978642463684), ('average_q_func2_loss', 1.356983550786972), ('n_updates', 184999), ('average_entropy', -1.0471941), ('temperature', 0.18014729022979736)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:196000 episode:29070 last_R: 36.301363468170166 average_R:41.81835011482239
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.953223), ('average_q2', 2.9398444), ('average_q_func1_loss', 1.3914533865451812), ('average_q_func2_loss', 1.3955846393108369), ('n_updates', 185999), ('average_entropy', -1.0324949), ('temperature', 0.18022266030311584)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:197000 episode:29084 last_R: 52.39471793174744 average_R:42.7291010093689
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.917555), ('average_q2', 2.9034588), ('average_q_func1_loss', 1.4065933775901795), ('average_q_func2_loss', 1.4056147730350494), ('n_updates', 186999), ('average_entropy', -1.0653158), ('temperature', 0.18429532647132874)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:198000 episode:29094 last_R: 57.70402407646179 average_R:41.88561646938324
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.878502), ('average_q2', 2.8925307), ('average_q_func1_loss', 1.4171238625049591), ('average_q_func2_loss', 1.4180348432064056), ('n_updates', 187999), ('average_entropy', -0.9535992), ('temperature', 0.1888008713722229)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:199000 episode:29107 last_R: 44.87680149078369 average_R:42.62823949337005
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.0114214), ('average_q2', 3.0203848), ('average_q_func1_loss', 1.4336832523345948), ('average_q_func2_loss', 1.4358537805080414), ('n_updates', 188999), ('average_entropy', -0.8821665), ('temperature', 0.1905713826417923)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:200000 episode:29118 last_R: 38.38020086288452 average_R:44.60630789279938
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.0356147), ('average_q2', 2.9846623), ('average_q_func1_loss', 1.4391322588920594), ('average_q_func2_loss', 1.4450889766216277), ('n_updates', 189999), ('average_entropy', -1.0940555), ('temperature', 0.19316831231117249)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 96 R: 96.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 236 R: 236.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 69 R: 69.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 59 R: 59.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 96 R: 96.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 100 R: 100.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 80 R: 80.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 86 R: 86.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 118 R: 118.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 60 R: 60.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 71 R: 71.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 53 R: 53.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 79 R: 79.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 123 R: 123.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 150 R: 150.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 72 R: 72.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 18 R: 18.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 87 R: 87.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 60 R: 60.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 75 R: 75.0
INFO:diayn_sim:true z: tensor([21, 29,  0,  1], device='cuda:0')
INFO:diayn_sim:disc z: tensor([19, 27, 22,  0])
INFO:diayn_sim:disc loss: 3.228052854537964
INFO:diayn_sim:top extrinsic: [203. 236. 123. 242.]
INFO:diayn_sim:last intrinsic: [ 0.840785    1.0332768  -0.56915665  1.4307759 ]
INFO:pfrl.experiments.train_agent_batch:The best score is updated 65.85 -> 89.4
INFO:pfrl.experiments.train_agent_batch:Saved the agent to results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a/best
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:201000 episode:29130 last_R: 32.91413331031799 average_R:45.16188580989838
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.9862752), ('average_q2', 3.0299194), ('average_q_func1_loss', 1.4636984038352967), ('average_q_func2_loss', 1.465749613046646), ('n_updates', 190999), ('average_entropy', -1.0564091), ('temperature', 0.19601336121559143)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:202000 episode:29142 last_R: 23.79669976234436 average_R:44.51776642084122
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.8913999), ('average_q2', 2.9542367), ('average_q_func1_loss', 1.4565982508659363), ('average_q_func2_loss', 1.4564789640903473), ('n_updates', 191999), ('average_entropy', -0.9856043), ('temperature', 0.19582901895046234)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:203000 episode:29151 last_R: 64.31324529647827 average_R:45.52618582725525
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 2.8936875), ('average_q2', 2.878349), ('average_q_func1_loss', 1.4700482177734375), ('average_q_func2_loss', 1.4713021945953368), ('n_updates', 192999), ('average_entropy', -1.0690573), ('temperature', 0.19973206520080566)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:204000 episode:29164 last_R: 31.045021772384644 average_R:45.81118483304977
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.0063434), ('average_q2', 3.0329556), ('average_q_func1_loss', 1.5119960796833039), ('average_q_func2_loss', 1.5115694117546081), ('n_updates', 193999), ('average_entropy', -1.0645559), ('temperature', 0.20302991569042206)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:205000 episode:29175 last_R: 60.1007399559021 average_R:45.75312335729599
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.0991774), ('average_q2', 3.1071303), ('average_q_func1_loss', 1.477347571849823), ('average_q_func2_loss', 1.4800553715229035), ('n_updates', 194999), ('average_entropy', -1.0233804), ('temperature', 0.2049470692873001)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:206000 episode:29186 last_R: 62.24189019203186 average_R:46.28046710014343
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.2927616), ('average_q2', 3.2772112), ('average_q_func1_loss', 1.5262009084224701), ('average_q_func2_loss', 1.5285899794101716), ('n_updates', 195999), ('average_entropy', -1.0620334), ('temperature', 0.20768514275550842)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:207000 episode:29198 last_R: 87.87343835830688 average_R:46.40164291381836
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.1311934), ('average_q2', 3.1180122), ('average_q_func1_loss', 1.4710844218730927), ('average_q_func2_loss', 1.4729591512680054), ('n_updates', 196999), ('average_entropy', -1.0442524), ('temperature', 0.21003280580043793)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:208000 episode:29206 last_R: 39.90998339653015 average_R:48.44462231636047
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.1092296), ('average_q2', 3.1058447), ('average_q_func1_loss', 1.5149077451229096), ('average_q_func2_loss', 1.5171356654167176), ('n_updates', 197999), ('average_entropy', -0.93644905), ('temperature', 0.21149544417858124)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:209000 episode:29218 last_R: 47.47175097465515 average_R:48.723147950172425
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.1050878), ('average_q2', 3.0896504), ('average_q_func1_loss', 1.541790428161621), ('average_q_func2_loss', 1.5442379057407378), ('n_updates', 198999), ('average_entropy', -1.0181742), ('temperature', 0.2140609622001648)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:210000 episode:29232 last_R: 32.263171434402466 average_R:48.75850041151047
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.241914), ('average_q2', 3.247611), ('average_q_func1_loss', 1.5584869623184203), ('average_q_func2_loss', 1.5588295710086824), ('n_updates', 199999), ('average_entropy', -0.9622161), ('temperature', 0.21867896616458893)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:211000 episode:29244 last_R: 29.8209547996521 average_R:48.142242698669435
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.3079288), ('average_q2', 3.3263495), ('average_q_func1_loss', 1.5987943017482757), ('average_q_func2_loss', 1.5986257934570312), ('n_updates', 200999), ('average_entropy', -1.0108843), ('temperature', 0.2201264351606369)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:212000 episode:29255 last_R: 139.5192220211029 average_R:48.476981744766235
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.4057868), ('average_q2', 3.3933501), ('average_q_func1_loss', 1.5808787429332734), ('average_q_func2_loss', 1.5811182177066803), ('n_updates', 201999), ('average_entropy', -1.0101315), ('temperature', 0.22082030773162842)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:213000 episode:29263 last_R: 121.18083763122559 average_R:49.11490563392639
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.1449885), ('average_q2', 3.1192644), ('average_q_func1_loss', 1.5902371561527253), ('average_q_func2_loss', 1.5927705979347229), ('n_updates', 202999), ('average_entropy', -1.0031064), ('temperature', 0.2248373180627823)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:214000 episode:29275 last_R: 25.48868155479431 average_R:50.974327566623685
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.4036148), ('average_q2', 3.3766894), ('average_q_func1_loss', 1.5911062479019165), ('average_q_func2_loss', 1.5891307020187377), ('n_updates', 203999), ('average_entropy', -1.0284485), ('temperature', 0.22763554751873016)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:215000 episode:29288 last_R: 34.90644574165344 average_R:50.69361970901489
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.250592), ('average_q2', 3.218468), ('average_q_func1_loss', 1.5981485986709594), ('average_q_func2_loss', 1.596793053150177), ('n_updates', 204999), ('average_entropy', -0.94197714), ('temperature', 0.231070414185524)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:216000 episode:29298 last_R: 14.9432053565979 average_R:51.46313937187195
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.2668788), ('average_q2', 3.245222), ('average_q_func1_loss', 1.6144342076778413), ('average_q_func2_loss', 1.613954255580902), ('n_updates', 205999), ('average_entropy', -0.99141085), ('temperature', 0.23162056505680084)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:217000 episode:29310 last_R: 32.95380902290344 average_R:50.033525521755216
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.5241182), ('average_q2', 3.484446), ('average_q_func1_loss', 1.6283754765987397), ('average_q_func2_loss', 1.631657063961029), ('n_updates', 206999), ('average_entropy', -0.99802595), ('temperature', 0.2352883666753769)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:218000 episode:29324 last_R: 27.58121609687805 average_R:48.9804093170166
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.4388156), ('average_q2', 3.3746514), ('average_q_func1_loss', 1.5988165438175201), ('average_q_func2_loss', 1.5982407903671265), ('n_updates', 207999), ('average_entropy', -0.9568748), ('temperature', 0.23682259023189545)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:219000 episode:29337 last_R: 39.848671436309814 average_R:49.20049136161804
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.5924644), ('average_q2', 3.6094742), ('average_q_func1_loss', 1.6414079356193543), ('average_q_func2_loss', 1.6390934848785401), ('n_updates', 208999), ('average_entropy', -1.0102607), ('temperature', 0.2420845478773117)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:220000 episode:29347 last_R: 27.55423402786255 average_R:50.03838690519333
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.5366697), ('average_q2', 3.5862887), ('average_q_func1_loss', 1.6483650064468385), ('average_q_func2_loss', 1.649057642221451), ('n_updates', 209999), ('average_entropy', -1.0938498), ('temperature', 0.24339482188224792)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:221000 episode:29357 last_R: 64.90997838973999 average_R:50.438756060600284
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.5001388), ('average_q2', 3.4953272), ('average_q_func1_loss', 1.626812480688095), ('average_q_func2_loss', 1.6287115836143493), ('n_updates', 210999), ('average_entropy', -1.0486614), ('temperature', 0.24601653218269348)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:222000 episode:29368 last_R: 52.58427405357361 average_R:48.88010615110397
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.2758644), ('average_q2', 3.3038232), ('average_q_func1_loss', 1.6458888757228851), ('average_q_func2_loss', 1.6475059509277343), ('n_updates', 211999), ('average_entropy', -1.0576977), ('temperature', 0.24745424091815948)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:223000 episode:29380 last_R: 44.55503273010254 average_R:50.88151559114456
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.4522414), ('average_q2', 3.4125874), ('average_q_func1_loss', 1.6362733280658721), ('average_q_func2_loss', 1.6409732460975648), ('n_updates', 212999), ('average_entropy', -0.99198), ('temperature', 0.2527972161769867)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:224000 episode:29390 last_R: 32.434463024139404 average_R:52.02195157766342
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.522228), ('average_q2', 3.5196936), ('average_q_func1_loss', 1.7041576659679414), ('average_q_func2_loss', 1.6971097052097321), ('n_updates', 213999), ('average_entropy', -1.0055891), ('temperature', 0.25452950596809387)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:225000 episode:29403 last_R: 48.185834646224976 average_R:51.23228649139404
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.5201566), ('average_q2', 3.5480118), ('average_q_func1_loss', 1.6398287892341614), ('average_q_func2_loss', 1.640312134027481), ('n_updates', 214999), ('average_entropy', -1.0813631), ('temperature', 0.2593801021575928)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 101 R: 101.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 57 R: 57.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 45 R: 45.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 81 R: 81.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 69 R: 69.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 90 R: 90.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 88 R: 88.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 89 R: 89.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 64 R: 64.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 57 R: 57.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 87 R: 87.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 57 R: 57.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 105 R: 105.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 70 R: 70.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 167 R: 167.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 74 R: 74.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 86 R: 86.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 48 R: 48.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 84 R: 84.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 91 R: 91.0
INFO:diayn_sim:true z: tensor([ 0, 12, 18,  7], device='cuda:0')
INFO:diayn_sim:disc z: tensor([ 3, 14, 33,  9])
INFO:diayn_sim:disc loss: 3.0089967250823975
INFO:diayn_sim:top extrinsic: [194. 127. 167. 161.]
INFO:diayn_sim:last intrinsic: [1.4308438  0.7946656  0.47203827 0.9143572 ]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:226000 episode:29413 last_R: 42.27620005607605 average_R:51.95817294597626
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.7364595), ('average_q2', 3.6725113), ('average_q_func1_loss', 1.7073156392574311), ('average_q_func2_loss', 1.7103480577468873), ('n_updates', 215999), ('average_entropy', -1.0701174), ('temperature', 0.2587894797325134)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:227000 episode:29426 last_R: 16.08524441719055 average_R:52.60191800355911
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.5699542), ('average_q2', 3.588274), ('average_q_func1_loss', 1.7585153937339784), ('average_q_func2_loss', 1.7557743108272552), ('n_updates', 216999), ('average_entropy', -1.0244085), ('temperature', 0.2628825306892395)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:228000 episode:29439 last_R: 40.85931181907654 average_R:52.21648878335953
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.532499), ('average_q2', 3.5925474), ('average_q_func1_loss', 1.7190937352180482), ('average_q_func2_loss', 1.7162483942508697), ('n_updates', 217999), ('average_entropy', -0.9944632), ('temperature', 0.2641114890575409)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:229000 episode:29450 last_R: 23.43627095222473 average_R:52.06859419345856
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.6107047), ('average_q2', 3.6032133), ('average_q_func1_loss', 1.7318917787075043), ('average_q_func2_loss', 1.73018195271492), ('n_updates', 218999), ('average_entropy', -0.93374467), ('temperature', 0.2685350179672241)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:230000 episode:29464 last_R: 37.06208038330078 average_R:51.231068487167356
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.765175), ('average_q2', 3.743786), ('average_q_func1_loss', 1.7583317720890046), ('average_q_func2_loss', 1.76083070397377), ('n_updates', 219999), ('average_entropy', -1.075291), ('temperature', 0.2697729766368866)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:231000 episode:29474 last_R: 71.46248626708984 average_R:49.984792773723605
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.6901684), ('average_q2', 3.6937866), ('average_q_func1_loss', 1.73954003572464), ('average_q_func2_loss', 1.7388861417770385), ('n_updates', 220999), ('average_entropy', -1.053101), ('temperature', 0.27523380517959595)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:232000 episode:29486 last_R: 61.26589298248291 average_R:50.36614457368851
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.7646031), ('average_q2', 3.8072677), ('average_q_func1_loss', 1.7526404821872712), ('average_q_func2_loss', 1.747398066520691), ('n_updates', 221999), ('average_entropy', -0.99353504), ('temperature', 0.27405214309692383)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:233000 episode:29499 last_R: 52.70064902305603 average_R:50.46741416454315
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.633396), ('average_q2', 3.6507971), ('average_q_func1_loss', 1.7863606750965118), ('average_q_func2_loss', 1.7874303352832794), ('n_updates', 222999), ('average_entropy', -0.9921685), ('temperature', 0.27768468856811523)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:234000 episode:29511 last_R: 63.96289348602295 average_R:49.15099423885346
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.8190732), ('average_q2', 3.8312337), ('average_q_func1_loss', 1.8172506308555603), ('average_q_func2_loss', 1.818219245672226), ('n_updates', 223999), ('average_entropy', -0.9952665), ('temperature', 0.27786046266555786)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:235000 episode:29526 last_R: 44.19776916503906 average_R:48.97861144542694
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.855413), ('average_q2', 3.8634367), ('average_q_func1_loss', 1.781628019809723), ('average_q_func2_loss', 1.7860918581485747), ('n_updates', 224999), ('average_entropy', -0.9527285), ('temperature', 0.2824985384941101)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:236000 episode:29538 last_R: 63.68027639389038 average_R:49.829475755691526
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 3.8962615), ('average_q2', 3.9202163), ('average_q_func1_loss', 1.8206007444858552), ('average_q_func2_loss', 1.8253199446201325), ('n_updates', 225999), ('average_entropy', -1.0437922), ('temperature', 0.28238680958747864)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:237000 episode:29554 last_R: 45.5173978805542 average_R:47.835324141979214
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.1137414), ('average_q2', 4.058521), ('average_q_func1_loss', 1.7978359150886536), ('average_q_func2_loss', 1.800219337940216), ('n_updates', 226999), ('average_entropy', -1.0291353), ('temperature', 0.28651103377342224)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:238000 episode:29565 last_R: 32.813405990600586 average_R:49.483135051727295
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.0094624), ('average_q2', 4.039752), ('average_q_func1_loss', 1.8170067429542542), ('average_q_func2_loss', 1.8168425178527832), ('n_updates', 227999), ('average_entropy', -0.9668119), ('temperature', 0.2904930114746094)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:239000 episode:29578 last_R: 52.074854373931885 average_R:48.41632676124573
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.047816), ('average_q2', 4.000804), ('average_q_func1_loss', 1.8209277176856995), ('average_q_func2_loss', 1.826355117559433), ('n_updates', 228999), ('average_entropy', -0.9886873), ('temperature', 0.2913269102573395)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:240000 episode:29593 last_R: 32.179219484329224 average_R:47.12320273160935
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.020483), ('average_q2', 3.9736023), ('average_q_func1_loss', 1.852752254009247), ('average_q_func2_loss', 1.8579480516910554), ('n_updates', 229999), ('average_entropy', -0.973165), ('temperature', 0.296426385641098)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:241000 episode:29606 last_R: 88.9893057346344 average_R:46.357879548072816
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.190303), ('average_q2', 4.213359), ('average_q_func1_loss', 1.8298183500766754), ('average_q_func2_loss', 1.8363725352287292), ('n_updates', 230999), ('average_entropy', -0.9961852), ('temperature', 0.2961936593055725)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:242000 episode:29619 last_R: 56.400598764419556 average_R:46.25350306749344
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.249338), ('average_q2', 4.2804513), ('average_q_func1_loss', 1.868786075115204), ('average_q_func2_loss', 1.8719415545463562), ('n_updates', 231999), ('average_entropy', -1.0048145), ('temperature', 0.2979929447174072)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:243000 episode:29634 last_R: 33.033135175704956 average_R:45.86925988674164
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.030765), ('average_q2', 4.012014), ('average_q_func1_loss', 1.8975660264492036), ('average_q_func2_loss', 1.9078484320640563), ('n_updates', 232999), ('average_entropy', -1.0277405), ('temperature', 0.3011610805988312)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:244000 episode:29650 last_R: 49.75095820426941 average_R:46.01142866611481
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.2375774), ('average_q2', 4.239665), ('average_q_func1_loss', 1.864522557258606), ('average_q_func2_loss', 1.8605162763595582), ('n_updates', 233999), ('average_entropy', -1.0483994), ('temperature', 0.3026985824108124)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:245000 episode:29667 last_R: 50.810993909835815 average_R:43.164549589157104
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.094007), ('average_q2', 4.0934963), ('average_q_func1_loss', 1.9086485743522643), ('average_q_func2_loss', 1.9177482438087463), ('n_updates', 234999), ('average_entropy', -0.91876173), ('temperature', 0.3046654164791107)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:246000 episode:29681 last_R: 46.5107581615448 average_R:43.25596920728683
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.084077), ('average_q2', 4.146795), ('average_q_func1_loss', 1.9150486385822296), ('average_q_func2_loss', 1.9229847884178162), ('n_updates', 235999), ('average_entropy', -1.0348073), ('temperature', 0.3044736683368683)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:247000 episode:29697 last_R: 31.758274793624878 average_R:42.82797068834305
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.0301914), ('average_q2', 4.088444), ('average_q_func1_loss', 1.9260355341434479), ('average_q_func2_loss', 1.9363317584991455), ('n_updates', 236999), ('average_entropy', -1.0123694), ('temperature', 0.3050171136856079)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:248000 episode:29712 last_R: 65.87902522087097 average_R:42.44729238271713
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.2883525), ('average_q2', 4.335592), ('average_q_func1_loss', 2.0123406863212585), ('average_q_func2_loss', 2.0251450192928315), ('n_updates', 237999), ('average_entropy', -0.97113067), ('temperature', 0.31102362275123596)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:249000 episode:29727 last_R: 35.123289346694946 average_R:41.459245429039
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.385967), ('average_q2', 4.458691), ('average_q_func1_loss', 1.9421060943603516), ('average_q_func2_loss', 1.950042209625244), ('n_updates', 238999), ('average_entropy', -0.9554955), ('temperature', 0.3175208270549774)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:250000 episode:29741 last_R: 29.55380654335022 average_R:41.69457851409912
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.1025443), ('average_q2', 4.0790906), ('average_q_func1_loss', 1.9674807620048522), ('average_q_func2_loss', 1.9783405101299285), ('n_updates', 239999), ('average_entropy', -0.9357846), ('temperature', 0.31741127371788025)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 22 R: 22.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 70 R: 70.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 70 R: 70.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 108 R: 108.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 61 R: 61.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 81 R: 81.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 82 R: 82.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 54 R: 54.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 61 R: 61.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 54 R: 54.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 77 R: 77.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 48 R: 48.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 70 R: 70.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 51 R: 51.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 66 R: 66.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 81 R: 81.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 55 R: 55.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 52 R: 52.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 67 R: 67.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 63 R: 63.0
INFO:diayn_sim:true z: tensor([ 0,  9, 29, 29], device='cuda:0')
INFO:diayn_sim:disc z: tensor([46,  8, 25, 36])
INFO:diayn_sim:disc loss: 3.4578380584716797
INFO:diayn_sim:top extrinsic: [191. 239. 114. 131.]
INFO:diayn_sim:last intrinsic: [-0.5691557   1.2014778   0.55113935  0.6330776 ]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:251000 episode:29757 last_R: 44.051963806152344 average_R:42.146285207271575
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.5258965), ('average_q2', 4.5164766), ('average_q_func1_loss', 1.9607989311218261), ('average_q_func2_loss', 1.9732193863391876), ('n_updates', 240999), ('average_entropy', -1.0860186), ('temperature', 0.3193042576313019)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:252000 episode:29772 last_R: 68.63213729858398 average_R:42.85659632205963
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.273992), ('average_q2', 4.253536), ('average_q_func1_loss', 1.9761939430236817), ('average_q_func2_loss', 1.98907576918602), ('n_updates', 241999), ('average_entropy', -0.9795005), ('temperature', 0.3200482726097107)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:253000 episode:29785 last_R: 39.427560329437256 average_R:42.72049699306488
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.4493504), ('average_q2', 4.459174), ('average_q_func1_loss', 2.0107059025764467), ('average_q_func2_loss', 2.024131075143814), ('n_updates', 242999), ('average_entropy', -0.9726098), ('temperature', 0.32330322265625)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:254000 episode:29800 last_R: 38.61837339401245 average_R:44.36796758651733
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.4036436), ('average_q2', 4.385127), ('average_q_func1_loss', 1.982195736169815), ('average_q_func2_loss', 2.002157484292984), ('n_updates', 243999), ('average_entropy', -0.92829835), ('temperature', 0.3242553174495697)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:255000 episode:29814 last_R: 47.37098836898804 average_R:44.57875465631485
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.591457), ('average_q2', 4.530214), ('average_q_func1_loss', 2.006517298221588), ('average_q_func2_loss', 2.021235500574112), ('n_updates', 244999), ('average_entropy', -1.0518203), ('temperature', 0.32827994227409363)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:256000 episode:29828 last_R: 62.96400856971741 average_R:45.74738479137421
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.7043147), ('average_q2', 4.7245045), ('average_q_func1_loss', 1.9993841791152953), ('average_q_func2_loss', 2.01817897439003), ('n_updates', 245999), ('average_entropy', -1.0165193), ('temperature', 0.3291129171848297)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:257000 episode:29843 last_R: 51.67891192436218 average_R:45.49450904130936
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.8186874), ('average_q2', 4.784407), ('average_q_func1_loss', 2.028674706220627), ('average_q_func2_loss', 2.04326611161232), ('n_updates', 246999), ('average_entropy', -0.99240977), ('temperature', 0.33180275559425354)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:258000 episode:29857 last_R: 46.96025085449219 average_R:45.41769675731659
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.5117874), ('average_q2', 4.4417667), ('average_q_func1_loss', 2.04773091673851), ('average_q_func2_loss', 2.0723154664039614), ('n_updates', 247999), ('average_entropy', -0.94529986), ('temperature', 0.3319128751754761)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:259000 episode:29869 last_R: 52.061362981796265 average_R:46.914495739936825
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.710004), ('average_q2', 4.6392775), ('average_q_func1_loss', 2.045060033798218), ('average_q_func2_loss', 2.0660953307151795), ('n_updates', 248999), ('average_entropy', -1.0742539), ('temperature', 0.3336271345615387)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:260000 episode:29883 last_R: 54.71906280517578 average_R:47.3018408703804
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.6242743), ('average_q2', 4.5703588), ('average_q_func1_loss', 2.0510613429546356), ('average_q_func2_loss', 2.076693506240845), ('n_updates', 249999), ('average_entropy', -1.014445), ('temperature', 0.33698078989982605)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:261000 episode:29896 last_R: 29.606985330581665 average_R:47.90489814043045
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.570755), ('average_q2', 4.564866), ('average_q_func1_loss', 2.0232262217998507), ('average_q_func2_loss', 2.049854174852371), ('n_updates', 250999), ('average_entropy', -1.0236547), ('temperature', 0.3366129398345947)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:262000 episode:29912 last_R: 50.63953185081482 average_R:47.48166098356247
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.2576427), ('average_q2', 4.2337303), ('average_q_func1_loss', 2.082763761281967), ('average_q_func2_loss', 2.109584891796112), ('n_updates', 251999), ('average_entropy', -0.9750861), ('temperature', 0.3414970934391022)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:263000 episode:29925 last_R: 49.989835262298584 average_R:47.423127501010896
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.5462685), ('average_q2', 4.557792), ('average_q_func1_loss', 2.067871836423874), ('average_q_func2_loss', 2.093757884502411), ('n_updates', 252999), ('average_entropy', -1.0126725), ('temperature', 0.3461818993091583)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:264000 episode:29940 last_R: 56.028319358825684 average_R:47.83070806980133
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.59754), ('average_q2', 4.594217), ('average_q_func1_loss', 2.0884210646152495), ('average_q_func2_loss', 2.1166969549655916), ('n_updates', 253999), ('average_entropy', -0.9403491), ('temperature', 0.34519168734550476)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:265000 episode:29953 last_R: 35.771597146987915 average_R:48.54509171962738
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.6902833), ('average_q2', 4.667555), ('average_q_func1_loss', 2.1223952424526216), ('average_q_func2_loss', 2.1431425631046297), ('n_updates', 254999), ('average_entropy', -1.0174327), ('temperature', 0.34974968433380127)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:266000 episode:29969 last_R: 40.0767126083374 average_R:47.2961371922493
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.6153126), ('average_q2', 4.634762), ('average_q_func1_loss', 2.150201586484909), ('average_q_func2_loss', 2.1801648902893067), ('n_updates', 255999), ('average_entropy', -1.0234867), ('temperature', 0.3483007848262787)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:267000 episode:29981 last_R: 55.347973346710205 average_R:47.87093923807144
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.777491), ('average_q2', 4.7726083), ('average_q_func1_loss', 2.137688057422638), ('average_q_func2_loss', 2.168798065185547), ('n_updates', 256999), ('average_entropy', -0.973707), ('temperature', 0.35140329599380493)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:268000 episode:29993 last_R: 29.804145097732544 average_R:47.80111737012863
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.8272996), ('average_q2', 4.8345356), ('average_q_func1_loss', 2.131105444431305), ('average_q_func2_loss', 2.1544343173503875), ('n_updates', 257999), ('average_entropy', -0.9954353), ('temperature', 0.34802523255348206)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:269000 episode:30008 last_R: 39.481874227523804 average_R:47.54586988210678
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.9558983), ('average_q2', 4.92979), ('average_q_func1_loss', 2.079392980337143), ('average_q_func2_loss', 2.108817962408066), ('n_updates', 258999), ('average_entropy', -1.0077664), ('temperature', 0.35415729880332947)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:270000 episode:30023 last_R: 33.753580808639526 average_R:47.723641521930695
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.936167), ('average_q2', 4.8959894), ('average_q_func1_loss', 2.1429396045207976), ('average_q_func2_loss', 2.1667862606048582), ('n_updates', 259999), ('average_entropy', -0.9412638), ('temperature', 0.35507073998451233)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:271000 episode:30035 last_R: 37.14345741271973 average_R:48.12356046438217
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.9720535), ('average_q2', 4.8996572), ('average_q_func1_loss', 2.140480809211731), ('average_q_func2_loss', 2.172378668785095), ('n_updates', 260999), ('average_entropy', -0.9754777), ('temperature', 0.3626427948474884)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:272000 episode:30049 last_R: 49.17999744415283 average_R:48.8030167555809
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.246584), ('average_q2', 5.2104473), ('average_q_func1_loss', 2.209044849872589), ('average_q_func2_loss', 2.2413134121894838), ('n_updates', 261999), ('average_entropy', -0.9825416), ('temperature', 0.3590916395187378)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:273000 episode:30064 last_R: 37.0046763420105 average_R:48.43288351297379
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.895339), ('average_q2', 4.955779), ('average_q_func1_loss', 2.212298102378845), ('average_q_func2_loss', 2.2434113800525664), ('n_updates', 262999), ('average_entropy', -0.99195534), ('temperature', 0.3629368543624878)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:274000 episode:30079 last_R: 82.60113191604614 average_R:48.48137946605682
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.6426964), ('average_q2', 4.6620345), ('average_q_func1_loss', 2.2537891018390654), ('average_q_func2_loss', 2.278761330842972), ('n_updates', 263999), ('average_entropy', -1.0876676), ('temperature', 0.3640557825565338)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:275000 episode:30094 last_R: 30.654004335403442 average_R:47.13637759685516
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.980704), ('average_q2', 4.9818077), ('average_q_func1_loss', 2.194951274394989), ('average_q_func2_loss', 2.211842987537384), ('n_updates', 264999), ('average_entropy', -0.9790762), ('temperature', 0.36686283349990845)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 63 R: 63.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 65 R: 65.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 72 R: 72.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 73 R: 73.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 51 R: 51.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 83 R: 83.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 93 R: 93.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 59 R: 59.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 99 R: 99.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 69 R: 69.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 73 R: 73.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 63 R: 63.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 56 R: 56.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 87 R: 87.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 104 R: 104.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 83 R: 83.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 74 R: 74.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 68 R: 68.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 59 R: 59.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 87 R: 87.0
INFO:diayn_sim:true z: tensor([28,  0, 29,  8], device='cuda:0')
INFO:diayn_sim:disc z: tensor([27, 26, 26, 41])
INFO:diayn_sim:disc loss: 3.540741205215454
INFO:diayn_sim:top extrinsic: [213. 177. 205. 199.]
INFO:diayn_sim:last intrinsic: [ 0.0856514 -0.5691557  1.199573   0.7688577]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:276000 episode:30108 last_R: 56.038392305374146 average_R:47.42979889631271
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.1296153), ('average_q2', 5.126224), ('average_q_func1_loss', 2.2840114176273345), ('average_q_func2_loss', 2.3240726339817046), ('n_updates', 265999), ('average_entropy', -1.081791), ('temperature', 0.36669111251831055)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:277000 episode:30123 last_R: 42.70131325721741 average_R:47.412664906978605
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.145694), ('average_q2', 5.1246943), ('average_q_func1_loss', 2.304948904514313), ('average_q_func2_loss', 2.3309900116920472), ('n_updates', 266999), ('average_entropy', -1.0259262), ('temperature', 0.3694866895675659)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:278000 episode:30136 last_R: 50.698580265045166 average_R:46.81085818052292
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.3967724), ('average_q2', 5.3966756), ('average_q_func1_loss', 2.2685353803634642), ('average_q_func2_loss', 2.2898134326934816), ('n_updates', 267999), ('average_entropy', -1.0362512), ('temperature', 0.36715126037597656)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:279000 episode:30155 last_R: 9.71327257156372 average_R:43.798356623649596
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.8696513), ('average_q2', 4.8671727), ('average_q_func1_loss', 2.3348998999595643), ('average_q_func2_loss', 2.358202192783356), ('n_updates', 268999), ('average_entropy', -1.00262), ('temperature', 0.36767908930778503)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:280000 episode:30170 last_R: 40.61987066268921 average_R:42.991487069129946
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.1865077), ('average_q2', 5.2167687), ('average_q_func1_loss', 2.334242947101593), ('average_q_func2_loss', 2.3517751359939574), ('n_updates', 269999), ('average_entropy', -0.9390696), ('temperature', 0.37052085995674133)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:281000 episode:30185 last_R: 41.66629099845886 average_R:42.335862567424776
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.3787603), ('average_q2', 5.3865743), ('average_q_func1_loss', 2.2885266649723053), ('average_q_func2_loss', 2.3005554723739623), ('n_updates', 270999), ('average_entropy', -1.0433908), ('temperature', 0.3734000623226166)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:282000 episode:30198 last_R: 43.02558183670044 average_R:43.18899295568466
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.458391), ('average_q2', 5.4149346), ('average_q_func1_loss', 2.309108954668045), ('average_q_func2_loss', 2.333390641212463), ('n_updates', 271999), ('average_entropy', -1.0275666), ('temperature', 0.3730601668357849)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:283000 episode:30214 last_R: 50.85262656211853 average_R:43.10500920534134
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.287436), ('average_q2', 5.27113), ('average_q_func1_loss', 2.372604556083679), ('average_q_func2_loss', 2.392566169500351), ('n_updates', 272999), ('average_entropy', -1.1036491), ('temperature', 0.37589821219444275)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:284000 episode:30228 last_R: 67.48850870132446 average_R:43.92607039928436
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.1505632), ('average_q2', 5.081628), ('average_q_func1_loss', 2.40285072684288), ('average_q_func2_loss', 2.42253448009491), ('n_updates', 273999), ('average_entropy', -0.9855986), ('temperature', 0.37633755803108215)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:285000 episode:30240 last_R: 35.23133611679077 average_R:44.75387107849121
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.4400835), ('average_q2', 5.371906), ('average_q_func1_loss', 2.446780718564987), ('average_q_func2_loss', 2.4663261020183564), ('n_updates', 274999), ('average_entropy', -0.9465038), ('temperature', 0.37726739048957825)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:286000 episode:30256 last_R: 40.03252601623535 average_R:46.00119439125061
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.419634), ('average_q2', 5.394716), ('average_q_func1_loss', 2.459738622903824), ('average_q_func2_loss', 2.4711113238334654), ('n_updates', 275999), ('average_entropy', -1.0696306), ('temperature', 0.37840840220451355)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:287000 episode:30271 last_R: 45.715553283691406 average_R:46.59147658824921
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 4.8191094), ('average_q2', 4.9146614), ('average_q_func1_loss', 2.4086596894264223), ('average_q_func2_loss', 2.423651980161667), ('n_updates', 276999), ('average_entropy', -0.8993196), ('temperature', 0.38257116079330444)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:288000 episode:30283 last_R: 34.99302625656128 average_R:47.55344462871552
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.131913), ('average_q2', 5.180404), ('average_q_func1_loss', 2.4109966373443603), ('average_q_func2_loss', 2.42735787153244), ('n_updates', 277999), ('average_entropy', -0.9818467), ('temperature', 0.38594257831573486)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:289000 episode:30300 last_R: 41.91775441169739 average_R:46.30037894487381
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.6068273), ('average_q2', 5.602388), ('average_q_func1_loss', 2.4923015236854553), ('average_q_func2_loss', 2.506895545721054), ('n_updates', 278999), ('average_entropy', -1.0261846), ('temperature', 0.3871195912361145)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:290000 episode:30309 last_R: 41.97903656959534 average_R:47.09972035646439
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.5306797), ('average_q2', 5.4810553), ('average_q_func1_loss', 2.4163472986221315), ('average_q_func2_loss', 2.4342531323432923), ('n_updates', 279999), ('average_entropy', -1.1041623), ('temperature', 0.38862836360931396)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:291000 episode:30325 last_R: 31.831135988235474 average_R:47.688679530620576
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.616543), ('average_q2', 5.654935), ('average_q_func1_loss', 2.463472875356674), ('average_q_func2_loss', 2.477649723291397), ('n_updates', 280999), ('average_entropy', -0.990365), ('temperature', 0.3942491412162781)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:292000 episode:30339 last_R: 38.9824161529541 average_R:46.994824576377866
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.2960353), ('average_q2', 5.241649), ('average_q_func1_loss', 2.530500236749649), ('average_q_func2_loss', 2.5439389681816102), ('n_updates', 281999), ('average_entropy', -1.0366688), ('temperature', 0.3859257400035858)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:293000 episode:30354 last_R: 47.00621509552002 average_R:47.34535455226898
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.4949903), ('average_q2', 5.5418205), ('average_q_func1_loss', 2.4791968524456025), ('average_q_func2_loss', 2.495453917980194), ('n_updates', 282999), ('average_entropy', -1.0267658), ('temperature', 0.39127904176712036)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:294000 episode:30369 last_R: 39.4092583656311 average_R:46.902688183784484
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.4274845), ('average_q2', 5.4481864), ('average_q_func1_loss', 2.4353345906734467), ('average_q_func2_loss', 2.4412308537960055), ('n_updates', 283999), ('average_entropy', -1.0024089), ('temperature', 0.3920353353023529)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:295000 episode:30384 last_R: 40.68975305557251 average_R:46.802269351482394
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.761869), ('average_q2', 5.717543), ('average_q_func1_loss', 2.4537570488452913), ('average_q_func2_loss', 2.454839526414871), ('n_updates', 284999), ('average_entropy', -0.97439563), ('temperature', 0.39335566759109497)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:296000 episode:30401 last_R: 31.80262327194214 average_R:46.22869021654129
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.601854), ('average_q2', 5.494813), ('average_q_func1_loss', 2.533904983997345), ('average_q_func2_loss', 2.536894677877426), ('n_updates', 285999), ('average_entropy', -0.96948695), ('temperature', 0.39074423909187317)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:297000 episode:30414 last_R: 31.697850465774536 average_R:44.616618475914
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.880659), ('average_q2', 5.965397), ('average_q_func1_loss', 2.482526943683624), ('average_q_func2_loss', 2.4842199754714964), ('n_updates', 286999), ('average_entropy', -1.0655868), ('temperature', 0.39942610263824463)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:298000 episode:30428 last_R: 36.96573352813721 average_R:45.334716672897336
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.603441), ('average_q2', 5.7053185), ('average_q_func1_loss', 2.5225964176654814), ('average_q_func2_loss', 2.5372322475910187), ('n_updates', 287999), ('average_entropy', -1.0114344), ('temperature', 0.40071651339530945)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:299000 episode:30441 last_R: 52.880839347839355 average_R:45.492266125679016
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.6804595), ('average_q2', 5.6342373), ('average_q_func1_loss', 2.5840346109867096), ('average_q_func2_loss', 2.5837296795845033), ('n_updates', 288999), ('average_entropy', -1.0154606), ('temperature', 0.399880975484848)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:300000 episode:30456 last_R: 40.51146173477173 average_R:46.04085544347763
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.870828), ('average_q2', 5.8818297), ('average_q_func1_loss', 2.5097317481040955), ('average_q_func2_loss', 2.5112375450134277), ('n_updates', 289999), ('average_entropy', -0.9916728), ('temperature', 0.4052508771419525)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 105 R: 105.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 52 R: 52.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 88 R: 88.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 127 R: 127.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 69 R: 69.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 86 R: 86.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 92 R: 92.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 72 R: 72.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 47 R: 47.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 95 R: 95.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 81 R: 81.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 95 R: 95.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 120 R: 120.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 83 R: 83.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 76 R: 76.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 87 R: 87.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 86 R: 86.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 112 R: 112.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 77 R: 77.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 88 R: 88.0
INFO:diayn_sim:true z: tensor([27,  0, 27, 12], device='cuda:0')
INFO:diayn_sim:disc z: tensor([25, 35, 32, 34])
INFO:diayn_sim:disc loss: 3.4145500659942627
INFO:diayn_sim:top extrinsic: [317. 167. 181. 195.]
INFO:diayn_sim:last intrinsic: [ 1.0539312  -0.5691557   0.7849388   0.71997666]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:301000 episode:30472 last_R: 39.976521015167236 average_R:45.70646578550339
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.6122265), ('average_q2', 5.640928), ('average_q_func1_loss', 2.5835193467140196), ('average_q_func2_loss', 2.5808065867424013), ('n_updates', 290999), ('average_entropy', -1.0028654), ('temperature', 0.4010325074195862)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:302000 episode:30486 last_R: 31.031643629074097 average_R:45.296913652420045
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.7283916), ('average_q2', 5.829437), ('average_q_func1_loss', 2.5935887122154235), ('average_q_func2_loss', 2.5820032858848574), ('n_updates', 291999), ('average_entropy', -0.9791443), ('temperature', 0.4038158059120178)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:303000 episode:30500 last_R: 38.10675263404846 average_R:45.94612801074982
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.8483224), ('average_q2', 5.858129), ('average_q_func1_loss', 2.531631144285202), ('average_q_func2_loss', 2.538921580314636), ('n_updates', 292999), ('average_entropy', -0.9789746), ('temperature', 0.405608594417572)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:304000 episode:30515 last_R: 29.329054355621338 average_R:46.01069783449173
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.0497003), ('average_q2', 6.0581145), ('average_q_func1_loss', 2.6515309035778047), ('average_q_func2_loss', 2.6589612782001497), ('n_updates', 293999), ('average_entropy', -0.9820362), ('temperature', 0.4067595601081848)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:305000 episode:30530 last_R: 50.424123764038086 average_R:45.25570515871048
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.7242885), ('average_q2', 5.9259367), ('average_q_func1_loss', 2.62639634013176), ('average_q_func2_loss', 2.62420086145401), ('n_updates', 294999), ('average_entropy', -0.97593486), ('temperature', 0.4135235548019409)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:306000 episode:30543 last_R: 85.1553590297699 average_R:45.58912938594818
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.916846), ('average_q2', 5.815541), ('average_q_func1_loss', 2.5961515283584595), ('average_q_func2_loss', 2.5894869339466093), ('n_updates', 295999), ('average_entropy', -1.0265138), ('temperature', 0.4085533320903778)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:307000 episode:30557 last_R: 43.606680154800415 average_R:45.906274976730344
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.966954), ('average_q2', 6.044075), ('average_q_func1_loss', 2.639965419769287), ('average_q_func2_loss', 2.6421244978904723), ('n_updates', 296999), ('average_entropy', -1.0480468), ('temperature', 0.40917524695396423)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:308000 episode:30570 last_R: 85.14689588546753 average_R:48.17760595798492
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.7512336), ('average_q2', 5.7365994), ('average_q_func1_loss', 2.686588315963745), ('average_q_func2_loss', 2.683323942422867), ('n_updates', 297999), ('average_entropy', -1.0347953), ('temperature', 0.40994080901145935)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:309000 episode:30583 last_R: 35.68732929229736 average_R:47.77279998540878
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.9458914), ('average_q2', 5.986108), ('average_q_func1_loss', 2.671305810213089), ('average_q_func2_loss', 2.6707375836372376), ('n_updates', 298999), ('average_entropy', -1.0170351), ('temperature', 0.41686829924583435)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:310000 episode:30597 last_R: 58.27582788467407 average_R:48.28215758800506
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.299766), ('average_q2', 6.2138534), ('average_q_func1_loss', 2.672025147676468), ('average_q_func2_loss', 2.659994661808014), ('n_updates', 299999), ('average_entropy', -1.0355879), ('temperature', 0.4130166172981262)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:311000 episode:30613 last_R: 34.49738955497742 average_R:48.30010244607925
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.995342), ('average_q2', 6.1425343), ('average_q_func1_loss', 2.7099486589431763), ('average_q_func2_loss', 2.7122049939632418), ('n_updates', 300999), ('average_entropy', -1.0055313), ('temperature', 0.4156495928764343)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:312000 episode:30628 last_R: 37.33159279823303 average_R:48.086587119102475
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.1773), ('average_q2', 6.0946407), ('average_q_func1_loss', 2.7254178643226625), ('average_q_func2_loss', 2.718452832698822), ('n_updates', 301999), ('average_entropy', -0.97734594), ('temperature', 0.41324853897094727)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:313000 episode:30642 last_R: 66.84090542793274 average_R:47.93070963144302
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.3263264), ('average_q2', 6.342513), ('average_q_func1_loss', 2.693200716972351), ('average_q_func2_loss', 2.68702819108963), ('n_updates', 302999), ('average_entropy', -1.0486538), ('temperature', 0.41595175862312317)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:314000 episode:30657 last_R: 61.564706563949585 average_R:46.941420941352845
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.254323), ('average_q2', 6.2359285), ('average_q_func1_loss', 2.6561845684051515), ('average_q_func2_loss', 2.6376975643634797), ('n_updates', 303999), ('average_entropy', -0.8606763), ('temperature', 0.4218510687351227)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:315000 episode:30669 last_R: 40.494120836257935 average_R:46.25230741262436
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 5.9312763), ('average_q2', 6.051341), ('average_q_func1_loss', 2.7514756608009336), ('average_q_func2_loss', 2.7465289664268493), ('n_updates', 304999), ('average_entropy', -0.9946796), ('temperature', 0.4182749390602112)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:316000 episode:30685 last_R: 27.279818534851074 average_R:45.68929144859314
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.0757413), ('average_q2', 6.003331), ('average_q_func1_loss', 2.66855064868927), ('average_q_func2_loss', 2.6494299137592314), ('n_updates', 305999), ('average_entropy', -1.0195596), ('temperature', 0.41986364126205444)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:317000 episode:30700 last_R: 43.30959916114807 average_R:45.61790882587433
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.153796), ('average_q2', 6.078245), ('average_q_func1_loss', 2.6713244414329527), ('average_q_func2_loss', 2.657501745223999), ('n_updates', 306999), ('average_entropy', -1.0477685), ('temperature', 0.4219188988208771)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:318000 episode:30715 last_R: 62.9347140789032 average_R:45.79041308641434
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.1533484), ('average_q2', 6.2036824), ('average_q_func1_loss', 2.7147707200050353), ('average_q_func2_loss', 2.7090757966041563), ('n_updates', 307999), ('average_entropy', -1.001342), ('temperature', 0.4271254539489746)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:319000 episode:30730 last_R: 41.390748739242554 average_R:46.48703225135803
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.1614814), ('average_q2', 6.1403565), ('average_q_func1_loss', 2.7195568108558654), ('average_q_func2_loss', 2.7148068416118623), ('n_updates', 308999), ('average_entropy', -1.0664932), ('temperature', 0.42712199687957764)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:320000 episode:30742 last_R: 61.84567713737488 average_R:46.51622268199921
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.065918), ('average_q2', 5.999951), ('average_q_func1_loss', 2.6623442113399505), ('average_q_func2_loss', 2.656187665462494), ('n_updates', 309999), ('average_entropy', -0.92572963), ('temperature', 0.4244188964366913)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:321000 episode:30754 last_R: 53.68659734725952 average_R:47.37285336494446
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.1370125), ('average_q2', 6.1453075), ('average_q_func1_loss', 2.6931100559234618), ('average_q_func2_loss', 2.6895557379722597), ('n_updates', 310999), ('average_entropy', -0.96927685), ('temperature', 0.4202291667461395)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:322000 episode:30768 last_R: 36.938483238220215 average_R:47.98727397441864
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.147914), ('average_q2', 6.2516503), ('average_q_func1_loss', 2.720208132266998), ('average_q_func2_loss', 2.705737463235855), ('n_updates', 311999), ('average_entropy', -1.0397289), ('temperature', 0.429092139005661)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:323000 episode:30783 last_R: 57.96182894706726 average_R:47.96796322345734
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.2185664), ('average_q2', 6.3273277), ('average_q_func1_loss', 2.7284895396232605), ('average_q_func2_loss', 2.7123760771751404), ('n_updates', 312999), ('average_entropy', -0.9568153), ('temperature', 0.42878007888793945)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:324000 episode:30798 last_R: 40.72353959083557 average_R:48.08466351032257
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.361236), ('average_q2', 6.1843486), ('average_q_func1_loss', 2.76503071308136), ('average_q_func2_loss', 2.7560992312431334), ('n_updates', 313999), ('average_entropy', -0.9380182), ('temperature', 0.42875465750694275)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:325000 episode:30813 last_R: 34.28641319274902 average_R:48.33169977426529
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.324873), ('average_q2', 6.070934), ('average_q_func1_loss', 2.7838403499126434), ('average_q_func2_loss', 2.7759623849391937), ('n_updates', 314999), ('average_entropy', -1.0314686), ('temperature', 0.43060994148254395)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 67 R: 67.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 77 R: 77.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 65 R: 65.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 106 R: 106.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 70 R: 70.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 94 R: 94.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 75 R: 75.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 89 R: 89.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 84 R: 84.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 80 R: 80.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 57 R: 57.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 80 R: 80.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 77 R: 77.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 73 R: 73.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 90 R: 90.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 83 R: 83.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 68 R: 68.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 74 R: 74.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 68 R: 68.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 74 R: 74.0
INFO:diayn_sim:true z: tensor([17, 27,  5,  0], device='cuda:0')
INFO:diayn_sim:disc z: tensor([16, 25,  4, 18])
INFO:diayn_sim:disc loss: 3.11751389503479
INFO:diayn_sim:top extrinsic: [208. 232. 219. 169.]
INFO:diayn_sim:last intrinsic: [ 1.1431193  1.2398674  1.3640053 -0.5691557]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:326000 episode:30827 last_R: 43.178881883621216 average_R:48.616941707134245
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.3665056), ('average_q2', 6.1512966), ('average_q_func1_loss', 2.7508082580566406), ('average_q_func2_loss', 2.7483592438697815), ('n_updates', 315999), ('average_entropy', -0.97193533), ('temperature', 0.4332423210144043)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:327000 episode:30841 last_R: 53.556118965148926 average_R:47.87926836013794
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.1352034), ('average_q2', 6.2361536), ('average_q_func1_loss', 2.7122901940345763), ('average_q_func2_loss', 2.7084610843658448), ('n_updates', 316999), ('average_entropy', -0.951813), ('temperature', 0.4305717945098877)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:328000 episode:30856 last_R: 37.18442916870117 average_R:46.77066914796829
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.5854616), ('average_q2', 6.785513), ('average_q_func1_loss', 2.823123378753662), ('average_q_func2_loss', 2.8225792515277863), ('n_updates', 317999), ('average_entropy', -0.9996059), ('temperature', 0.4312227666378021)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:329000 episode:30871 last_R: 60.56616759300232 average_R:45.23160741329193
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.454707), ('average_q2', 6.6575565), ('average_q_func1_loss', 2.8121747875213625), ('average_q_func2_loss', 2.8186441254615784), ('n_updates', 318999), ('average_entropy', -1.0407405), ('temperature', 0.43695294857025146)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:330000 episode:30884 last_R: 50.511008739471436 average_R:45.36348571300507
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.2838516), ('average_q2', 6.3047395), ('average_q_func1_loss', 2.7803678667545317), ('average_q_func2_loss', 2.7665158486366273), ('n_updates', 319999), ('average_entropy', -1.0048206), ('temperature', 0.4345499277114868)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:331000 episode:30900 last_R: 48.78333616256714 average_R:46.244124267101284
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.470907), ('average_q2', 6.465141), ('average_q_func1_loss', 2.717220177650452), ('average_q_func2_loss', 2.7098302376270293), ('n_updates', 320999), ('average_entropy', -0.93548656), ('temperature', 0.4373084604740143)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:332000 episode:30913 last_R: 56.256596326828 average_R:46.31269003868103
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.593243), ('average_q2', 6.5948524), ('average_q_func1_loss', 2.7734486150741575), ('average_q_func2_loss', 2.783163080215454), ('n_updates', 321999), ('average_entropy', -0.9839087), ('temperature', 0.436668336391449)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:333000 episode:30927 last_R: 28.910479307174683 average_R:46.12831458091736
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.528611), ('average_q2', 6.6143928), ('average_q_func1_loss', 2.8713872599601746), ('average_q_func2_loss', 2.8554218864440917), ('n_updates', 322999), ('average_entropy', -1.0128961), ('temperature', 0.43940800428390503)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:334000 episode:30943 last_R: 68.90339732170105 average_R:46.12163634300232
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.5477896), ('average_q2', 6.6744165), ('average_q_func1_loss', 2.770985894203186), ('average_q_func2_loss', 2.7488274550437928), ('n_updates', 323999), ('average_entropy', -1.0024731), ('temperature', 0.44397783279418945)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:335000 episode:30956 last_R: 36.31953191757202 average_R:45.98904214143753
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.4731493), ('average_q2', 6.4743485), ('average_q_func1_loss', 2.7960905766487123), ('average_q_func2_loss', 2.79666797876358), ('n_updates', 324999), ('average_entropy', -0.96677196), ('temperature', 0.4441581070423126)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:336000 episode:30971 last_R: 53.167601585388184 average_R:47.71273407697677
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.712624), ('average_q2', 6.869463), ('average_q_func1_loss', 2.845790913105011), ('average_q_func2_loss', 2.8272101068496704), ('n_updates', 325999), ('average_entropy', -1.0283233), ('temperature', 0.4472973346710205)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:337000 episode:30983 last_R: 41.42059779167175 average_R:48.29758896350861
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.5840507), ('average_q2', 6.4680705), ('average_q_func1_loss', 2.8245689773559572), ('average_q_func2_loss', 2.8157248497009277), ('n_updates', 326999), ('average_entropy', -1.0005419), ('temperature', 0.44907328486442566)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:338000 episode:30998 last_R: 61.26611685752869 average_R:48.84581929445267
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.4329004), ('average_q2', 6.424068), ('average_q_func1_loss', 2.8329771518707276), ('average_q_func2_loss', 2.824656090736389), ('n_updates', 327999), ('average_entropy', -0.9591389), ('temperature', 0.44579315185546875)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:339000 episode:31011 last_R: 41.69534420967102 average_R:48.93289332389831
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.3567886), ('average_q2', 6.283845), ('average_q_func1_loss', 2.904675862789154), ('average_q_func2_loss', 2.896704425811768), ('n_updates', 328999), ('average_entropy', -0.97603315), ('temperature', 0.45051348209381104)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:340000 episode:31025 last_R: 45.84062170982361 average_R:49.010584180355075
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.8230457), ('average_q2', 6.774106), ('average_q_func1_loss', 2.8441123247146605), ('average_q_func2_loss', 2.8477041935920715), ('n_updates', 329999), ('average_entropy', -1.0608816), ('temperature', 0.44715002179145813)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:341000 episode:31041 last_R: 69.332674741745 average_R:50.21530010223389
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.815527), ('average_q2', 6.794412), ('average_q_func1_loss', 2.826809995174408), ('average_q_func2_loss', 2.819047065973282), ('n_updates', 330999), ('average_entropy', -0.975627), ('temperature', 0.45053917169570923)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:342000 episode:31054 last_R: 44.16117787361145 average_R:50.47352364063263
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.461271), ('average_q2', 6.517294), ('average_q_func1_loss', 2.7989032649993897), ('average_q_func2_loss', 2.7734459924697874), ('n_updates', 331999), ('average_entropy', -0.9899954), ('temperature', 0.45136120915412903)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:343000 episode:31069 last_R: 31.394659519195557 average_R:49.14577296972275
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.54072), ('average_q2', 6.4663234), ('average_q_func1_loss', 2.8870395827293396), ('average_q_func2_loss', 2.8843306851387025), ('n_updates', 332999), ('average_entropy', -0.9872835), ('temperature', 0.45542019605636597)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:344000 episode:31082 last_R: 56.09410309791565 average_R:49.29692988872528
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.849904), ('average_q2', 6.7267776), ('average_q_func1_loss', 2.8030563473701475), ('average_q_func2_loss', 2.8000378143787383), ('n_updates', 333999), ('average_entropy', -1.0449641), ('temperature', 0.452275812625885)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:345000 episode:31096 last_R: 69.95097231864929 average_R:48.33109015226364
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.6920743), ('average_q2', 6.6431856), ('average_q_func1_loss', 2.87490075469017), ('average_q_func2_loss', 2.872975393533707), ('n_updates', 334999), ('average_entropy', -0.94373035), ('temperature', 0.45279189944267273)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:346000 episode:31112 last_R: 80.38568615913391 average_R:48.57301223278046
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.053409), ('average_q2', 7.2004485), ('average_q_func1_loss', 2.918199257850647), ('average_q_func2_loss', 2.919298384189606), ('n_updates', 335999), ('average_entropy', -1.0479026), ('temperature', 0.4521201550960541)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:347000 episode:31127 last_R: 39.359147787094116 average_R:48.02575405836105
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.6996245), ('average_q2', 6.6916), ('average_q_func1_loss', 2.90108802318573), ('average_q_func2_loss', 2.8995705687999727), ('n_updates', 336999), ('average_entropy', -0.96994776), ('temperature', 0.4604679048061371)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:348000 episode:31139 last_R: 48.44350719451904 average_R:48.253115932941434
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.85253), ('average_q2', 6.8142753), ('average_q_func1_loss', 2.9531360149383543), ('average_q_func2_loss', 2.9423232102394103), ('n_updates', 337999), ('average_entropy', -1.005823), ('temperature', 0.45551565289497375)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:349000 episode:31154 last_R: 28.27165722846985 average_R:48.24680255174637
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.595798), ('average_q2', 6.6813664), ('average_q_func1_loss', 2.902059278488159), ('average_q_func2_loss', 2.898106653690338), ('n_updates', 338999), ('average_entropy', -1.0278898), ('temperature', 0.45446285605430603)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:350000 episode:31168 last_R: 57.896697998046875 average_R:48.32368942975998
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.014572), ('average_q2', 6.867458), ('average_q_func1_loss', 2.9021775126457214), ('average_q_func2_loss', 2.892969164848328), ('n_updates', 339999), ('average_entropy', -1.0304552), ('temperature', 0.4579589068889618)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 122 R: 122.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 74 R: 74.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 84 R: 84.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 70 R: 70.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 73 R: 73.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 94 R: 94.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 85 R: 85.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 72 R: 72.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 82 R: 82.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 105 R: 105.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 111 R: 111.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 69 R: 69.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 62 R: 62.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 59 R: 59.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 97 R: 97.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 96 R: 96.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 68 R: 68.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 96 R: 96.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 91 R: 91.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 108 R: 108.0
INFO:diayn_sim:true z: tensor([ 5,  0, 28,  3], device='cuda:0')
INFO:diayn_sim:disc z: tensor([ 5, 30, 27,  1])
INFO:diayn_sim:disc loss: 3.1095218658447266
INFO:diayn_sim:top extrinsic: [155. 273. 280. 225.]
INFO:diayn_sim:last intrinsic: [ 1.0661223 -0.5691557  1.28194    1.4308975]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:351000 episode:31182 last_R: 47.71787881851196 average_R:47.02984138727188
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.641446), ('average_q2', 6.58825), ('average_q_func1_loss', 2.864022958278656), ('average_q_func2_loss', 2.8480516362190245), ('n_updates', 340999), ('average_entropy', -0.94531924), ('temperature', 0.45899292826652527)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:352000 episode:31195 last_R: 38.12142062187195 average_R:47.4157581114769
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.9961343), ('average_q2', 7.012262), ('average_q_func1_loss', 2.9101473760604857), ('average_q_func2_loss', 2.901402918100357), ('n_updates', 341999), ('average_entropy', -1.0382886), ('temperature', 0.4589516222476959)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:353000 episode:31210 last_R: 42.779696226119995 average_R:47.94776667833328
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.675168), ('average_q2', 6.7128515), ('average_q_func1_loss', 2.946942572593689), ('average_q_func2_loss', 2.9521108841896058), ('n_updates', 342999), ('average_entropy', -0.91772115), ('temperature', 0.4594508409500122)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:354000 episode:31224 last_R: 45.08513903617859 average_R:47.87334526777268
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.0485954), ('average_q2', 7.031072), ('average_q_func1_loss', 2.8363721323013307), ('average_q_func2_loss', 2.8280423188209536), ('n_updates', 343999), ('average_entropy', -1.0047415), ('temperature', 0.4614354372024536)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:355000 episode:31238 last_R: 93.85276436805725 average_R:48.23754422664642
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.6208487), ('average_q2', 6.6540527), ('average_q_func1_loss', 2.9242612886428834), ('average_q_func2_loss', 2.915903859138489), ('n_updates', 344999), ('average_entropy', -1.0290835), ('temperature', 0.45920103788375854)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:356000 episode:31251 last_R: 52.870492458343506 average_R:48.53852459430695
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.916791), ('average_q2', 6.984659), ('average_q_func1_loss', 2.925252913236618), ('average_q_func2_loss', 2.9219144439697264), ('n_updates', 345999), ('average_entropy', -0.95879495), ('temperature', 0.4640592038631439)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:357000 episode:31265 last_R: 76.37666606903076 average_R:48.601808376312256
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.31471), ('average_q2', 7.128088), ('average_q_func1_loss', 2.832777372598648), ('average_q_func2_loss', 2.8128850269317627), ('n_updates', 346999), ('average_entropy', -0.93737197), ('temperature', 0.4687061011791229)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:358000 episode:31280 last_R: 38.21539068222046 average_R:49.065025296211246
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.95151), ('average_q2', 6.8386636), ('average_q_func1_loss', 2.8817978060245513), ('average_q_func2_loss', 2.881216630935669), ('n_updates', 347999), ('average_entropy', -0.9402206), ('temperature', 0.4689148962497711)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:359000 episode:31292 last_R: 39.178239583969116 average_R:48.20282009601593
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.9677367), ('average_q2', 6.764138), ('average_q_func1_loss', 2.941174569129944), ('average_q_func2_loss', 2.934490146636963), ('n_updates', 348999), ('average_entropy', -0.9495175), ('temperature', 0.47430387139320374)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:360000 episode:31309 last_R: 36.327906370162964 average_R:48.33175989151001
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.995095), ('average_q2', 6.873511), ('average_q_func1_loss', 3.0340556502342224), ('average_q_func2_loss', 3.0156774163246154), ('n_updates', 349999), ('average_entropy', -0.95414245), ('temperature', 0.4657948911190033)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:361000 episode:31322 last_R: 77.92407417297363 average_R:48.5337603020668
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.0887794), ('average_q2', 7.1276507), ('average_q_func1_loss', 2.866366637945175), ('average_q_func2_loss', 2.867269906997681), ('n_updates', 350999), ('average_entropy', -1.0194659), ('temperature', 0.4647469222545624)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:362000 episode:31335 last_R: 55.26879906654358 average_R:48.968012688159945
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.126724), ('average_q2', 7.1240964), ('average_q_func1_loss', 2.8401245462894438), ('average_q_func2_loss', 2.8402687096595765), ('n_updates', 351999), ('average_entropy', -1.0374947), ('temperature', 0.4701649248600006)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:363000 episode:31346 last_R: 43.0868616104126 average_R:50.381719245910645
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.715645), ('average_q2', 6.7549853), ('average_q_func1_loss', 2.9547399497032165), ('average_q_func2_loss', 2.952148572206497), ('n_updates', 352999), ('average_entropy', -1.0042884), ('temperature', 0.47334685921669006)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:364000 episode:31361 last_R: 52.337393045425415 average_R:49.958780689239504
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.33097), ('average_q2', 7.2670474), ('average_q_func1_loss', 2.916792709827423), ('average_q_func2_loss', 2.9151033639907835), ('n_updates', 353999), ('average_entropy', -1.0650343), ('temperature', 0.46916499733924866)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:365000 episode:31375 last_R: 57.94924211502075 average_R:49.650178382396696
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.9384413), ('average_q2', 6.893251), ('average_q_func1_loss', 2.895340390205383), ('average_q_func2_loss', 2.8784228456020355), ('n_updates', 354999), ('average_entropy', -1.00922), ('temperature', 0.47065281867980957)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:366000 episode:31390 last_R: 56.5316002368927 average_R:49.811983115673065
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.0292444), ('average_q2', 6.9743547), ('average_q_func1_loss', 2.9136869168281554), ('average_q_func2_loss', 2.912908353805542), ('n_updates', 355999), ('average_entropy', -1.0060064), ('temperature', 0.47278687357902527)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:367000 episode:31403 last_R: 76.49658441543579 average_R:50.390268659591676
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.339583), ('average_q2', 7.221426), ('average_q_func1_loss', 2.862172281742096), ('average_q_func2_loss', 2.8554296946525572), ('n_updates', 356999), ('average_entropy', -1.0242064), ('temperature', 0.46789294481277466)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:368000 episode:31416 last_R: 58.414209604263306 average_R:50.283127527236935
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.9771233), ('average_q2', 6.8558173), ('average_q_func1_loss', 2.9857596516609193), ('average_q_func2_loss', 2.9855552661418914), ('n_updates', 357999), ('average_entropy', -1.057848), ('temperature', 0.4698629379272461)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:369000 episode:31428 last_R: 60.80402112007141 average_R:51.19010095357895
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.431325), ('average_q2', 7.539179), ('average_q_func1_loss', 2.938152029514313), ('average_q_func2_loss', 2.9502488708496095), ('n_updates', 358999), ('average_entropy', -0.9583463), ('temperature', 0.47500303387641907)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:370000 episode:31442 last_R: 41.82291030883789 average_R:49.45816665649414
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.936852), ('average_q2', 6.93024), ('average_q_func1_loss', 2.9233632922172545), ('average_q_func2_loss', 2.924734878540039), ('n_updates', 359999), ('average_entropy', -1.0421621), ('temperature', 0.47185903787612915)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:371000 episode:31454 last_R: 64.16750645637512 average_R:50.59294676542282
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.960806), ('average_q2', 6.826633), ('average_q_func1_loss', 2.9649877381324767), ('average_q_func2_loss', 2.967070208787918), ('n_updates', 360999), ('average_entropy', -1.0342366), ('temperature', 0.47308459877967834)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:372000 episode:31468 last_R: 49.17917442321777 average_R:50.68235806941986
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.8765044), ('average_q2', 6.9905925), ('average_q_func1_loss', 2.9877830147743225), ('average_q_func2_loss', 2.9930663394927977), ('n_updates', 361999), ('average_entropy', -0.98013425), ('temperature', 0.47472307085990906)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:373000 episode:31483 last_R: 36.840463638305664 average_R:50.33078988790512
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.7634234), ('average_q2', 7.6065946), ('average_q_func1_loss', 3.0284456157684327), ('average_q_func2_loss', 3.0202241849899294), ('n_updates', 362999), ('average_entropy', -1.0716997), ('temperature', 0.4798485338687897)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:374000 episode:31496 last_R: 43.53489351272583 average_R:50.69688975095749
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.2619805), ('average_q2', 7.3088713), ('average_q_func1_loss', 2.8652662575244903), ('average_q_func2_loss', 2.8517180716991426), ('n_updates', 363999), ('average_entropy', -0.9528098), ('temperature', 0.4701864719390869)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:375000 episode:31511 last_R: 51.74616050720215 average_R:49.491507642269134
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.4643574), ('average_q2', 7.3450274), ('average_q_func1_loss', 2.9628443360328673), ('average_q_func2_loss', 2.9564714860916137), ('n_updates', 364999), ('average_entropy', -0.99489695), ('temperature', 0.4717130661010742)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 60 R: 60.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 98 R: 98.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 74 R: 74.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 76 R: 76.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 71 R: 71.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 61 R: 61.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 79 R: 79.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 57 R: 57.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 69 R: 69.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 80 R: 80.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 58 R: 58.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 88 R: 88.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 54 R: 54.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 68 R: 68.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 86 R: 86.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 54 R: 54.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 77 R: 77.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 59 R: 59.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 68 R: 68.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 58 R: 58.0
INFO:diayn_sim:true z: tensor([ 5, 11, 34,  0], device='cuda:0')
INFO:diayn_sim:disc z: tensor([46, 44, 17, 16])
INFO:diayn_sim:disc loss: 3.5143027305603027
INFO:diayn_sim:top extrinsic: [123. 213. 215. 297.]
INFO:diayn_sim:last intrinsic: [ 0.9138062   1.0232291   0.22280145 -0.5691557 ]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:376000 episode:31525 last_R: 56.42597436904907 average_R:48.60221623897552
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.2539797), ('average_q2', 7.2036977), ('average_q_func1_loss', 3.0155683183670043), ('average_q_func2_loss', 3.0209534204006196), ('n_updates', 365999), ('average_entropy', -1.0049726), ('temperature', 0.4751755893230438)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:377000 episode:31538 last_R: 40.30543398857117 average_R:47.81393874168396
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 6.3685412), ('average_q2', 6.3108892), ('average_q_func1_loss', 2.931670186519623), ('average_q_func2_loss', 2.927375626564026), ('n_updates', 366999), ('average_entropy', -0.9700936), ('temperature', 0.47959211468696594)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:378000 episode:31553 last_R: 59.48001313209534 average_R:47.172518842220306
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.161034), ('average_q2', 7.153281), ('average_q_func1_loss', 2.9302167534828185), ('average_q_func2_loss', 2.936494241952896), ('n_updates', 367999), ('average_entropy', -1.0189062), ('temperature', 0.47731220722198486)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:379000 episode:31568 last_R: 44.27199387550354 average_R:46.89927049636841
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.2424326), ('average_q2', 7.286951), ('average_q_func1_loss', 2.9782823061943056), ('average_q_func2_loss', 2.9693263506889345), ('n_updates', 368999), ('average_entropy', -1.0186284), ('temperature', 0.47914090752601624)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:380000 episode:31582 last_R: 41.12720775604248 average_R:47.425821685791014
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.588172), ('average_q2', 7.47564), ('average_q_func1_loss', 2.982614769935608), ('average_q_func2_loss', 2.971801359653473), ('n_updates', 369999), ('average_entropy', -1.0310596), ('temperature', 0.47500595450401306)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:381000 episode:31594 last_R: 52.752358198165894 average_R:47.81961276292801
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.154134), ('average_q2', 7.256006), ('average_q_func1_loss', 3.0330428099632263), ('average_q_func2_loss', 3.018904709815979), ('n_updates', 370999), ('average_entropy', -1.0000902), ('temperature', 0.4745745062828064)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:382000 episode:31606 last_R: 56.73812222480774 average_R:49.16989311218262
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.269929), ('average_q2', 7.2883377), ('average_q_func1_loss', 2.973639509677887), ('average_q_func2_loss', 2.966123814582825), ('n_updates', 371999), ('average_entropy', -1.037409), ('temperature', 0.47798269987106323)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:383000 episode:31618 last_R: 66.38173985481262 average_R:50.16634261608124
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.3537245), ('average_q2', 7.4233427), ('average_q_func1_loss', 2.8929546880722046), ('average_q_func2_loss', 2.8941891193389893), ('n_updates', 372999), ('average_entropy', -1.0052904), ('temperature', 0.48032909631729126)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:384000 episode:31632 last_R: 54.66544485092163 average_R:50.655076949596406
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.1364865), ('average_q2', 7.0795617), ('average_q_func1_loss', 3.0232444751262664), ('average_q_func2_loss', 2.9973857724666595), ('n_updates', 373999), ('average_entropy', -1.034012), ('temperature', 0.4819953739643097)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:385000 episode:31643 last_R: 56.68976593017578 average_R:51.54622481584549
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.2545238), ('average_q2', 7.0547304), ('average_q_func1_loss', 2.996704869270325), ('average_q_func2_loss', 2.998627724647522), ('n_updates', 374999), ('average_entropy', -1.0034035), ('temperature', 0.4832940995693207)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:386000 episode:31657 last_R: 34.264514207839966 average_R:51.50308261871338
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.6115284), ('average_q2', 7.5802355), ('average_q_func1_loss', 2.9524224853515624), ('average_q_func2_loss', 2.9553012371063234), ('n_updates', 375999), ('average_entropy', -1.031832), ('temperature', 0.48234736919403076)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:387000 episode:31671 last_R: 36.40689706802368 average_R:51.909028673171996
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.5901895), ('average_q2', 7.6980367), ('average_q_func1_loss', 2.9768578362464906), ('average_q_func2_loss', 2.968782081604004), ('n_updates', 376999), ('average_entropy', -1.0063876), ('temperature', 0.4827738404273987)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:388000 episode:31684 last_R: 59.19511365890503 average_R:51.97511039972305
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.187832), ('average_q2', 7.311514), ('average_q_func1_loss', 2.9510924077033995), ('average_q_func2_loss', 2.9573925852775576), ('n_updates', 377999), ('average_entropy', -0.9591101), ('temperature', 0.4850803017616272)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:389000 episode:31697 last_R: 48.34281849861145 average_R:51.39517948627472
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.623067), ('average_q2', 7.6106105), ('average_q_func1_loss', 3.025164135694504), ('average_q_func2_loss', 3.02980544090271), ('n_updates', 378999), ('average_entropy', -0.9807981), ('temperature', 0.4758451581001282)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:390000 episode:31710 last_R: 37.232372999191284 average_R:50.32316539287567
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.416052), ('average_q2', 7.397926), ('average_q_func1_loss', 3.008303678035736), ('average_q_func2_loss', 2.991531159877777), ('n_updates', 379999), ('average_entropy', -1.0253146), ('temperature', 0.48060470819473267)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:391000 episode:31725 last_R: 54.250539779663086 average_R:49.791801743507385
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.3219323), ('average_q2', 7.4241943), ('average_q_func1_loss', 2.8937686419487), ('average_q_func2_loss', 2.8914312720298767), ('n_updates', 380999), ('average_entropy', -0.9708868), ('temperature', 0.48787638545036316)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:392000 episode:31738 last_R: 60.36327600479126 average_R:49.899600117206575
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.2122655), ('average_q2', 7.0527062), ('average_q_func1_loss', 2.946621835231781), ('average_q_func2_loss', 2.9531723403930665), ('n_updates', 381999), ('average_entropy', -1.0447811), ('temperature', 0.4838732182979584)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:393000 episode:31752 last_R: 45.90931987762451 average_R:49.90370151996613
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.510704), ('average_q2', 7.3274865), ('average_q_func1_loss', 3.0478456139564516), ('average_q_func2_loss', 3.0332768201828), ('n_updates', 382999), ('average_entropy', -1.0233209), ('temperature', 0.48395103216171265)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:394000 episode:31766 last_R: 65.47631025314331 average_R:50.045299196243285
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.4682856), ('average_q2', 7.2795095), ('average_q_func1_loss', 2.919927335977554), ('average_q_func2_loss', 2.9338271164894105), ('n_updates', 383999), ('average_entropy', -0.9782124), ('temperature', 0.48183491826057434)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:395000 episode:31778 last_R: 44.03526949882507 average_R:50.04434940099716
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.5262823), ('average_q2', 7.400422), ('average_q_func1_loss', 3.0065683221817014), ('average_q_func2_loss', 3.0072903752326967), ('n_updates', 384999), ('average_entropy', -0.999356), ('temperature', 0.48349395394325256)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:396000 episode:31793 last_R: 22.674079418182373 average_R:49.59656807184219
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.2762537), ('average_q2', 7.121368), ('average_q_func1_loss', 3.037924201488495), ('average_q_func2_loss', 3.019101860523224), ('n_updates', 385999), ('average_entropy', -0.93009853), ('temperature', 0.4860053062438965)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:397000 episode:31804 last_R: 52.79528546333313 average_R:50.001310827732084
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.3085895), ('average_q2', 7.2616854), ('average_q_func1_loss', 3.0305416059494017), ('average_q_func2_loss', 3.0327633380889893), ('n_updates', 386999), ('average_entropy', -0.97157866), ('temperature', 0.4865420162677765)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:398000 episode:31819 last_R: 44.33999228477478 average_R:49.51279179573059
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.66105), ('average_q2', 7.645208), ('average_q_func1_loss', 2.972679166793823), ('average_q_func2_loss', 2.957344822883606), ('n_updates', 387999), ('average_entropy', -1.0280062), ('temperature', 0.4902990460395813)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:399000 episode:31832 last_R: 65.58963584899902 average_R:49.28123976945877
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.4930234), ('average_q2', 7.595742), ('average_q_func1_loss', 2.972120900154114), ('average_q_func2_loss', 2.9658033168315887), ('n_updates', 388999), ('average_entropy', -1.0831858), ('temperature', 0.48630112409591675)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:400000 episode:31844 last_R: 77.200510263443 average_R:50.549813187122346
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.3388715), ('average_q2', 7.520509), ('average_q_func1_loss', 3.0617386221885683), ('average_q_func2_loss', 3.073813930749893), ('n_updates', 389999), ('average_entropy', -1.0448233), ('temperature', 0.4885910153388977)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 50 R: 50.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 118 R: 118.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 60 R: 60.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 67 R: 67.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 84 R: 84.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 51 R: 51.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 72 R: 72.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 75 R: 75.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 72 R: 72.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 57 R: 57.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 74 R: 74.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 58 R: 58.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 68 R: 68.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 52 R: 52.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 62 R: 62.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 121 R: 121.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 77 R: 77.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 69 R: 69.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 81 R: 81.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 70 R: 70.0
INFO:diayn_sim:true z: tensor([17,  0,  0, 17], device='cuda:0')
INFO:diayn_sim:disc z: tensor([32, 10,  7, 33])
INFO:diayn_sim:disc loss: 3.9159207344055176
INFO:diayn_sim:top extrinsic: [230. 190. 186. 217.]
INFO:diayn_sim:last intrinsic: [ 0.67508507 -0.5691557  -0.5691557   0.4474349 ]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:401000 episode:31860 last_R: 54.202327251434326 average_R:49.191298117637636
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.7714667), ('average_q2', 7.5753317), ('average_q_func1_loss', 3.062909342050552), ('average_q_func2_loss', 3.044321756362915), ('n_updates', 390999), ('average_entropy', -0.9182317), ('temperature', 0.49157506227493286)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:402000 episode:31871 last_R: 35.464741945266724 average_R:48.58037129163742
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.6657596), ('average_q2', 7.578932), ('average_q_func1_loss', 3.0791767287254332), ('average_q_func2_loss', 3.0644371795654295), ('n_updates', 391999), ('average_entropy', -1.0215307), ('temperature', 0.48918455839157104)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:403000 episode:31885 last_R: 39.91605305671692 average_R:48.650007009506226
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.8023105), ('average_q2', 7.8309865), ('average_q_func1_loss', 3.0194422960281373), ('average_q_func2_loss', 3.0252800512313844), ('n_updates', 392999), ('average_entropy', -1.0762907), ('temperature', 0.4849031865596771)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:404000 episode:31899 last_R: 43.97106099128723 average_R:49.10130552053452
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.508492), ('average_q2', 7.380639), ('average_q_func1_loss', 2.9852048218250276), ('average_q_func2_loss', 2.978830238580704), ('n_updates', 393999), ('average_entropy', -0.9630404), ('temperature', 0.49005427956581116)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:405000 episode:31914 last_R: 36.78925657272339 average_R:48.96400863647461
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.4263997), ('average_q2', 7.3999104), ('average_q_func1_loss', 3.098706524372101), ('average_q_func2_loss', 3.0879363918304445), ('n_updates', 394999), ('average_entropy', -1.0014622), ('temperature', 0.4889441132545471)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:406000 episode:31927 last_R: 44.4978129863739 average_R:48.99879132509231
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.54026), ('average_q2', 7.4110117), ('average_q_func1_loss', 3.014136016368866), ('average_q_func2_loss', 3.0081617045402527), ('n_updates', 395999), ('average_entropy', -1.0425901), ('temperature', 0.4857107102870941)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:407000 episode:31938 last_R: 66.98643922805786 average_R:49.499723906517026
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.6626906), ('average_q2', 7.832333), ('average_q_func1_loss', 3.035499370098114), ('average_q_func2_loss', 3.0388271379470826), ('n_updates', 396999), ('average_entropy', -0.9272935), ('temperature', 0.49229663610458374)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:408000 episode:31951 last_R: 44.53117823600769 average_R:50.58791162252426
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.4162335), ('average_q2', 7.435969), ('average_q_func1_loss', 3.089748584032059), ('average_q_func2_loss', 3.0938465142250062), ('n_updates', 397999), ('average_entropy', -0.99164355), ('temperature', 0.4935687780380249)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:409000 episode:31962 last_R: 74.11620688438416 average_R:51.740007462501524
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.339358), ('average_q2', 7.970413), ('average_q_func1_loss', 3.0066410386562348), ('average_q_func2_loss', 3.0115383780002594), ('n_updates', 398999), ('average_entropy', -0.9781937), ('temperature', 0.49298039078712463)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:410000 episode:31975 last_R: 84.30534672737122 average_R:52.76368225812912
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.6627207), ('average_q2', 7.5351534), ('average_q_func1_loss', 3.036900808811188), ('average_q_func2_loss', 3.027856192588806), ('n_updates', 399999), ('average_entropy', -1.0271897), ('temperature', 0.4968532621860504)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:411000 episode:31988 last_R: 33.20633292198181 average_R:52.88356204748154
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.6230464), ('average_q2', 7.684301), ('average_q_func1_loss', 2.9899824512004853), ('average_q_func2_loss', 2.997880277633667), ('n_updates', 400999), ('average_entropy', -1.0549656), ('temperature', 0.49520182609558105)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:412000 episode:32000 last_R: 38.13008093833923 average_R:53.244208509922025
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.5711374), ('average_q2', 7.621207), ('average_q_func1_loss', 3.052581040859222), ('average_q_func2_loss', 3.059505717754364), ('n_updates', 401999), ('average_entropy', -1.000884), ('temperature', 0.4893077611923218)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:413000 episode:32013 last_R: 58.1575562953949 average_R:54.487807879447935
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.9741373), ('average_q2', 8.067675), ('average_q_func1_loss', 3.021797947883606), ('average_q_func2_loss', 3.0299101448059083), ('n_updates', 402999), ('average_entropy', -1.0303237), ('temperature', 0.49339988827705383)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:414000 episode:32027 last_R: 67.45027494430542 average_R:54.98570118188858
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.6667247), ('average_q2', 7.5516367), ('average_q_func1_loss', 3.0653007364273073), ('average_q_func2_loss', 3.0673131489753724), ('n_updates', 403999), ('average_entropy', -0.98184705), ('temperature', 0.49515098333358765)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:415000 episode:32041 last_R: 48.61351227760315 average_R:54.07425536632538
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.979475), ('average_q2', 8.00138), ('average_q_func1_loss', 3.0437905311584474), ('average_q_func2_loss', 3.0342814254760744), ('n_updates', 404999), ('average_entropy', -1.1042017), ('temperature', 0.4894322156906128)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:416000 episode:32055 last_R: 36.0752170085907 average_R:52.02768007278442
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.050635), ('average_q2', 8.024066), ('average_q_func1_loss', 3.011403594017029), ('average_q_func2_loss', 2.9946777057647704), ('n_updates', 405999), ('average_entropy', -1.0223303), ('temperature', 0.4940359592437744)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:417000 episode:32068 last_R: 36.58995270729065 average_R:51.77890221118927
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.149997), ('average_q2', 8.146159), ('average_q_func1_loss', 2.9568515324592592), ('average_q_func2_loss', 2.958320574760437), ('n_updates', 406999), ('average_entropy', -1.056475), ('temperature', 0.4912451207637787)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:418000 episode:32082 last_R: 32.49229383468628 average_R:51.224872136116026
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.5373936), ('average_q2', 7.400534), ('average_q_func1_loss', 3.071426889896393), ('average_q_func2_loss', 3.0630878472328185), ('n_updates', 407999), ('average_entropy', -1.0207006), ('temperature', 0.4910319745540619)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:419000 episode:32097 last_R: 47.21222496032715 average_R:50.53259668588638
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.964761), ('average_q2', 7.911641), ('average_q_func1_loss', 3.021182279586792), ('average_q_func2_loss', 3.008537962436676), ('n_updates', 408999), ('average_entropy', -1.0732697), ('temperature', 0.4980567991733551)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:420000 episode:32110 last_R: 51.54384183883667 average_R:49.77412546157837
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.8622413), ('average_q2', 7.883693), ('average_q_func1_loss', 3.0733893513679504), ('average_q_func2_loss', 3.0706211280822755), ('n_updates', 409999), ('average_entropy', -1.000211), ('temperature', 0.49467921257019043)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:421000 episode:32121 last_R: 29.944793701171875 average_R:50.21883275032044
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.5945168), ('average_q2', 7.5540133), ('average_q_func1_loss', 3.0492713761329653), ('average_q_func2_loss', 3.0605596220493316), ('n_updates', 410999), ('average_entropy', -0.99080247), ('temperature', 0.4958038032054901)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:422000 episode:32134 last_R: 87.60527777671814 average_R:51.16793510913849
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.5589933), ('average_q2', 7.4286356), ('average_q_func1_loss', 3.104845049381256), ('average_q_func2_loss', 3.1047585105895994), ('n_updates', 411999), ('average_entropy', -1.0239407), ('temperature', 0.49594226479530334)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:423000 episode:32147 last_R: 41.70154881477356 average_R:51.597500772476195
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.095312), ('average_q2', 8.3144245), ('average_q_func1_loss', 2.9653394412994385), ('average_q_func2_loss', 2.9698826551437376), ('n_updates', 412999), ('average_entropy', -1.0112225), ('temperature', 0.4956844747066498)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:424000 episode:32161 last_R: 45.840378284454346 average_R:51.14058478832245
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.926465), ('average_q2', 8.011618), ('average_q_func1_loss', 3.0728636956214905), ('average_q_func2_loss', 3.0752509117126463), ('n_updates', 413999), ('average_entropy', -0.9938693), ('temperature', 0.4949420988559723)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:425000 episode:32173 last_R: 29.938299894332886 average_R:50.889078605175015
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.675726), ('average_q2', 7.781463), ('average_q_func1_loss', 3.099058644771576), ('average_q_func2_loss', 3.1039356207847595), ('n_updates', 414999), ('average_entropy', -0.98988515), ('temperature', 0.5001351237297058)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 94 R: 94.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 69 R: 69.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 130 R: 130.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 73 R: 73.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 68 R: 68.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 84 R: 84.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 72 R: 72.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 80 R: 80.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 56 R: 56.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 72 R: 72.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 72 R: 72.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 79 R: 79.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 55 R: 55.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 62 R: 62.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 81 R: 81.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 59 R: 59.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 79 R: 79.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 163 R: 163.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 85 R: 85.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 63 R: 63.0
INFO:diayn_sim:true z: tensor([26,  5, 26,  5], device='cuda:0')
INFO:diayn_sim:disc z: tensor([28,  6, 21, 16])
INFO:diayn_sim:disc loss: 3.0767555236816406
INFO:diayn_sim:top extrinsic: [166. 272. 210. 134.]
INFO:diayn_sim:last intrinsic: [ 1.2719033   1.6221545   0.9504237  -0.50361156]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:426000 episode:32186 last_R: 60.85425519943237 average_R:51.44209964513779
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.23392), ('average_q2', 8.025866), ('average_q_func1_loss', 3.0839269804954528), ('average_q_func2_loss', 3.0801175308227537), ('n_updates', 415999), ('average_entropy', -1.0156949), ('temperature', 0.5034200549125671)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:427000 episode:32200 last_R: 33.444390535354614 average_R:51.41633520364761
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.6091933), ('average_q2', 7.835766), ('average_q_func1_loss', 3.0837152862548827), ('average_q_func2_loss', 3.0662805330753327), ('n_updates', 416999), ('average_entropy', -1.0073873), ('temperature', 0.4943442940711975)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:428000 episode:32213 last_R: 105.0743477344513 average_R:50.7344818854332
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.005822), ('average_q2', 7.954387), ('average_q_func1_loss', 3.0952902472019197), ('average_q_func2_loss', 3.10160880446434), ('n_updates', 417999), ('average_entropy', -0.93819886), ('temperature', 0.49557578563690186)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:429000 episode:32225 last_R: 41.318963050842285 average_R:49.837225914001465
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.65076), ('average_q2', 7.803285), ('average_q_func1_loss', 3.1032285261154176), ('average_q_func2_loss', 3.0963221979141236), ('n_updates', 418999), ('average_entropy', -0.9639274), ('temperature', 0.4994271993637085)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:430000 episode:32240 last_R: 45.92847180366516 average_R:50.24935927391052
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.30411), ('average_q2', 8.073409), ('average_q_func1_loss', 3.093663215637207), ('average_q_func2_loss', 3.1028363728523254), ('n_updates', 419999), ('average_entropy', -0.98385084), ('temperature', 0.49653005599975586)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:431000 episode:32251 last_R: 46.58410906791687 average_R:50.67830308198929
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.013107), ('average_q2', 8.117086), ('average_q_func1_loss', 3.098507902622223), ('average_q_func2_loss', 3.0917211389541626), ('n_updates', 420999), ('average_entropy', -1.0050262), ('temperature', 0.4912150502204895)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:432000 episode:32263 last_R: 32.50587201118469 average_R:51.41306316137314
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.8652864), ('average_q2', 7.633995), ('average_q_func1_loss', 3.13632346868515), ('average_q_func2_loss', 3.124502217769623), ('n_updates', 421999), ('average_entropy', -0.96942055), ('temperature', 0.49964237213134766)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:433000 episode:32273 last_R: 52.45193362236023 average_R:52.2219516158104
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.886388), ('average_q2', 7.8659863), ('average_q_func1_loss', 2.985842936038971), ('average_q_func2_loss', 2.9862120378017427), ('n_updates', 422999), ('average_entropy', -1.0363657), ('temperature', 0.5004240870475769)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:434000 episode:32286 last_R: 55.581629276275635 average_R:52.35517106771469
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.141772), ('average_q2', 8.032482), ('average_q_func1_loss', 3.161607151031494), ('average_q_func2_loss', 3.170232102870941), ('n_updates', 423999), ('average_entropy', -1.0451438), ('temperature', 0.5011921525001526)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:435000 episode:32300 last_R: 56.847665548324585 average_R:53.24613984823227
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.087327), ('average_q2', 8.059606), ('average_q_func1_loss', 3.0875133049488066), ('average_q_func2_loss', 3.0994923627376556), ('n_updates', 424999), ('average_entropy', -1.0528108), ('temperature', 0.5008458495140076)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:436000 episode:32312 last_R: 64.30815958976746 average_R:54.40918791294098
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.266994), ('average_q2', 8.331993), ('average_q_func1_loss', 3.1131385469436648), ('average_q_func2_loss', 3.120059962272644), ('n_updates', 425999), ('average_entropy', -0.9823296), ('temperature', 0.5046462416648865)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:437000 episode:32323 last_R: 43.53894257545471 average_R:54.61237412214279
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.226691), ('average_q2', 8.081618), ('average_q_func1_loss', 3.0368759179115297), ('average_q_func2_loss', 3.0308941864967345), ('n_updates', 426999), ('average_entropy', -1.0388249), ('temperature', 0.5013957023620605)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:438000 episode:32334 last_R: 61.64304208755493 average_R:55.5033851647377
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.282326), ('average_q2', 8.247369), ('average_q_func1_loss', 3.070127799510956), ('average_q_func2_loss', 3.07047287940979), ('n_updates', 427999), ('average_entropy', -0.96140134), ('temperature', 0.5003678202629089)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:439000 episode:32347 last_R: 34.99324417114258 average_R:54.96106833219528
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.126139), ('average_q2', 8.160917), ('average_q_func1_loss', 3.096723909378052), ('average_q_func2_loss', 3.0973416244983674), ('n_updates', 428999), ('average_entropy', -1.0233778), ('temperature', 0.5047154426574707)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:440000 episode:32359 last_R: 37.446277379989624 average_R:55.89954562187195
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.5473495), ('average_q2', 7.6229963), ('average_q_func1_loss', 3.0830783081054687), ('average_q_func2_loss', 3.073920673131943), ('n_updates', 429999), ('average_entropy', -1.0240908), ('temperature', 0.5048647522926331)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:441000 episode:32371 last_R: 62.00060820579529 average_R:55.01920437335968
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.440422), ('average_q2', 8.353303), ('average_q_func1_loss', 3.1528857517242432), ('average_q_func2_loss', 3.1328684449195863), ('n_updates', 430999), ('average_entropy', -1.1327633), ('temperature', 0.5017942190170288)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:442000 episode:32384 last_R: 31.91083550453186 average_R:55.33427887439728
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.004935), ('average_q2', 8.199097), ('average_q_func1_loss', 2.967112853527069), ('average_q_func2_loss', 2.968290395736694), ('n_updates', 431999), ('average_entropy', -0.98776245), ('temperature', 0.49967336654663086)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:443000 episode:32398 last_R: 39.11614799499512 average_R:54.4865403342247
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.390836), ('average_q2', 8.2483), ('average_q_func1_loss', 3.067111974954605), ('average_q_func2_loss', 3.073147143125534), ('n_updates', 432999), ('average_entropy', -1.0130395), ('temperature', 0.4979148209095001)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:444000 episode:32408 last_R: 51.464757442474365 average_R:55.02776371955871
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.9979405), ('average_q2', 7.746006), ('average_q_func1_loss', 3.1385148859024046), ('average_q_func2_loss', 3.14890793800354), ('n_updates', 433999), ('average_entropy', -0.9580844), ('temperature', 0.4992820620536804)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:445000 episode:32420 last_R: 48.54930520057678 average_R:54.219786856174466
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.02837), ('average_q2', 8.056699), ('average_q_func1_loss', 3.072294888496399), ('average_q_func2_loss', 3.085869646072388), ('n_updates', 434999), ('average_entropy', -0.9929396), ('temperature', 0.5001581311225891)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:446000 episode:32434 last_R: 58.115227460861206 average_R:53.37680496454239
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.036101), ('average_q2', 8.026429), ('average_q_func1_loss', 3.257585608959198), ('average_q_func2_loss', 3.2480303287506103), ('n_updates', 435999), ('average_entropy', -1.0026414), ('temperature', 0.504210889339447)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:447000 episode:32445 last_R: 58.91697645187378 average_R:53.64251210212708
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.42101), ('average_q2', 8.584044), ('average_q_func1_loss', 3.089693162441254), ('average_q_func2_loss', 3.093292090892792), ('n_updates', 436999), ('average_entropy', -1.0480214), ('temperature', 0.5028504729270935)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:448000 episode:32459 last_R: 93.15332221984863 average_R:52.438557000160216
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.204152), ('average_q2', 8.305476), ('average_q_func1_loss', 3.1553769278526307), ('average_q_func2_loss', 3.162973606586456), ('n_updates', 437999), ('average_entropy', -0.9689131), ('temperature', 0.5027860403060913)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:449000 episode:32471 last_R: 40.26800227165222 average_R:52.4282260131836
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.250281), ('average_q2', 8.231683), ('average_q_func1_loss', 3.157843778133392), ('average_q_func2_loss', 3.1587686240673065), ('n_updates', 438999), ('average_entropy', -0.9996892), ('temperature', 0.5000367760658264)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:450000 episode:32481 last_R: 63.890368700027466 average_R:52.53231265544891
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.775513), ('average_q2', 7.9615965), ('average_q_func1_loss', 3.0549204921722413), ('average_q_func2_loss', 3.0449870121479035), ('n_updates', 439999), ('average_entropy', -0.98801744), ('temperature', 0.5000125169754028)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 40 R: 40.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 49 R: 49.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 51 R: 51.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 51 R: 51.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 66 R: 66.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 50 R: 50.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 64 R: 64.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 52 R: 52.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 50 R: 50.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 75 R: 75.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 63 R: 63.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 60 R: 60.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 69 R: 69.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 56 R: 56.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 68 R: 68.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 62 R: 62.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 49 R: 49.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 66 R: 66.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 71 R: 71.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 75 R: 75.0
INFO:diayn_sim:true z: tensor([ 4, 14,  3, 48], device='cuda:0')
INFO:diayn_sim:disc z: tensor([ 1, 36, 13, 47])
INFO:diayn_sim:disc loss: 3.2161104679107666
INFO:diayn_sim:top extrinsic: [119. 218. 244. 178.]
INFO:diayn_sim:last intrinsic: [ 1.4339182   0.69657683 -0.5689812   1.2219353 ]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:451000 episode:32493 last_R: 61.18326258659363 average_R:53.51526470661163
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.149601), ('average_q2', 8.000322), ('average_q_func1_loss', 3.0669255447387695), ('average_q_func2_loss', 3.064566671848297), ('n_updates', 440999), ('average_entropy', -1.0038445), ('temperature', 0.5019909143447876)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:452000 episode:32507 last_R: 50.24782395362854 average_R:53.61228697538376
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.190997), ('average_q2', 8.258903), ('average_q_func1_loss', 3.1711119031906128), ('average_q_func2_loss', 3.15069908618927), ('n_updates', 441999), ('average_entropy', -1.0085326), ('temperature', 0.5001691579818726)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:453000 episode:32517 last_R: 83.24474453926086 average_R:54.84953962802887
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.895827), ('average_q2', 7.944481), ('average_q_func1_loss', 3.1312834429740906), ('average_q_func2_loss', 3.121358094215393), ('n_updates', 442999), ('average_entropy', -0.97347695), ('temperature', 0.499956339597702)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:454000 episode:32527 last_R: 50.769819021224976 average_R:55.49626583814621
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.8234105), ('average_q2', 7.928226), ('average_q_func1_loss', 3.2223040103912353), ('average_q_func2_loss', 3.204848356246948), ('n_updates', 443999), ('average_entropy', -1.0323685), ('temperature', 0.4948524832725525)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:455000 episode:32539 last_R: 42.775248527526855 average_R:56.08183157920838
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.8993464), ('average_q2', 8.102827), ('average_q_func1_loss', 3.129367768764496), ('average_q_func2_loss', 3.115408000946045), ('n_updates', 444999), ('average_entropy', -0.9972301), ('temperature', 0.506921112537384)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:456000 episode:32552 last_R: 43.689857959747314 average_R:55.845633556842806
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.239533), ('average_q2', 8.382545), ('average_q_func1_loss', 3.2077279043197633), ('average_q_func2_loss', 3.1989099884033205), ('n_updates', 445999), ('average_entropy', -1.0335872), ('temperature', 0.4974600076675415)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:457000 episode:32562 last_R: 65.11915898323059 average_R:57.60590755701065
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.289344), ('average_q2', 8.132113), ('average_q_func1_loss', 3.1959757661819457), ('average_q_func2_loss', 3.1915807247161867), ('n_updates', 446999), ('average_entropy', -1.0330819), ('temperature', 0.5015408992767334)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:458000 episode:32574 last_R: 36.23267674446106 average_R:57.602804069519046
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.201053), ('average_q2', 8.079108), ('average_q_func1_loss', 3.137151435613632), ('average_q_func2_loss', 3.1252740693092345), ('n_updates', 447999), ('average_entropy', -0.9955801), ('temperature', 0.49721047282218933)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:459000 episode:32586 last_R: 32.893309116363525 average_R:58.22051434278488
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.365428), ('average_q2', 8.30593), ('average_q_func1_loss', 3.1718171215057374), ('average_q_func2_loss', 3.1606863284111024), ('n_updates', 448999), ('average_entropy', -1.006679), ('temperature', 0.5056697726249695)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:460000 episode:32600 last_R: 49.147886991500854 average_R:57.15353685855865
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.338494), ('average_q2', 8.467149), ('average_q_func1_loss', 3.0474904108047487), ('average_q_func2_loss', 3.048168432712555), ('n_updates', 449999), ('average_entropy', -0.96493745), ('temperature', 0.5069544315338135)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:461000 episode:32609 last_R: 36.87502479553223 average_R:58.13477435827255
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.05771), ('average_q2', 7.9940023), ('average_q_func1_loss', 3.0769833731651306), ('average_q_func2_loss', 3.0726587986946106), ('n_updates', 450999), ('average_entropy', -0.9907996), ('temperature', 0.5081904530525208)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:462000 episode:32620 last_R: 62.54307556152344 average_R:57.57740512132645
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.243929), ('average_q2', 8.191188), ('average_q_func1_loss', 3.096554057598114), ('average_q_func2_loss', 3.0975166082382204), ('n_updates', 451999), ('average_entropy', -0.9698123), ('temperature', 0.5050352811813354)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:463000 episode:32634 last_R: 92.16617178916931 average_R:56.355169348716736
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.406895), ('average_q2', 8.523408), ('average_q_func1_loss', 3.14324609041214), ('average_q_func2_loss', 3.1278343033790588), ('n_updates', 452999), ('average_entropy', -0.9798011), ('temperature', 0.5026750564575195)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:464000 episode:32645 last_R: 48.16209697723389 average_R:56.46032806873322
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.997186), ('average_q2', 8.117983), ('average_q_func1_loss', 3.123053057193756), ('average_q_func2_loss', 3.117441190481186), ('n_updates', 453999), ('average_entropy', -1.02482), ('temperature', 0.49928268790245056)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:465000 episode:32657 last_R: 38.9120454788208 average_R:57.377877352237704
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.983793), ('average_q2', 8.304338), ('average_q_func1_loss', 3.106160101890564), ('average_q_func2_loss', 3.1054172992706297), ('n_updates', 454999), ('average_entropy', -0.9701648), ('temperature', 0.5013159513473511)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:466000 episode:32669 last_R: 38.232017517089844 average_R:56.2544186592102
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.364623), ('average_q2', 8.368776), ('average_q_func1_loss', 3.0974719429016115), ('average_q_func2_loss', 3.0864616942405703), ('n_updates', 455999), ('average_entropy', -0.915495), ('temperature', 0.5020204186439514)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:467000 episode:32681 last_R: 29.478274822235107 average_R:55.227926931381226
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.630265), ('average_q2', 8.618974), ('average_q_func1_loss', 3.120357642173767), ('average_q_func2_loss', 3.1041551661491393), ('n_updates', 456999), ('average_entropy', -0.97509235), ('temperature', 0.49716728925704956)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:468000 episode:32692 last_R: 45.894827127456665 average_R:56.20093547105789
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.826128), ('average_q2', 8.636512), ('average_q_func1_loss', 3.116637125015259), ('average_q_func2_loss', 3.091339988708496), ('n_updates', 457999), ('average_entropy', -0.9972816), ('temperature', 0.5002301335334778)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:469000 episode:32706 last_R: 45.82747268676758 average_R:55.44801849603653
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 7.9463477), ('average_q2', 7.997225), ('average_q_func1_loss', 3.1571293377876284), ('average_q_func2_loss', 3.15087193608284), ('n_updates', 458999), ('average_entropy', -0.9245151), ('temperature', 0.5084352493286133)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:470000 episode:32716 last_R: 33.68828845024109 average_R:55.531790590286256
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.436703), ('average_q2', 8.510131), ('average_q_func1_loss', 3.11676522731781), ('average_q_func2_loss', 3.1226820945739746), ('n_updates', 459999), ('average_entropy', -1.0054384), ('temperature', 0.5064877271652222)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:471000 episode:32725 last_R: 60.98509693145752 average_R:57.196057991981505
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.694226), ('average_q2', 8.407722), ('average_q_func1_loss', 3.1243912053108214), ('average_q_func2_loss', 3.1291195702552796), ('n_updates', 460999), ('average_entropy', -1.0637535), ('temperature', 0.50732421875)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:472000 episode:32738 last_R: 70.41140222549438 average_R:57.715527215003966
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.577009), ('average_q2', 8.555533), ('average_q_func1_loss', 3.165841817855835), ('average_q_func2_loss', 3.1730129432678225), ('n_updates', 461999), ('average_entropy', -1.0090635), ('temperature', 0.5072274804115295)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:473000 episode:32751 last_R: 47.127400636672974 average_R:57.19680378675461
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.4963455), ('average_q2', 8.398355), ('average_q_func1_loss', 3.2945375752449038), ('average_q_func2_loss', 3.280402512550354), ('n_updates', 462999), ('average_entropy', -0.9940219), ('temperature', 0.5051597952842712)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:474000 episode:32764 last_R: 38.01583290100098 average_R:56.679532392024996
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.820092), ('average_q2', 8.803861), ('average_q_func1_loss', 3.1471635627746584), ('average_q_func2_loss', 3.1556373381614686), ('n_updates', 463999), ('average_entropy', -1.0494671), ('temperature', 0.5008641481399536)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:475000 episode:32777 last_R: 47.64318537712097 average_R:55.908752455711365
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.721297), ('average_q2', 8.480546), ('average_q_func1_loss', 3.3951714634895325), ('average_q_func2_loss', 3.37214821100235), ('n_updates', 464999), ('average_entropy', -1.0301672), ('temperature', 0.5106867551803589)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 85 R: 85.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 135 R: 135.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 170 R: 170.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 61 R: 61.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 89 R: 89.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 73 R: 73.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 102 R: 102.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 87 R: 87.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 77 R: 77.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 105 R: 105.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 89 R: 89.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 101 R: 101.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 77 R: 77.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 97 R: 97.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 121 R: 121.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 142 R: 142.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 73 R: 73.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 126 R: 126.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 101 R: 101.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 84 R: 84.0
INFO:diayn_sim:true z: tensor([28,  9,  8,  4], device='cuda:0')
INFO:diayn_sim:disc z: tensor([35, 36, 47, 26])
INFO:diayn_sim:disc loss: 3.340658664703369
INFO:diayn_sim:top extrinsic: [166. 203. 372. 164.]
INFO:diayn_sim:last intrinsic: [ 0.65882325  0.96171093  1.2323523  -0.5676298 ]
INFO:pfrl.experiments.train_agent_batch:The best score is updated 89.4 -> 99.75
INFO:pfrl.experiments.train_agent_batch:Saved the agent to results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a/best
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:476000 episode:32787 last_R: 74.51481509208679 average_R:57.66476632356644
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.262032), ('average_q2', 8.243104), ('average_q_func1_loss', 3.147147283554077), ('average_q_func2_loss', 3.1502325642108917), ('n_updates', 465999), ('average_entropy', -1.0029849), ('temperature', 0.5039626955986023)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:477000 episode:32797 last_R: 68.1377809047699 average_R:56.87470996379852
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.668837), ('average_q2', 8.48283), ('average_q_func1_loss', 3.2356634378433227), ('average_q_func2_loss', 3.228519501686096), ('n_updates', 466999), ('average_entropy', -0.99149644), ('temperature', 0.5060387849807739)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:478000 episode:32808 last_R: 56.85589933395386 average_R:58.6548006939888
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.197594), ('average_q2', 8.286078), ('average_q_func1_loss', 3.134458932876587), ('average_q_func2_loss', 3.139156792163849), ('n_updates', 467999), ('average_entropy', -0.98394614), ('temperature', 0.5040783286094666)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:479000 episode:32819 last_R: 71.88010501861572 average_R:58.18230820178986
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.804361), ('average_q2', 8.851717), ('average_q_func1_loss', 3.2091668176651003), ('average_q_func2_loss', 3.20428071975708), ('n_updates', 468999), ('average_entropy', -0.98439026), ('temperature', 0.5061293244361877)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:480000 episode:32832 last_R: 47.9667010307312 average_R:57.06780366182327
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.226734), ('average_q2', 8.223933), ('average_q_func1_loss', 3.1393403816223144), ('average_q_func2_loss', 3.136367075443268), ('n_updates', 469999), ('average_entropy', -1.001257), ('temperature', 0.5011457204818726)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:481000 episode:32841 last_R: 47.10960125923157 average_R:57.16091947555542
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.779463), ('average_q2', 8.798017), ('average_q_func1_loss', 3.1757330012321474), ('average_q_func2_loss', 3.1631946682929994), ('n_updates', 470999), ('average_entropy', -1.0915195), ('temperature', 0.5061823129653931)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:482000 episode:32852 last_R: 70.46106386184692 average_R:59.15855270862579
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.28767), ('average_q2', 8.473493), ('average_q_func1_loss', 3.2037938332557676), ('average_q_func2_loss', 3.198607094287872), ('n_updates', 471999), ('average_entropy', -1.0246445), ('temperature', 0.5064166784286499)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:483000 episode:32864 last_R: 34.9221887588501 average_R:59.98142519235611
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.770332), ('average_q2', 8.605297), ('average_q_func1_loss', 2.9878493583202363), ('average_q_func2_loss', 2.9756365704536436), ('n_updates', 472999), ('average_entropy', -0.9682484), ('temperature', 0.5085347294807434)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:484000 episode:32876 last_R: 36.715184450149536 average_R:60.74550525903702
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.579111), ('average_q2', 8.385426), ('average_q_func1_loss', 3.1275548553466797), ('average_q_func2_loss', 3.118871171474457), ('n_updates', 473999), ('average_entropy', -0.99806803), ('temperature', 0.5036362409591675)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:485000 episode:32885 last_R: 96.3067741394043 average_R:61.43103582143784
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.604983), ('average_q2', 8.743842), ('average_q_func1_loss', 3.181075221300125), ('average_q_func2_loss', 3.1464313006401063), ('n_updates', 474999), ('average_entropy', -1.0213006), ('temperature', 0.5055462121963501)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:486000 episode:32897 last_R: 105.50185441970825 average_R:60.63708686828613
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.79254), ('average_q2', 8.907559), ('average_q_func1_loss', 3.2051586258411406), ('average_q_func2_loss', 3.179309561252594), ('n_updates', 475999), ('average_entropy', -1.0070158), ('temperature', 0.5107431411743164)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:487000 episode:32908 last_R: 61.26127052307129 average_R:59.90099264383316
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.558355), ('average_q2', 8.595814), ('average_q_func1_loss', 3.1439039301872254), ('average_q_func2_loss', 3.1506501960754396), ('n_updates', 476999), ('average_entropy', -1.0360078), ('temperature', 0.5110020041465759)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:488000 episode:32919 last_R: 62.79164671897888 average_R:59.931834723949436
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.76568), ('average_q2', 8.852639), ('average_q_func1_loss', 3.191089000701904), ('average_q_func2_loss', 3.19008092880249), ('n_updates', 477999), ('average_entropy', -0.9768798), ('temperature', 0.4994650185108185)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:489000 episode:32929 last_R: 106.81624436378479 average_R:59.5266446018219
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.742305), ('average_q2', 8.813046), ('average_q_func1_loss', 3.219906451702118), ('average_q_func2_loss', 3.191810176372528), ('n_updates', 478999), ('average_entropy', -1.0026832), ('temperature', 0.5066161751747131)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:490000 episode:32938 last_R: 49.3500862121582 average_R:61.37206950187683
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.617937), ('average_q2', 8.481149), ('average_q_func1_loss', 3.1509806740283968), ('average_q_func2_loss', 3.1512642240524293), ('n_updates', 479999), ('average_entropy', -1.019071), ('temperature', 0.5065550208091736)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:491000 episode:32948 last_R: 92.71201682090759 average_R:61.49526888847351
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.881276), ('average_q2', 9.021053), ('average_q_func1_loss', 3.212565517425537), ('average_q_func2_loss', 3.203512725830078), ('n_updates', 480999), ('average_entropy', -1.0715442), ('temperature', 0.49979063868522644)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:492000 episode:32956 last_R: 77.93474555015564 average_R:63.018794610500336
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.828385), ('average_q2', 8.804575), ('average_q_func1_loss', 3.1907204532623292), ('average_q_func2_loss', 3.190861020088196), ('n_updates', 481999), ('average_entropy', -0.9906706), ('temperature', 0.5029399991035461)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:493000 episode:32966 last_R: 83.1308901309967 average_R:64.151307554245
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.845746), ('average_q2', 8.937703), ('average_q_func1_loss', 3.2078599333763123), ('average_q_func2_loss', 3.193678092956543), ('n_updates', 482999), ('average_entropy', -1.0074521), ('temperature', 0.5071051120758057)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:494000 episode:32976 last_R: 87.20784449577332 average_R:64.51780913829803
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.900718), ('average_q2', 8.938205), ('average_q_func1_loss', 3.1779142415523527), ('average_q_func2_loss', 3.1824527180194853), ('n_updates', 483999), ('average_entropy', -0.9975149), ('temperature', 0.5086750388145447)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:495000 episode:32986 last_R: 89.56934785842896 average_R:65.23347070217133
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.151423), ('average_q2', 9.085164), ('average_q_func1_loss', 3.1803549575805663), ('average_q_func2_loss', 3.184001138210297), ('n_updates', 484999), ('average_entropy', -1.0382959), ('temperature', 0.5052292943000793)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:496000 episode:32996 last_R: 100.32566666603088 average_R:66.40661820173264
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.844565), ('average_q2', 8.948238), ('average_q_func1_loss', 3.2665530586242677), ('average_q_func2_loss', 3.2536045026779177), ('n_updates', 485999), ('average_entropy', -1.0221833), ('temperature', 0.5014529228210449)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:497000 episode:33009 last_R: 81.49004077911377 average_R:66.68147769451141
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.2504), ('average_q2', 9.283102), ('average_q_func1_loss', 3.153572750091553), ('average_q_func2_loss', 3.14988600730896), ('n_updates', 486999), ('average_entropy', -1.0055747), ('temperature', 0.5044918060302734)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:498000 episode:33017 last_R: 109.39930152893066 average_R:68.50630952835083
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.617861), ('average_q2', 8.783839), ('average_q_func1_loss', 3.2841711711883543), ('average_q_func2_loss', 3.2676500940322875), ('n_updates', 487999), ('average_entropy', -1.0392587), ('temperature', 0.5041295289993286)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:499000 episode:33027 last_R: 50.756855487823486 average_R:69.21780800580979
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.826813), ('average_q2', 8.745233), ('average_q_func1_loss', 3.2217607522010803), ('average_q_func2_loss', 3.2217575812339785), ('n_updates', 488999), ('average_entropy', -1.0179408), ('temperature', 0.5073927640914917)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:500000 episode:33038 last_R: 49.533064126968384 average_R:67.25385143518447
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.2770605), ('average_q2', 9.388994), ('average_q_func1_loss', 3.248111720085144), ('average_q_func2_loss', 3.2440602588653564), ('n_updates', 489999), ('average_entropy', -1.0026019), ('temperature', 0.5101706385612488)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 56 R: 56.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 61 R: 61.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 64 R: 64.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 49 R: 49.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 70 R: 70.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 79 R: 79.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 60 R: 60.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 73 R: 73.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 77 R: 77.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 79 R: 79.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 106 R: 106.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 83 R: 83.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 77 R: 77.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 54 R: 54.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 72 R: 72.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 88 R: 88.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 87 R: 87.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 76 R: 76.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 90 R: 90.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 113 R: 113.0
INFO:diayn_sim:true z: tensor([ 0, 29, 13, 28], device='cuda:0')
INFO:diayn_sim:disc z: tensor([ 3, 25, 36, 24])
INFO:diayn_sim:disc loss: 2.7720870971679688
INFO:diayn_sim:top extrinsic: [241. 214. 220. 273.]
INFO:diayn_sim:last intrinsic: [1.4308441 1.1297143 0.8252585 1.1737266]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:501000 episode:33048 last_R: 56.82634162902832 average_R:65.96460896492005
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.872617), ('average_q2', 8.889947), ('average_q_func1_loss', 3.214664926528931), ('average_q_func2_loss', 3.209269063472748), ('n_updates', 490999), ('average_entropy', -0.9668211), ('temperature', 0.507845938205719)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:502000 episode:33058 last_R: 52.949607849121094 average_R:64.06813184261323
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.858631), ('average_q2', 9.138394), ('average_q_func1_loss', 3.205181484222412), ('average_q_func2_loss', 3.199570484161377), ('n_updates', 491999), ('average_entropy', -0.9098478), ('temperature', 0.5046378374099731)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:503000 episode:33064 last_R: 120.46011972427368 average_R:65.3148953795433
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.032367), ('average_q2', 9.014998), ('average_q_func1_loss', 3.289389386177063), ('average_q_func2_loss', 3.2662394976615907), ('n_updates', 492999), ('average_entropy', -1.0114717), ('temperature', 0.5058844685554504)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:504000 episode:33076 last_R: 30.595271348953247 average_R:67.1184623837471
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.862344), ('average_q2', 8.800477), ('average_q_func1_loss', 3.2016943538188936), ('average_q_func2_loss', 3.184046995639801), ('n_updates', 493999), ('average_entropy', -0.9986236), ('temperature', 0.5139306783676147)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:505000 episode:33086 last_R: 51.46354961395264 average_R:66.20780941009521
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.993911), ('average_q2', 8.842149), ('average_q_func1_loss', 3.2502512311935425), ('average_q_func2_loss', 3.249618411064148), ('n_updates', 494999), ('average_entropy', -0.96900856), ('temperature', 0.5020478963851929)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:506000 episode:33095 last_R: 88.78173828125 average_R:67.69837907075882
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.661062), ('average_q2', 8.6118965), ('average_q_func1_loss', 3.241588840484619), ('average_q_func2_loss', 3.2355124592781066), ('n_updates', 495999), ('average_entropy', -0.9244618), ('temperature', 0.5070180892944336)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:507000 episode:33104 last_R: 48.85560965538025 average_R:65.69383783817291
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.815493), ('average_q2', 8.880349), ('average_q_func1_loss', 3.2801219153404237), ('average_q_func2_loss', 3.27962651014328), ('n_updates', 496999), ('average_entropy', -1.0345205), ('temperature', 0.5110991597175598)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:508000 episode:33110 last_R: 64.30642127990723 average_R:69.08321211814881
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.687008), ('average_q2', 8.765692), ('average_q_func1_loss', 3.305930914878845), ('average_q_func2_loss', 3.2983649611473083), ('n_updates', 497999), ('average_entropy', -0.96939), ('temperature', 0.5112859010696411)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:509000 episode:33117 last_R: 136.83513259887695 average_R:69.49041539907455
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.828764), ('average_q2', 8.7419815), ('average_q_func1_loss', 3.1679400873184203), ('average_q_func2_loss', 3.173084374666214), ('n_updates', 498999), ('average_entropy', -1.0343565), ('temperature', 0.510042130947113)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:510000 episode:33125 last_R: 46.559367179870605 average_R:72.19191554546356
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.967353), ('average_q2', 8.723102), ('average_q_func1_loss', 3.2802128100395205), ('average_q_func2_loss', 3.2769252240657805), ('n_updates', 499999), ('average_entropy', -0.9946755), ('temperature', 0.5101436972618103)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:511000 episode:33138 last_R: 69.16380381584167 average_R:73.17537661075592
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.132744), ('average_q2', 9.024425), ('average_q_func1_loss', 3.335112416744232), ('average_q_func2_loss', 3.3249915838241577), ('n_updates', 500999), ('average_entropy', -0.9656267), ('temperature', 0.5083492994308472)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:512000 episode:33145 last_R: 58.582863092422485 average_R:72.74436252593995
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.313955), ('average_q2', 9.248101), ('average_q_func1_loss', 3.2106495440006255), ('average_q_func2_loss', 3.189560329914093), ('n_updates', 501999), ('average_entropy', -0.99218297), ('temperature', 0.5060732364654541)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:513000 episode:33155 last_R: 74.38757967948914 average_R:75.32982511997223
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.955177), ('average_q2', 8.962313), ('average_q_func1_loss', 3.282825220823288), ('average_q_func2_loss', 3.281161615848541), ('n_updates', 502999), ('average_entropy', -0.92906797), ('temperature', 0.506734311580658)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:514000 episode:33166 last_R: 50.150482416152954 average_R:72.80152200460434
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.146441), ('average_q2', 9.134339), ('average_q_func1_loss', 3.388810362815857), ('average_q_func2_loss', 3.4000354957580567), ('n_updates', 503999), ('average_entropy', -1.0036), ('temperature', 0.5082636475563049)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:515000 episode:33173 last_R: 57.0552442073822 average_R:73.29676667451858
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.835499), ('average_q2', 8.860488), ('average_q_func1_loss', 3.3027944660186765), ('average_q_func2_loss', 3.3099220299720766), ('n_updates', 504999), ('average_entropy', -0.9723486), ('temperature', 0.5105760097503662)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:516000 episode:33180 last_R: 102.085444688797 average_R:75.69206189393998
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.129219), ('average_q2', 9.226664), ('average_q_func1_loss', 3.241775357723236), ('average_q_func2_loss', 3.2214834082126615), ('n_updates', 505999), ('average_entropy', -1.0422994), ('temperature', 0.5057207345962524)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:517000 episode:33184 last_R: 214.3810534477234 average_R:76.45178554058074
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.195311), ('average_q2', 9.235096), ('average_q_func1_loss', 3.2597406780719758), ('average_q_func2_loss', 3.2615577924251555), ('n_updates', 506999), ('average_entropy', -0.93929285), ('temperature', 0.49886980652809143)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:518000 episode:33192 last_R: 56.289647340774536 average_R:78.49325247049332
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.295974), ('average_q2', 9.250023), ('average_q_func1_loss', 3.260373628139496), ('average_q_func2_loss', 3.2416738617420195), ('n_updates', 507999), ('average_entropy', -0.9521392), ('temperature', 0.5032848715782166)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:519000 episode:33199 last_R: 62.660866498947144 average_R:82.91387499332428
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.436085), ('average_q2', 9.4480915), ('average_q_func1_loss', 3.250881631374359), ('average_q_func2_loss', 3.2593009090423584), ('n_updates', 508999), ('average_entropy', -0.9920089), ('temperature', 0.4973479211330414)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:520000 episode:33208 last_R: 75.84805393218994 average_R:81.92888748407364
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.854486), ('average_q2', 8.901984), ('average_q_func1_loss', 3.3404999351501465), ('average_q_func2_loss', 3.3492283916473387), ('n_updates', 509999), ('average_entropy', -0.9552242), ('temperature', 0.5074085593223572)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:521000 episode:33215 last_R: 140.44885921478271 average_R:81.73006130933761
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.907664), ('average_q2', 8.883644), ('average_q_func1_loss', 3.2317981338500976), ('average_q_func2_loss', 3.2354322052001954), ('n_updates', 510999), ('average_entropy', -1.0044162), ('temperature', 0.5017985701560974)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:522000 episode:33222 last_R: 116.19607591629028 average_R:83.02266232252121
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.111797), ('average_q2', 9.250882), ('average_q_func1_loss', 3.180491449832916), ('average_q_func2_loss', 3.1676434433460234), ('n_updates', 511999), ('average_entropy', -0.9615486), ('temperature', 0.5038952827453613)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:523000 episode:33230 last_R: 53.58464050292969 average_R:83.64793555021286
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.441466), ('average_q2', 9.4841), ('average_q_func1_loss', 3.1457351565361025), ('average_q_func2_loss', 3.1462424755096436), ('n_updates', 512999), ('average_entropy', -1.0821187), ('temperature', 0.501498281955719)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:524000 episode:33236 last_R: 103.21955037117004 average_R:85.30816054105759
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.496997), ('average_q2', 9.567258), ('average_q_func1_loss', 3.3071323573589324), ('average_q_func2_loss', 3.299960095882416), ('n_updates', 513999), ('average_entropy', -1.0071087), ('temperature', 0.5034883618354797)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:525000 episode:33246 last_R: 69.32533168792725 average_R:86.95591360092163
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.588443), ('average_q2', 8.709592), ('average_q_func1_loss', 3.307559587955475), ('average_q_func2_loss', 3.3039287090301515), ('n_updates', 514999), ('average_entropy', -0.92320615), ('temperature', 0.5017135143280029)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 126 R: 126.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 176 R: 176.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 235 R: 235.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 505 R: 505.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 127 R: 127.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 91 R: 91.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 274 R: 274.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 249 R: 249.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 473 R: 473.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 236 R: 236.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 85 R: 85.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 186 R: 186.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 97 R: 97.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 86 R: 86.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 84 R: 84.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 151 R: 151.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 91 R: 91.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 381 R: 381.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 446 R: 446.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 58 R: 58.0
INFO:diayn_sim:true z: tensor([19,  3,  1,  0], device='cuda:0')
INFO:diayn_sim:disc z: tensor([42,  0, 33, 16])
INFO:diayn_sim:disc loss: 3.8590755462646484
INFO:diayn_sim:top extrinsic: [485. 564. 274. 649.]
INFO:diayn_sim:last intrinsic: [-0.08093691  1.4308374  -0.56915474 -0.5691557 ]
INFO:pfrl.experiments.train_agent_batch:The best score is updated 99.75 -> 207.85
INFO:pfrl.experiments.train_agent_batch:Saved the agent to results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a/best
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:526000 episode:33252 last_R: 44.20593762397766 average_R:86.71764993429184
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.755088), ('average_q2', 9.682908), ('average_q_func1_loss', 3.3108655977249146), ('average_q_func2_loss', 3.3186102294921875), ('n_updates', 515999), ('average_entropy', -1.0221552), ('temperature', 0.4999086856842041)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:527000 episode:33258 last_R: 86.38308930397034 average_R:89.1489628124237
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.596423), ('average_q2', 9.447326), ('average_q_func1_loss', 3.3447589612007143), ('average_q_func2_loss', 3.322555537223816), ('n_updates', 516999), ('average_entropy', -0.9740819), ('temperature', 0.5005825757980347)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:528000 episode:33261 last_R: 135.64545893669128 average_R:92.31691142320634
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 8.904845), ('average_q2', 8.885789), ('average_q_func1_loss', 3.2935570311546325), ('average_q_func2_loss', 3.279918465614319), ('n_updates', 517999), ('average_entropy', -0.86806774), ('temperature', 0.5060834288597107)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:529000 episode:33268 last_R: 161.03457355499268 average_R:96.93446582317353
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.36707), ('average_q2', 9.383039), ('average_q_func1_loss', 3.355702202320099), ('average_q_func2_loss', 3.359322690963745), ('n_updates', 518999), ('average_entropy', -0.9917228), ('temperature', 0.5054749846458435)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:530000 episode:33276 last_R: 58.29337811470032 average_R:97.1460084104538
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.836865), ('average_q2', 9.604004), ('average_q_func1_loss', 3.3865276694297792), ('average_q_func2_loss', 3.351336007118225), ('n_updates', 519999), ('average_entropy', -0.948785), ('temperature', 0.4971626400947571)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:531000 episode:33281 last_R: 218.2815601825714 average_R:97.42044246196747
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.2828245), ('average_q2', 9.489717), ('average_q_func1_loss', 3.4414640617370607), ('average_q_func2_loss', 3.436098344326019), ('n_updates', 520999), ('average_entropy', -1.0047691), ('temperature', 0.5029192566871643)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:532000 episode:33288 last_R: 151.7779667377472 average_R:96.8554841351509
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.528648), ('average_q2', 9.346017), ('average_q_func1_loss', 3.3373851370811463), ('average_q_func2_loss', 3.334102704524994), ('n_updates', 521999), ('average_entropy', -1.0188789), ('temperature', 0.5044329762458801)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:533000 episode:33297 last_R: 45.738304138183594 average_R:94.99726444482803
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.239203), ('average_q2', 9.512328), ('average_q_func1_loss', 3.313290045261383), ('average_q_func2_loss', 3.2931351828575135), ('n_updates', 522999), ('average_entropy', -0.91308534), ('temperature', 0.5085077881813049)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:534000 episode:33301 last_R: 131.2473087310791 average_R:95.41793624162673
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.415988), ('average_q2', 9.647267), ('average_q_func1_loss', 3.358198721408844), ('average_q_func2_loss', 3.3449299216270445), ('n_updates', 523999), ('average_entropy', -1.0441867), ('temperature', 0.49881860613822937)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:535000 episode:33303 last_R: 227.16237902641296 average_R:97.14528370857239
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.699756), ('average_q2', 9.648358), ('average_q_func1_loss', 3.3549772119522094), ('average_q_func2_loss', 3.3536924076080323), ('n_updates', 524999), ('average_entropy', -0.9259065), ('temperature', 0.5015026330947876)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:536000 episode:33307 last_R: 49.42279267311096 average_R:102.2067630147934
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.595983), ('average_q2', 9.626078), ('average_q_func1_loss', 3.425533664226532), ('average_q_func2_loss', 3.420709207057953), ('n_updates', 525999), ('average_entropy', -1.0146714), ('temperature', 0.5085241198539734)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:537000 episode:33314 last_R: 118.22259902954102 average_R:108.02250636816025
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.366021), ('average_q2', 9.471317), ('average_q_func1_loss', 3.3337449407577515), ('average_q_func2_loss', 3.335304522514343), ('n_updates', 526999), ('average_entropy', -1.0314817), ('temperature', 0.5060418248176575)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:538000 episode:33317 last_R: 195.97513222694397 average_R:108.98312508106231
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.782747), ('average_q2', 9.684715), ('average_q_func1_loss', 3.36484703540802), ('average_q_func2_loss', 3.3604372358322143), ('n_updates', 527999), ('average_entropy', -1.0157923), ('temperature', 0.4996891915798187)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:539000 episode:33321 last_R: 37.136831521987915 average_R:107.10015080690384
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.454216), ('average_q2', 9.564495), ('average_q_func1_loss', 3.3700043392181396), ('average_q_func2_loss', 3.368678250312805), ('n_updates', 528999), ('average_entropy', -1.0303205), ('temperature', 0.5012499690055847)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:540000 episode:33324 last_R: 383.2246799468994 average_R:109.08847648382186
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.4379015), ('average_q2', 9.422867), ('average_q_func1_loss', 3.512146339416504), ('average_q_func2_loss', 3.5150308418273926), ('n_updates', 529999), ('average_entropy', -0.96946853), ('temperature', 0.4985513985157013)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:541000 episode:33329 last_R: 34.523547887802124 average_R:117.55741944789887
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.567862), ('average_q2', 9.809282), ('average_q_func1_loss', 3.450395588874817), ('average_q_func2_loss', 3.457845594882965), ('n_updates', 530999), ('average_entropy', -1.0107462), ('temperature', 0.5030568838119507)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:542000 episode:33329 last_R: 34.523547887802124 average_R:117.55741944789887
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.60041), ('average_q2', 9.651047), ('average_q_func1_loss', 3.445749428272247), ('average_q_func2_loss', 3.440912010669708), ('n_updates', 531999), ('average_entropy', -1.0464915), ('temperature', 0.5020844340324402)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:543000 episode:33333 last_R: 393.9863135814667 average_R:122.70831679821015
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.845461), ('average_q2', 9.634127), ('average_q_func1_loss', 3.3266884684562683), ('average_q_func2_loss', 3.3120686268806456), ('n_updates', 532999), ('average_entropy', -0.95721966), ('temperature', 0.5049271583557129)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:544000 episode:33337 last_R: 657.495297908783 average_R:130.61750812768935
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.530291), ('average_q2', 9.485641), ('average_q_func1_loss', 3.455224895477295), ('average_q_func2_loss', 3.453654987812042), ('n_updates', 533999), ('average_entropy', -0.968241), ('temperature', 0.5014723539352417)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:545000 episode:33339 last_R: 214.84041666984558 average_R:133.4624558019638
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.244631), ('average_q2', 9.502682), ('average_q_func1_loss', 3.4849530053138733), ('average_q_func2_loss', 3.474302885532379), ('n_updates', 534999), ('average_entropy', -1.0268686), ('temperature', 0.4973246157169342)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:546000 episode:33343 last_R: 226.19926762580872 average_R:138.01102155923843
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.1840515), ('average_q2', 10.233654), ('average_q_func1_loss', 3.4974871015548707), ('average_q_func2_loss', 3.4966455936431884), ('n_updates', 535999), ('average_entropy', -0.9724236), ('temperature', 0.49361082911491394)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:547000 episode:33344 last_R: 653.6695959568024 average_R:143.11470282554626
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.540023), ('average_q2', 9.474351), ('average_q_func1_loss', 3.366206922531128), ('average_q_func2_loss', 3.3539937210083006), ('n_updates', 536999), ('average_entropy', -0.9988904), ('temperature', 0.4992881715297699)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:548000 episode:33346 last_R: 376.2667565345764 average_R:149.76259343385698
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.959135), ('average_q2', 10.075168), ('average_q_func1_loss', 3.3977211046218874), ('average_q_func2_loss', 3.398028175830841), ('n_updates', 537999), ('average_entropy', -0.9881485), ('temperature', 0.5048436522483826)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:549000 episode:33347 last_R: 456.0792324542999 average_R:153.5411890864372
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.068239), ('average_q2', 10.037991), ('average_q_func1_loss', 3.4327014923095702), ('average_q_func2_loss', 3.4164474201202393), ('n_updates', 538999), ('average_entropy', -1.0488485), ('temperature', 0.5011370182037354)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:550000 episode:33349 last_R: 244.77994561195374 average_R:157.0446502184868
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.911853), ('average_q2', 10.037918), ('average_q_func1_loss', 3.4091254043579102), ('average_q_func2_loss', 3.4153723239898683), ('n_updates', 539999), ('average_entropy', -1.0013033), ('temperature', 0.4988965690135956)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 179 R: 179.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 81 R: 81.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 49 R: 49.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 69 R: 69.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 651 R: 651.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 268 R: 268.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 634 R: 634.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 548 R: 548.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 200 R: 200.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 65 R: 65.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 609 R: 609.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 507 R: 507.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 329 R: 329.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 288 R: 288.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 911 R: 911.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 295 R: 295.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 531 R: 531.0
INFO:diayn_sim:true z: tensor([43,  5,  3, 16], device='cuda:0')
INFO:diayn_sim:disc z: tensor([11,  3,  6, 36])
INFO:diayn_sim:disc loss: 3.0737502574920654
INFO:diayn_sim:top extrinsic: [ 962. 1200.  934. 1000.]
INFO:diayn_sim:last intrinsic: [ 1.2578206   1.5380995  -0.54529095  1.1022615 ]
INFO:pfrl.experiments.train_agent_batch:The best score is updated 207.85 -> 460.7
INFO:pfrl.experiments.train_agent_batch:Saved the agent to results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a/best
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:551000 episode:33350 last_R: 681.6610445976257 average_R:163.36694720506668
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.153298), ('average_q2', 10.0061035), ('average_q_func1_loss', 3.484089825153351), ('average_q_func2_loss', 3.4837411618232728), ('n_updates', 540999), ('average_entropy', -0.9903194), ('temperature', 0.49439120292663574)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:552000 episode:33353 last_R: 739.9600560665131 average_R:171.8983723473549
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.885744), ('average_q2', 9.992285), ('average_q_func1_loss', 3.56221396446228), ('average_q_func2_loss', 3.550608720779419), ('n_updates', 541999), ('average_entropy', -1.0185202), ('temperature', 0.5010996460914612)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:553000 episode:33354 last_R: 100.57880878448486 average_R:170.633563952446
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.517789), ('average_q2', 9.267591), ('average_q_func1_loss', 3.5205122375488282), ('average_q_func2_loss', 3.524419295787811), ('n_updates', 542999), ('average_entropy', -1.0139031), ('temperature', 0.5036590099334717)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:554000 episode:33355 last_R: 681.73024725914 average_R:176.40379007816315
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.043871), ('average_q2', 10.039365), ('average_q_func1_loss', 3.574559726715088), ('average_q_func2_loss', 3.571620044708252), ('n_updates', 543999), ('average_entropy', -0.87138027), ('temperature', 0.5019230246543884)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:555000 episode:33358 last_R: 678.6390323638916 average_R:186.9162366104126
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.976378), ('average_q2', 9.942011), ('average_q_func1_loss', 3.510840039253235), ('average_q_func2_loss', 3.48033833026886), ('n_updates', 544999), ('average_entropy', -1.0506538), ('temperature', 0.49803563952445984)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:556000 episode:33360 last_R: 79.37039184570312 average_R:189.8125490283966
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.749294), ('average_q2', 9.674407), ('average_q_func1_loss', 3.4970621943473814), ('average_q_func2_loss', 3.484387369155884), ('n_updates', 545999), ('average_entropy', -0.96911216), ('temperature', 0.5028595924377441)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:557000 episode:33361 last_R: 327.51133275032043 average_R:191.7312077665329
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.604222), ('average_q2', 10.344725), ('average_q_func1_loss', 3.3994857263565064), ('average_q_func2_loss', 3.3944934642314912), ('n_updates', 546999), ('average_entropy', -1.0107319), ('temperature', 0.5015640258789062)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:558000 episode:33362 last_R: 140.24970960617065 average_R:191.25417387247086
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.67058), ('average_q2', 10.851894), ('average_q_func1_loss', 3.5444053483009337), ('average_q_func2_loss', 3.54143283367157), ('n_updates', 547999), ('average_entropy', -1.077922), ('temperature', 0.4993588626384735)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:559000 episode:33364 last_R: 725.1944239139557 average_R:203.9577221465111
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.399698), ('average_q2', 10.481697), ('average_q_func1_loss', 3.4781988072395325), ('average_q_func2_loss', 3.4793491804599763), ('n_updates', 548999), ('average_entropy', -0.94952244), ('temperature', 0.49993857741355896)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:560000 episode:33367 last_R: 726.2174558639526 average_R:213.16512834310532
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.163216), ('average_q2', 10.249666), ('average_q_func1_loss', 3.667726957798004), ('average_q_func2_loss', 3.667125155925751), ('n_updates', 549999), ('average_entropy', -1.0316155), ('temperature', 0.5006304979324341)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:561000 episode:33368 last_R: 264.76716470718384 average_R:214.20245425462724
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.29902), ('average_q2', 10.367514), ('average_q_func1_loss', 3.5445324420928954), ('average_q_func2_loss', 3.535867302417755), ('n_updates', 550999), ('average_entropy', -1.0049034), ('temperature', 0.5015172362327576)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:562000 episode:33370 last_R: 43.70069122314453 average_R:215.47284028291702
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.474474), ('average_q2', 10.583361), ('average_q_func1_loss', 3.7097156476974487), ('average_q_func2_loss', 3.6806966280937194), ('n_updates', 551999), ('average_entropy', -0.97628623), ('temperature', 0.4936046600341797)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:563000 episode:33372 last_R: 183.18434309959412 average_R:217.41014271497727
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.465754), ('average_q2', 10.368286), ('average_q_func1_loss', 3.468467755317688), ('average_q_func2_loss', 3.459619801044464), ('n_updates', 552999), ('average_entropy', -0.9665151), ('temperature', 0.4952302575111389)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:564000 episode:33375 last_R: 738.8248522281647 average_R:232.40832176685333
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.52551), ('average_q2', 10.282187), ('average_q_func1_loss', 3.6371834778785708), ('average_q_func2_loss', 3.6318562722206114), ('n_updates', 553999), ('average_entropy', -1.0520703), ('temperature', 0.49427175521850586)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:565000 episode:33378 last_R: 83.4851644039154 average_R:234.71975514650345
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.682692), ('average_q2', 10.776551), ('average_q_func1_loss', 3.4941590785980225), ('average_q_func2_loss', 3.496519660949707), ('n_updates', 554999), ('average_entropy', -1.0513144), ('temperature', 0.501350998878479)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:566000 episode:33379 last_R: 304.66010069847107 average_R:237.39225957393646
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.429944), ('average_q2', 10.720889), ('average_q_func1_loss', 3.5864022755622864), ('average_q_func2_loss', 3.604745852947235), ('n_updates', 555999), ('average_entropy', -0.9592523), ('temperature', 0.5010439157485962)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:567000 episode:33382 last_R: 732.8695869445801 average_R:249.03989275455476
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.340354), ('average_q2', 10.594035), ('average_q_func1_loss', 3.6569697570800783), ('average_q_func2_loss', 3.650806918144226), ('n_updates', 556999), ('average_entropy', -0.97760975), ('temperature', 0.49918901920318604)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:568000 episode:33383 last_R: 126.05200481414795 average_R:248.42282056808472
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.819101), ('average_q2', 10.903069), ('average_q_func1_loss', 3.654405117034912), ('average_q_func2_loss', 3.643463318347931), ('n_updates', 557999), ('average_entropy', -0.9321918), ('temperature', 0.4956726133823395)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:569000 episode:33384 last_R: 372.8205337524414 average_R:250.66121909618377
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 9.904069), ('average_q2', 9.973383), ('average_q_func1_loss', 3.564996304512024), ('average_q_func2_loss', 3.572424054145813), ('n_updates', 558999), ('average_entropy', -0.9971024), ('temperature', 0.49578651785850525)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:570000 episode:33385 last_R: 714.7703623771667 average_R:257.17145990133287
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.886674), ('average_q2', 10.624994), ('average_q_func1_loss', 3.678339211940765), ('average_q_func2_loss', 3.6645631289482115), ('n_updates', 559999), ('average_entropy', -1.0044124), ('temperature', 0.49836966395378113)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:571000 episode:33387 last_R: 140.49774527549744 average_R:264.6477709698677
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.097478), ('average_q2', 9.985096), ('average_q_func1_loss', 3.5791561937332155), ('average_q_func2_loss', 3.5737442803382873), ('n_updates', 560999), ('average_entropy', -1.0646502), ('temperature', 0.4997207224369049)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:572000 episode:33390 last_R: 40.33107876777649 average_R:270.2359099435806
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.735207), ('average_q2', 10.719004), ('average_q_func1_loss', 3.5957424950599672), ('average_q_func2_loss', 3.600276918411255), ('n_updates', 561999), ('average_entropy', -1.0408612), ('temperature', 0.5024811029434204)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:573000 episode:33392 last_R: 734.7947642803192 average_R:275.8678670501709
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.419479), ('average_q2', 10.3792515), ('average_q_func1_loss', 3.5642372870445254), ('average_q_func2_loss', 3.556222212314606), ('n_updates', 562999), ('average_entropy', -1.0218524), ('temperature', 0.49932894110679626)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:574000 episode:33395 last_R: 195.4459102153778 average_R:286.3618712592125
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.590045), ('average_q2', 10.667815), ('average_q_func1_loss', 3.6456068992614745), ('average_q_func2_loss', 3.64965478181839), ('n_updates', 563999), ('average_entropy', -0.9646615), ('temperature', 0.4993564486503601)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:575000 episode:33397 last_R: 190.41714692115784 average_R:288.2719328570366
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.938774), ('average_q2', 10.9838), ('average_q_func1_loss', 3.656569788455963), ('average_q_func2_loss', 3.647936248779297), ('n_updates', 564999), ('average_entropy', -0.96628356), ('temperature', 0.49562060832977295)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 182 R: 182.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 852 R: 852.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 400 R: 400.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 894 R: 894.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 895 R: 895.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 724 R: 724.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 106 R: 106.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([10, 14,  9, 41], device='cuda:0')
INFO:diayn_sim:disc z: tensor([10, 37, 45, 13])
INFO:diayn_sim:disc loss: 2.6567838191986084
INFO:diayn_sim:top extrinsic: [1000. 1000. 2182. 1618.]
INFO:diayn_sim:last intrinsic: [1.3074155 1.0310433 1.3709064 1.3113914]
INFO:pfrl.experiments.train_agent_batch:The best score is updated 460.7 -> 852.65
INFO:pfrl.experiments.train_agent_batch:Saved the agent to results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a/best
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:576000 episode:33397 last_R: 190.41714692115784 average_R:288.2719328570366
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.615804), ('average_q2', 10.583199), ('average_q_func1_loss', 3.5972682881355285), ('average_q_func2_loss', 3.591056931018829), ('n_updates', 565999), ('average_entropy', -0.9769458), ('temperature', 0.4972841441631317)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:577000 episode:33400 last_R: 686.6984331607819 average_R:298.9150104403496
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.703741), ('average_q2', 10.879168), ('average_q_func1_loss', 3.6890727949142454), ('average_q_func2_loss', 3.681836347579956), ('n_updates', 566999), ('average_entropy', -1.0657334), ('temperature', 0.49724704027175903)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:578000 episode:33401 last_R: 433.1992435455322 average_R:301.9345297884941
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.657916), ('average_q2', 10.6285715), ('average_q_func1_loss', 3.6400237894058227), ('average_q_func2_loss', 3.6234720134735108), ('n_updates', 567999), ('average_entropy', -0.9652217), ('temperature', 0.4967278838157654)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:579000 episode:33401 last_R: 433.1992435455322 average_R:301.9345297884941
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.442091), ('average_q2', 11.336597), ('average_q_func1_loss', 3.6215041732788085), ('average_q_func2_loss', 3.599067108631134), ('n_updates', 568999), ('average_entropy', -0.98862565), ('temperature', 0.49737781286239624)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:580000 episode:33402 last_R: 431.95967721939087 average_R:305.2663656997681
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.654534), ('average_q2', 10.712729), ('average_q_func1_loss', 3.737123351097107), ('average_q_func2_loss', 3.7309547758102415), ('n_updates', 569999), ('average_entropy', -0.9504606), ('temperature', 0.4960560202598572)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:581000 episode:33405 last_R: 118.04663276672363 average_R:315.513235309124
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.684158), ('average_q2', 10.664344), ('average_q_func1_loss', 3.6070721626281737), ('average_q_func2_loss', 3.6017592120170594), ('n_updates', 570999), ('average_entropy', -1.0299568), ('temperature', 0.5005949139595032)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:582000 episode:33407 last_R: 168.77825617790222 average_R:319.3282154273987
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.686893), ('average_q2', 10.700863), ('average_q_func1_loss', 3.6613313698768617), ('average_q_func2_loss', 3.65402941942215), ('n_updates', 571999), ('average_entropy', -0.93990916), ('temperature', 0.5029413104057312)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:583000 episode:33407 last_R: 168.77825617790222 average_R:319.3282154273987
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.137062), ('average_q2', 10.98442), ('average_q_func1_loss', 3.5717313623428346), ('average_q_func2_loss', 3.559553918838501), ('n_updates', 572999), ('average_entropy', -0.8755189), ('temperature', 0.4961705803871155)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:584000 episode:33409 last_R: 249.05063772201538 average_R:327.5049791669846
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.952043), ('average_q2', 10.853318), ('average_q_func1_loss', 3.674172921180725), ('average_q_func2_loss', 3.671676607131958), ('n_updates', 573999), ('average_entropy', -0.97520185), ('temperature', 0.49740442633628845)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:585000 episode:33411 last_R: 29.554896593093872 average_R:333.1894913864136
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.879997), ('average_q2', 10.620028), ('average_q_func1_loss', 3.6146054434776307), ('average_q_func2_loss', 3.6017021131515503), ('n_updates', 574999), ('average_entropy', -0.9508877), ('temperature', 0.5075163245201111)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:586000 episode:33412 last_R: 714.3734738826752 average_R:339.8379057717323
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.332787), ('average_q2', 11.446796), ('average_q_func1_loss', 3.646290748119354), ('average_q_func2_loss', 3.635272538661957), ('n_updates', 575999), ('average_entropy', -1.0094332), ('temperature', 0.5041764378547668)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:587000 episode:33413 last_R: 495.0455799102783 average_R:337.9845898079872
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.965403), ('average_q2', 10.878746), ('average_q_func1_loss', 3.630086989402771), ('average_q_func2_loss', 3.6219127941131593), ('n_updates', 576999), ('average_entropy', -0.9975515), ('temperature', 0.4963225722312927)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:588000 episode:33414 last_R: 728.3226573467255 average_R:344.08559039115903
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.6274805), ('average_q2', 10.553735), ('average_q_func1_loss', 3.6929802680015564), ('average_q_func2_loss', 3.678274919986725), ('n_updates', 577999), ('average_entropy', -0.922962), ('temperature', 0.5039381980895996)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:589000 episode:33415 last_R: 703.6157004833221 average_R:350.3012184000015
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.416247), ('average_q2', 11.542123), ('average_q_func1_loss', 3.6419721102714537), ('average_q_func2_loss', 3.6475736045837404), ('n_updates', 578999), ('average_entropy', -1.0004388), ('temperature', 0.5006377696990967)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:590000 episode:33417 last_R: 94.74442267417908 average_R:355.42869388103486
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.234308), ('average_q2', 11.287484), ('average_q_func1_loss', 3.691819031238556), ('average_q_func2_loss', 3.6912042403221133), ('n_updates', 579999), ('average_entropy', -1.0474943), ('temperature', 0.5004715323448181)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:591000 episode:33420 last_R: 154.85028314590454 average_R:367.07931169748304
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.337831), ('average_q2', 11.2675), ('average_q_func1_loss', 3.6829635429382326), ('average_q_func2_loss', 3.6752046871185304), ('n_updates', 580999), ('average_entropy', -0.9710094), ('temperature', 0.5025234222412109)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:592000 episode:33420 last_R: 154.85028314590454 average_R:367.07931169748304
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.213004), ('average_q2', 11.347466), ('average_q_func1_loss', 3.6211501479148867), ('average_q_func2_loss', 3.627434320449829), ('n_updates', 581999), ('average_entropy', -1.0108341), ('temperature', 0.49736833572387695)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:593000 episode:33421 last_R: 725.5765900611877 average_R:373.9637092828751
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.723911), ('average_q2', 10.915252), ('average_q_func1_loss', 3.668952827453613), ('average_q_func2_loss', 3.6696185636520386), ('n_updates', 582999), ('average_entropy', -1.0365794), ('temperature', 0.4924706518650055)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:594000 episode:33422 last_R: 176.88568592071533 average_R:375.12075657367706
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.917381), ('average_q2', 11.081248), ('average_q_func1_loss', 3.703203580379486), ('average_q_func2_loss', 3.676183581352234), ('n_updates', 583999), ('average_entropy', -0.9485696), ('temperature', 0.49498140811920166)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:595000 episode:33426 last_R: 741.7931442260742 average_R:391.05474143981934
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.245678), ('average_q2', 11.367387), ('average_q_func1_loss', 3.5938178396224973), ('average_q_func2_loss', 3.5925450253486635), ('n_updates', 584999), ('average_entropy', -1.0581771), ('temperature', 0.4957754611968994)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:596000 episode:33426 last_R: 741.7931442260742 average_R:391.05474143981934
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 10.961327), ('average_q2', 10.954519), ('average_q_func1_loss', 3.838528800010681), ('average_q_func2_loss', 3.843818476200104), ('n_updates', 585999), ('average_entropy', -1.0375919), ('temperature', 0.5009530782699585)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:597000 episode:33426 last_R: 741.7931442260742 average_R:391.05474143981934
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.428461), ('average_q2', 11.570019), ('average_q_func1_loss', 3.7971752405166628), ('average_q_func2_loss', 3.7829175329208375), ('n_updates', 586999), ('average_entropy', -1.0150323), ('temperature', 0.49737873673439026)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:598000 episode:33426 last_R: 741.7931442260742 average_R:391.05474143981934
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.447262), ('average_q2', 11.662501), ('average_q_func1_loss', 3.8163824820518495), ('average_q_func2_loss', 3.808276059627533), ('n_updates', 587999), ('average_entropy', -1.034502), ('temperature', 0.4962455630302429)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:599000 episode:33430 last_R: 739.2583894729614 average_R:408.0118093562126
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.1837015), ('average_q2', 11.076087), ('average_q_func1_loss', 3.684749548435211), ('average_q_func2_loss', 3.6733371734619142), ('n_updates', 588999), ('average_entropy', -0.95167273), ('temperature', 0.5015396475791931)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:600000 episode:33431 last_R: 267.2317361831665 average_R:409.9795222258568
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.961457), ('average_q2', 12.041419), ('average_q_func1_loss', 3.72262503862381), ('average_q_func2_loss', 3.728378624916077), ('n_updates', 589999), ('average_entropy', -1.0300553), ('temperature', 0.5039505958557129)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 565 R: 565.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 994 R: 994.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([ 9, 20, 13, 10], device='cuda:0')
INFO:diayn_sim:disc z: tensor([ 9, 20, 42, 11])
INFO:diayn_sim:disc loss: 2.566934108734131
INFO:diayn_sim:top extrinsic: [1895. 1000. 3565. 2000.]
INFO:diayn_sim:last intrinsic: [1.4690862 1.320435  1.2806888 1.3099451]
INFO:pfrl.experiments.train_agent_batch:The best score is updated 852.65 -> 977.95
INFO:pfrl.experiments.train_agent_batch:Saved the agent to results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a/best
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:601000 episode:33432 last_R: 494.7917490005493 average_R:414.7953404855728
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.2124405), ('average_q2', 11.100834), ('average_q_func1_loss', 3.765007495880127), ('average_q_func2_loss', 3.7443283224105834), ('n_updates', 590999), ('average_entropy', -0.9661715), ('temperature', 0.49461689591407776)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:602000 episode:33433 last_R: 476.635751247406 average_R:415.6218348622322
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.329332), ('average_q2', 11.225428), ('average_q_func1_loss', 3.6825645971298218), ('average_q_func2_loss', 3.684320657253265), ('n_updates', 591999), ('average_entropy', -0.9237285), ('temperature', 0.4988554120063782)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:603000 episode:33435 last_R: 725.4560623168945 average_R:421.9815951681137
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.991975), ('average_q2', 11.70432), ('average_q_func1_loss', 3.688908271789551), ('average_q_func2_loss', 3.6652021288871763), ('n_updates', 592999), ('average_entropy', -0.96971506), ('temperature', 0.5044591426849365)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:604000 episode:33437 last_R: 42.10876727104187 average_R:415.99165167331694
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.937988), ('average_q2', 11.645026), ('average_q_func1_loss', 3.7968994641304015), ('average_q_func2_loss', 3.795097501277924), ('n_updates', 593999), ('average_entropy', -0.9739784), ('temperature', 0.4974731206893921)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:605000 episode:33438 last_R: 729.0723416805267 average_R:419.8149804210663
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.196456), ('average_q2', 11.295589), ('average_q_func1_loss', 3.628612198829651), ('average_q_func2_loss', 3.63540372133255), ('n_updates', 594999), ('average_entropy', -0.9954519), ('temperature', 0.5040451884269714)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:606000 episode:33441 last_R: 54.89872097969055 average_R:422.5541182374954
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.609145), ('average_q2', 11.540114), ('average_q_func1_loss', 3.7366654014587404), ('average_q_func2_loss', 3.7377705478668215), ('n_updates', 595999), ('average_entropy', -0.9875436), ('temperature', 0.5028365254402161)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:607000 episode:33442 last_R: 724.874260187149 average_R:428.7955186009407
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.522194), ('average_q2', 11.378597), ('average_q_func1_loss', 3.712419626712799), ('average_q_func2_loss', 3.69672979593277), ('n_updates', 596999), ('average_entropy', -0.9613184), ('temperature', 0.5027631521224976)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:608000 episode:33444 last_R: 344.8461561203003 average_R:430.7669491696358
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.508944), ('average_q2', 11.367559), ('average_q_func1_loss', 3.7393405199050904), ('average_q_func2_loss', 3.7290712666511534), ('n_updates', 597999), ('average_entropy', -1.0024371), ('temperature', 0.5058254599571228)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:609000 episode:33444 last_R: 344.8461561203003 average_R:430.7669491696358
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.480553), ('average_q2', 11.451766), ('average_q_func1_loss', 3.765677831172943), ('average_q_func2_loss', 3.752065496444702), ('n_updates', 598999), ('average_entropy', -0.97667915), ('temperature', 0.49543535709381104)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:610000 episode:33445 last_R: 696.1963453292847 average_R:433.7032598733902
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.939894), ('average_q2', 12.00525), ('average_q_func1_loss', 3.651390492916107), ('average_q_func2_loss', 3.652542793750763), ('n_updates', 599999), ('average_entropy', -0.9856762), ('temperature', 0.4999195337295532)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:611000 episode:33446 last_R: 696.2906422615051 average_R:436.90349873065946
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.755399), ('average_q2', 11.879455), ('average_q_func1_loss', 3.7377319502830506), ('average_q_func2_loss', 3.7317740964889525), ('n_updates', 600999), ('average_entropy', -0.94034266), ('temperature', 0.5098573565483093)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:612000 episode:33448 last_R: 686.7325165271759 average_R:443.7955839323997
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.938678), ('average_q2', 11.941929), ('average_q_func1_loss', 3.662450649738312), ('average_q_func2_loss', 3.6718150782585144), ('n_updates', 601999), ('average_entropy', -0.9962596), ('temperature', 0.49806487560272217)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:613000 episode:33448 last_R: 686.7325165271759 average_R:443.7955839323997
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.739549), ('average_q2', 11.751852), ('average_q_func1_loss', 3.758945355415344), ('average_q_func2_loss', 3.7624600410461424), ('n_updates', 602999), ('average_entropy', -0.96466076), ('temperature', 0.49942290782928467)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:614000 episode:33450 last_R: 434.0006744861603 average_R:446.36046004772186
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.285592), ('average_q2', 11.3253565), ('average_q_func1_loss', 3.8823482036590575), ('average_q_func2_loss', 3.8796931195259092), ('n_updates', 603999), ('average_entropy', -1.0010444), ('temperature', 0.496727854013443)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:615000 episode:33451 last_R: 675.1591742038727 average_R:450.1292010855675
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.43328), ('average_q2', 12.341845), ('average_q_func1_loss', 3.8888560485839845), ('average_q_func2_loss', 3.8784740948677063), ('n_updates', 604999), ('average_entropy', -1.0364857), ('temperature', 0.5051242113113403)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:616000 episode:33452 last_R: 736.0604431629181 average_R:457.0563329005241
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.668525), ('average_q2', 11.591663), ('average_q_func1_loss', 3.6710664200782777), ('average_q_func2_loss', 3.6630527663230894), ('n_updates', 605999), ('average_entropy', -1.0405564), ('temperature', 0.5002040266990662)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:617000 episode:33452 last_R: 736.0604431629181 average_R:457.0563329005241
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.73559), ('average_q2', 11.992618), ('average_q_func1_loss', 3.781035509109497), ('average_q_func2_loss', 3.780262761116028), ('n_updates', 606999), ('average_entropy', -0.9659484), ('temperature', 0.49884045124053955)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:618000 episode:33455 last_R: 41.62146306037903 average_R:456.6464777803421
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.651067), ('average_q2', 11.399087), ('average_q_func1_loss', 3.596827578544617), ('average_q_func2_loss', 3.6003593754768373), ('n_updates', 607999), ('average_entropy', -0.941183), ('temperature', 0.49847111105918884)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:619000 episode:33457 last_R: 156.04435276985168 average_R:459.29918558359145
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.546891), ('average_q2', 11.572769), ('average_q_func1_loss', 3.7074203443527223), ('average_q_func2_loss', 3.7047948002815247), ('n_updates', 608999), ('average_entropy', -1.0706172), ('temperature', 0.4959034025669098)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:620000 episode:33459 last_R: 197.17150259017944 average_R:455.51689593553544
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.414864), ('average_q2', 12.329463), ('average_q_func1_loss', 3.7792145919799807), ('average_q_func2_loss', 3.7984739398956298), ('n_updates', 609999), ('average_entropy', -1.0398278), ('temperature', 0.4967193603515625)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:621000 episode:33459 last_R: 197.17150259017944 average_R:455.51689593553544
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.110255), ('average_q2', 12.186108), ('average_q_func1_loss', 3.6705606532096864), ('average_q_func2_loss', 3.66139386177063), ('n_updates', 610999), ('average_entropy', -0.99748135), ('temperature', 0.49899959564208984)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:622000 episode:33462 last_R: 380.99689269065857 average_R:465.7118186211586
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.001358), ('average_q2', 12.046214), ('average_q_func1_loss', 3.807357082366943), ('average_q_func2_loss', 3.7991751885414122), ('n_updates', 611999), ('average_entropy', -0.9852715), ('temperature', 0.49705788493156433)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:623000 episode:33463 last_R: 243.81636023521423 average_R:461.09595802307126
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.815353), ('average_q2', 11.727264), ('average_q_func1_loss', 3.814182105064392), ('average_q_func2_loss', 3.7955003786087036), ('n_updates', 612999), ('average_entropy', -1.0088478), ('temperature', 0.4967590868473053)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:624000 episode:33464 last_R: 688.4630327224731 average_R:460.7286441111565
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.06419), ('average_q2', 11.953309), ('average_q_func1_loss', 3.905402274131775), ('average_q_func2_loss', 3.893427002429962), ('n_updates', 613999), ('average_entropy', -0.9718502), ('temperature', 0.5014204978942871)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:625000 episode:33465 last_R: 135.22662162780762 average_R:459.87696340084074
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.116182), ('average_q2', 12.137725), ('average_q_func1_loss', 3.7123823285102846), ('average_q_func2_loss', 3.7085322880744935), ('n_updates', 614999), ('average_entropy', -1.0147086), ('temperature', 0.4970267415046692)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 940 R: 940.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([14, 19, 29, 28], device='cuda:0')
INFO:diayn_sim:disc z: tensor([40, 29, 19, 32])
INFO:diayn_sim:disc loss: 2.9134180545806885
INFO:diayn_sim:top extrinsic: [1000. 1000. 1435. 1940.]
INFO:diayn_sim:last intrinsic: [ 1.4130716   1.3250482   1.2786438  -0.02254367]
INFO:pfrl.experiments.train_agent_batch:The best score is updated 977.95 -> 997.0
INFO:pfrl.experiments.train_agent_batch:Saved the agent to results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a/best
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:626000 episode:33467 last_R: 705.1798074245453 average_R:462.9152943992615
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.190836), ('average_q2', 12.247453), ('average_q_func1_loss', 3.797005159854889), ('average_q_func2_loss', 3.7824417471885683), ('n_updates', 615999), ('average_entropy', -1.09256), ('temperature', 0.4943573474884033)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:627000 episode:33468 last_R: 673.5833501815796 average_R:467.0034562540054
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.792863), ('average_q2', 11.89688), ('average_q_func1_loss', 3.7914277696609497), ('average_q_func2_loss', 3.771428716182709), ('n_updates', 616999), ('average_entropy', -0.9700183), ('temperature', 0.4979974925518036)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:628000 episode:33468 last_R: 673.5833501815796 average_R:467.0034562540054
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.017239), ('average_q2', 12.275848), ('average_q_func1_loss', 3.8366071438789366), ('average_q_func2_loss', 3.841049256324768), ('n_updates', 617999), ('average_entropy', -1.0550536), ('temperature', 0.5009061098098755)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:629000 episode:33469 last_R: 671.9674768447876 average_R:471.6608806848526
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.945873), ('average_q2', 11.954702), ('average_q_func1_loss', 3.8201209807395937), ('average_q_func2_loss', 3.8070736646652223), ('n_updates', 618999), ('average_entropy', -1.013515), ('temperature', 0.49755170941352844)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:630000 episode:33471 last_R: 694.4778528213501 average_R:481.79267094373705
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 11.841562), ('average_q2', 11.858007), ('average_q_func1_loss', 3.87210711479187), ('average_q_func2_loss', 3.849735746383667), ('n_updates', 619999), ('average_entropy', -0.9870991), ('temperature', 0.49615412950515747)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:631000 episode:33473 last_R: 733.5995755195618 average_R:488.22889713287356
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.091541), ('average_q2', 12.216759), ('average_q_func1_loss', 3.7292406606674193), ('average_q_func2_loss', 3.705297236442566), ('n_updates', 620999), ('average_entropy', -1.0184621), ('temperature', 0.5022136569023132)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:632000 episode:33473 last_R: 733.5995755195618 average_R:488.22889713287356
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.337617), ('average_q2', 12.294489), ('average_q_func1_loss', 3.9065771222114565), ('average_q_func2_loss', 3.902991409301758), ('n_updates', 621999), ('average_entropy', -1.0196906), ('temperature', 0.49578166007995605)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:633000 episode:33474 last_R: 697.0473771095276 average_R:488.02802119970323
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.228576), ('average_q2', 12.286998), ('average_q_func1_loss', 3.7199189186096193), ('average_q_func2_loss', 3.7197269797325134), ('n_updates', 622999), ('average_entropy', -1.0117233), ('temperature', 0.4993910789489746)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:634000 episode:33475 last_R: 746.5553631782532 average_R:488.1053263092041
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.523086), ('average_q2', 12.451032), ('average_q_func1_loss', 3.700391149520874), ('average_q_func2_loss', 3.6858155727386475), ('n_updates', 623999), ('average_entropy', -0.9757987), ('temperature', 0.5009192228317261)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:635000 episode:33477 last_R: 702.1608538627625 average_R:499.09281145572663
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.229893), ('average_q2', 12.182934), ('average_q_func1_loss', 3.7604562640190125), ('average_q_func2_loss', 3.7753770565986633), ('n_updates', 624999), ('average_entropy', -1.0244621), ('temperature', 0.5013159513473511)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:636000 episode:33477 last_R: 702.1608538627625 average_R:499.09281145572663
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.080071), ('average_q2', 12.05857), ('average_q_func1_loss', 3.7991730475425722), ('average_q_func2_loss', 3.791093683242798), ('n_updates', 625999), ('average_entropy', -0.9753749), ('temperature', 0.5026514530181885)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:637000 episode:33479 last_R: 371.94329714775085 average_R:506.01642886638643
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.409703), ('average_q2', 12.433887), ('average_q_func1_loss', 3.6919340801239016), ('average_q_func2_loss', 3.6831743621826174), ('n_updates', 626999), ('average_entropy', -1.0283523), ('temperature', 0.502254843711853)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:638000 episode:33480 last_R: 722.8839786052704 average_R:508.79847095012667
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.689821), ('average_q2', 12.70033), ('average_q_func1_loss', 3.7803388690948485), ('average_q_func2_loss', 3.749598627090454), ('n_updates', 627999), ('average_entropy', -1.0434871), ('temperature', 0.4983741044998169)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:639000 episode:33481 last_R: 695.2592558860779 average_R:512.4812172532081
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.156929), ('average_q2', 12.016857), ('average_q_func1_loss', 3.670346193313599), ('average_q_func2_loss', 3.6722100138664246), ('n_updates', 628999), ('average_entropy', -1.0263906), ('temperature', 0.4975273013114929)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:640000 episode:33481 last_R: 695.2592558860779 average_R:512.4812172532081
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.60775), ('average_q2', 12.521029), ('average_q_func1_loss', 3.73833016872406), ('average_q_func2_loss', 3.735494909286499), ('n_updates', 629999), ('average_entropy', -0.944251), ('temperature', 0.5008499026298523)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:641000 episode:33483 last_R: 727.7557671070099 average_R:518.1999305367469
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.5110855), ('average_q2', 12.349653), ('average_q_func1_loss', 3.7019599866867066), ('average_q_func2_loss', 3.7009143471717834), ('n_updates', 630999), ('average_entropy', -1.0183256), ('temperature', 0.49785250425338745)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:642000 episode:33484 last_R: 729.3486590385437 average_R:521.765211789608
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.405936), ('average_q2', 12.336489), ('average_q_func1_loss', 3.8463517832756042), ('average_q_func2_loss', 3.8504798650741576), ('n_updates', 631999), ('average_entropy', -0.91959995), ('temperature', 0.49951496720314026)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:643000 episode:33485 last_R: 737.6110138893127 average_R:521.9936183047295
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.526067), ('average_q2', 12.619566), ('average_q_func1_loss', 3.8377615141868593), ('average_q_func2_loss', 3.826327919960022), ('n_updates', 632999), ('average_entropy', -0.9781796), ('temperature', 0.49287310242652893)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:644000 episode:33485 last_R: 737.6110138893127 average_R:521.9936183047295
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.620813), ('average_q2', 12.772669), ('average_q_func1_loss', 3.8834049773216246), ('average_q_func2_loss', 3.8887063694000243), ('n_updates', 633999), ('average_entropy', -1.0494914), ('temperature', 0.5012955665588379)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:645000 episode:33487 last_R: 691.0367889404297 average_R:527.1852113580703
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.084762), ('average_q2', 12.275039), ('average_q_func1_loss', 3.778312232494354), ('average_q_func2_loss', 3.766926839351654), ('n_updates', 634999), ('average_entropy', -0.9856924), ('temperature', 0.497775137424469)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:646000 episode:33489 last_R: 738.0897734165192 average_R:531.943781428337
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.813073), ('average_q2', 12.75877), ('average_q_func1_loss', 3.7316679334640503), ('average_q_func2_loss', 3.7184426403045654), ('n_updates', 635999), ('average_entropy', -0.9357682), ('temperature', 0.5067299008369446)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:647000 episode:33489 last_R: 738.0897734165192 average_R:531.943781428337
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.552794), ('average_q2', 12.678767), ('average_q_func1_loss', 3.6373702478408814), ('average_q_func2_loss', 3.657330162525177), ('n_updates', 636999), ('average_entropy', -0.977407), ('temperature', 0.5026419162750244)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:648000 episode:33489 last_R: 738.0897734165192 average_R:531.943781428337
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.827159), ('average_q2', 12.528133), ('average_q_func1_loss', 3.747880220413208), ('average_q_func2_loss', 3.740522527694702), ('n_updates', 637999), ('average_entropy', -1.0153228), ('temperature', 0.5016264915466309)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:649000 episode:33491 last_R: 710.3571364879608 average_R:543.7341342139244
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.478925), ('average_q2', 12.75316), ('average_q_func1_loss', 3.8969412779808046), ('average_q_func2_loss', 3.8934004068374635), ('n_updates', 638999), ('average_entropy', -1.0413), ('temperature', 0.4955010414123535)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:650000 episode:33493 last_R: 692.7722365856171 average_R:547.2712831664086
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.508307), ('average_q2', 12.461318), ('average_q_func1_loss', 3.7754673099517824), ('average_q_func2_loss', 3.7867336583137514), ('n_updates', 639999), ('average_entropy', -1.0679799), ('temperature', 0.5040961503982544)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 359 R: 359.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([17,  5, 30, 20], device='cuda:0')
INFO:diayn_sim:disc z: tensor([36, 48, 32, 29])
INFO:diayn_sim:disc loss: 2.6826727390289307
INFO:diayn_sim:top extrinsic: [1359. 1000. 1000. 1060.]
INFO:diayn_sim:last intrinsic: [1.2747741 1.443409  0.8543966 1.3446217]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:651000 episode:33493 last_R: 692.7722365856171 average_R:547.2712831664086
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.702339), ('average_q2', 12.6871805), ('average_q_func1_loss', 3.736065113544464), ('average_q_func2_loss', 3.726952223777771), ('n_updates', 640999), ('average_entropy', -1.0198649), ('temperature', 0.4950830638408661)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:652000 episode:33493 last_R: 692.7722365856171 average_R:547.2712831664086
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.788971), ('average_q2', 12.82505), ('average_q_func1_loss', 3.9060292792320253), ('average_q_func2_loss', 3.9250959396362304), ('n_updates', 641999), ('average_entropy', -1.0264225), ('temperature', 0.5007335543632507)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:653000 episode:33495 last_R: 687.8671231269836 average_R:552.1897481679916
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.949303), ('average_q2', 13.035098), ('average_q_func1_loss', 3.8696363973617554), ('average_q_func2_loss', 3.8613468861579894), ('n_updates', 642999), ('average_entropy', -0.9746293), ('temperature', 0.49575498700141907)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:654000 episode:33498 last_R: 641.3946237564087 average_R:561.098725118637
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.84912), ('average_q2', 12.894978), ('average_q_func1_loss', 3.8830257630348206), ('average_q_func2_loss', 3.8774074840545656), ('n_updates', 643999), ('average_entropy', -1.0374002), ('temperature', 0.49730801582336426)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:655000 episode:33498 last_R: 641.3946237564087 average_R:561.098725118637
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.289716), ('average_q2', 13.340205), ('average_q_func1_loss', 3.7991552782058715), ('average_q_func2_loss', 3.7834124398231506), ('n_updates', 644999), ('average_entropy', -0.9707854), ('temperature', 0.49381643533706665)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:656000 episode:33498 last_R: 641.3946237564087 average_R:561.098725118637
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.563894), ('average_q2', 12.594699), ('average_q_func1_loss', 3.7154565811157227), ('average_q_func2_loss', 3.706602330207825), ('n_updates', 645999), ('average_entropy', -1.0239612), ('temperature', 0.4978483021259308)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:657000 episode:33499 last_R: 689.8520908355713 average_R:562.8192411708832
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.079599), ('average_q2', 13.316108), ('average_q_func1_loss', 3.71175009727478), ('average_q_func2_loss', 3.707560932636261), ('n_updates', 646999), ('average_entropy', -0.9912118), ('temperature', 0.49957388639450073)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:658000 episode:33502 last_R: 732.5495467185974 average_R:568.6043365192413
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.010495), ('average_q2', 13.022697), ('average_q_func1_loss', 3.7603737020492556), ('average_q_func2_loss', 3.7375066304206848), ('n_updates', 647999), ('average_entropy', -1.0367277), ('temperature', 0.49803972244262695)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:659000 episode:33502 last_R: 732.5495467185974 average_R:568.6043365192413
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.1359625), ('average_q2', 12.974555), ('average_q_func1_loss', 3.820542619228363), ('average_q_func2_loss', 3.8134865021705626), ('n_updates', 648999), ('average_entropy', -1.0555713), ('temperature', 0.5025722980499268)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:660000 episode:33502 last_R: 732.5495467185974 average_R:568.6043365192413
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.628628), ('average_q2', 12.568458), ('average_q_func1_loss', 3.830339729785919), ('average_q_func2_loss', 3.8133107233047485), ('n_updates', 649999), ('average_entropy', -1.0031124), ('temperature', 0.4965055286884308)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:661000 episode:33503 last_R: 685.9736094474792 average_R:568.598931236267
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.208987), ('average_q2', 13.137049), ('average_q_func1_loss', 3.791154537200928), ('average_q_func2_loss', 3.7898831295967104), ('n_updates', 650999), ('average_entropy', -1.0206157), ('temperature', 0.49938422441482544)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:662000 episode:33506 last_R: 700.2249553203583 average_R:574.7481452298165
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.820882), ('average_q2', 12.819522), ('average_q_func1_loss', 3.712525806427002), ('average_q_func2_loss', 3.711475523710251), ('n_updates', 651999), ('average_entropy', -1.0500135), ('temperature', 0.49607715010643005)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:663000 episode:33506 last_R: 700.2249553203583 average_R:574.7481452298165
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.146359), ('average_q2', 13.2422285), ('average_q_func1_loss', 3.7358674120903017), ('average_q_func2_loss', 3.7341137742996215), ('n_updates', 652999), ('average_entropy', -0.9340565), ('temperature', 0.493060439825058)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:664000 episode:33507 last_R: 286.4325511455536 average_R:575.9246881794929
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.006023), ('average_q2', 13.079694), ('average_q_func1_loss', 3.85496698141098), ('average_q_func2_loss', 3.840302515029907), ('n_updates', 653999), ('average_entropy', -1.0255759), ('temperature', 0.5091801285743713)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:665000 episode:33508 last_R: 709.7280986309052 average_R:576.3279738807678
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.546862), ('average_q2', 12.624486), ('average_q_func1_loss', 3.82151935338974), ('average_q_func2_loss', 3.818328742980957), ('n_updates', 654999), ('average_entropy', -0.9858457), ('temperature', 0.4935901165008545)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:666000 episode:33510 last_R: 728.5273969173431 average_R:580.7966961503029
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.547885), ('average_q2', 13.605068), ('average_q_func1_loss', 3.798744297027588), ('average_q_func2_loss', 3.8045509934425352), ('n_updates', 655999), ('average_entropy', -1.0646433), ('temperature', 0.4978654980659485)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:667000 episode:33510 last_R: 728.5273969173431 average_R:580.7966961503029
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.231453), ('average_q2', 13.276105), ('average_q_func1_loss', 3.7421067571640014), ('average_q_func2_loss', 3.7282291197776796), ('n_updates', 656999), ('average_entropy', -1.0485525), ('temperature', 0.4981651306152344)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:668000 episode:33511 last_R: 726.2126724720001 average_R:587.7632739090919
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.671541), ('average_q2', 13.571967), ('average_q_func1_loss', 3.7719482445716856), ('average_q_func2_loss', 3.784679419994354), ('n_updates', 657999), ('average_entropy', -0.90955055), ('temperature', 0.49649208784103394)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:669000 episode:33512 last_R: 718.1440207958221 average_R:587.8009793782235
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.206688), ('average_q2', 13.260984), ('average_q_func1_loss', 3.7692598724365234), ('average_q_func2_loss', 3.774162266254425), ('n_updates', 658999), ('average_entropy', -0.9792046), ('temperature', 0.4953784942626953)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:670000 episode:33514 last_R: 711.4913048744202 average_R:590.0212135624886
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.767918), ('average_q2', 12.971504), ('average_q_func1_loss', 3.915346610546112), ('average_q_func2_loss', 3.917375466823578), ('n_updates', 659999), ('average_entropy', -1.1273249), ('temperature', 0.5024937391281128)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:671000 episode:33514 last_R: 711.4913048744202 average_R:590.0212135624886
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.210168), ('average_q2', 13.453135), ('average_q_func1_loss', 3.835140724182129), ('average_q_func2_loss', 3.8183474206924437), ('n_updates', 660999), ('average_entropy', -1.0721889), ('temperature', 0.5000459551811218)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:672000 episode:33515 last_R: 706.8918821811676 average_R:590.053975379467
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 12.913308), ('average_q2', 12.914869), ('average_q_func1_loss', 3.904085919857025), ('average_q_func2_loss', 3.891898810863495), ('n_updates', 661999), ('average_entropy', -0.9205), ('temperature', 0.4973889887332916)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:673000 episode:33516 last_R: 699.4083070755005 average_R:590.0067843055725
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.49877), ('average_q2', 13.504794), ('average_q_func1_loss', 3.676901364326477), ('average_q_func2_loss', 3.688631246089935), ('n_updates', 662999), ('average_entropy', -1.0218855), ('temperature', 0.49771976470947266)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:674000 episode:33518 last_R: 722.4671778678894 average_R:596.4244003725051
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.013859), ('average_q2', 12.939582), ('average_q_func1_loss', 3.76725305557251), ('average_q_func2_loss', 3.7782030391693113), ('n_updates', 663999), ('average_entropy', -1.0141529), ('temperature', 0.49779611825942993)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:675000 episode:33518 last_R: 722.4671778678894 average_R:596.4244003725051
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.177406), ('average_q2', 13.113384), ('average_q_func1_loss', 3.8467554569244387), ('average_q_func2_loss', 3.8462700128555296), ('n_updates', 664999), ('average_entropy', -1.0153483), ('temperature', 0.49902230501174927)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 619 R: 619.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([ 9, 34,  9,  2], device='cuda:0')
INFO:diayn_sim:disc z: tensor([47, 17, 38,  2])
INFO:diayn_sim:disc loss: 3.2041006088256836
INFO:diayn_sim:top extrinsic: [1000. 2000. 1000. 1000.]
INFO:diayn_sim:last intrinsic: [-0.10412931  1.3743329   0.12686086  1.4344258 ]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:676000 episode:33519 last_R: 686.3736958503723 average_R:597.4028983974457
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.3061285), ('average_q2', 13.365395), ('average_q_func1_loss', 4.00820372581482), ('average_q_func2_loss', 4.00983090877533), ('n_updates', 665999), ('average_entropy', -0.99939775), ('temperature', 0.4958244264125824)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:677000 episode:33520 last_R: 674.3861186504364 average_R:602.598256752491
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.802125), ('average_q2', 13.856678), ('average_q_func1_loss', 3.739927670955658), ('average_q_func2_loss', 3.7260672283172607), ('n_updates', 666999), ('average_entropy', -0.96318495), ('temperature', 0.5124881267547607)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:678000 episode:33522 last_R: 665.2376999855042 average_R:606.9932710003853
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.718028), ('average_q2', 13.48192), ('average_q_func1_loss', 3.832812104225159), ('average_q_func2_loss', 3.8445769572257995), ('n_updates', 667999), ('average_entropy', -1.0016298), ('temperature', 0.49961522221565247)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:679000 episode:33522 last_R: 665.2376999855042 average_R:606.9932710003853
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.035423), ('average_q2', 13.194139), ('average_q_func1_loss', 3.8763856148719786), ('average_q_func2_loss', 3.8743871092796325), ('n_updates', 668999), ('average_entropy', -0.98636377), ('temperature', 0.4987461268901825)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:680000 episode:33523 last_R: 669.702029466629 average_R:606.392162117958
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.002467), ('average_q2', 14.022457), ('average_q_func1_loss', 3.791788001060486), ('average_q_func2_loss', 3.7882149171829225), ('n_updates', 669999), ('average_entropy', -1.0624926), ('temperature', 0.5034888982772827)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:681000 episode:33525 last_R: 747.0928707122803 average_R:609.5595269966126
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.370903), ('average_q2', 13.263061), ('average_q_func1_loss', 3.8260947680473327), ('average_q_func2_loss', 3.828877477645874), ('n_updates', 670999), ('average_entropy', -1.0288572), ('temperature', 0.49927642941474915)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:682000 episode:33526 last_R: 724.7786023616791 average_R:609.3893815779686
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.404323), ('average_q2', 13.28217), ('average_q_func1_loss', 3.71107479095459), ('average_q_func2_loss', 3.7230379509925844), ('n_updates', 671999), ('average_entropy', -0.9147227), ('temperature', 0.5062556266784668)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:683000 episode:33526 last_R: 724.7786023616791 average_R:609.3893815779686
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.560927), ('average_q2', 13.484284), ('average_q_func1_loss', 3.8211791038513185), ('average_q_func2_loss', 3.819940152168274), ('n_updates', 672999), ('average_entropy', -1.0227417), ('temperature', 0.5029144287109375)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:684000 episode:33527 last_R: 690.6811382770538 average_R:608.832486679554
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.459301), ('average_q2', 13.571871), ('average_q_func1_loss', 3.7849054074287416), ('average_q_func2_loss', 3.775675206184387), ('n_updates', 673999), ('average_entropy', -0.9625984), ('temperature', 0.5073444247245789)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:685000 episode:33529 last_R: 706.6594944000244 average_R:609.3479289436341
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.287545), ('average_q2', 13.277817), ('average_q_func1_loss', 3.7884236335754395), ('average_q_func2_loss', 3.8027465558052063), ('n_updates', 674999), ('average_entropy', -0.9636642), ('temperature', 0.5059943795204163)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:686000 episode:33530 last_R: 750.7645246982574 average_R:609.462990295887
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.499499), ('average_q2', 13.533125), ('average_q_func1_loss', 3.763874237537384), ('average_q_func2_loss', 3.7739565324783326), ('n_updates', 675999), ('average_entropy', -1.0091165), ('temperature', 0.4990779459476471)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:687000 episode:33530 last_R: 750.7645246982574 average_R:609.462990295887
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.363888), ('average_q2', 13.6278), ('average_q_func1_loss', 3.824895296096802), ('average_q_func2_loss', 3.813268127441406), ('n_updates', 676999), ('average_entropy', -1.0516841), ('temperature', 0.5004746317863464)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:688000 episode:33531 last_R: 687.5191867351532 average_R:613.6658648014069
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.700791), ('average_q2', 13.635067), ('average_q_func1_loss', 3.845359106063843), ('average_q_func2_loss', 3.8468887495994566), ('n_updates', 677999), ('average_entropy', -0.9652204), ('temperature', 0.4925060570240021)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:689000 episode:33533 last_R: 696.2558441162109 average_R:618.1513311672211
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.18697), ('average_q2', 14.080615), ('average_q_func1_loss', 3.8906401205062866), ('average_q_func2_loss', 3.885477089881897), ('n_updates', 678999), ('average_entropy', -1.043298), ('temperature', 0.4938974678516388)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:690000 episode:33534 last_R: 691.2861547470093 average_R:620.9985331892967
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.34369), ('average_q2', 13.3662405), ('average_q_func1_loss', 3.8583617496490477), ('average_q_func2_loss', 3.835210802555084), ('n_updates', 679999), ('average_entropy', -1.0429631), ('temperature', 0.5004600882530212)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:691000 episode:33534 last_R: 691.2861547470093 average_R:620.9985331892967
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.838927), ('average_q2', 13.810017), ('average_q_func1_loss', 3.8342173218727114), ('average_q_func2_loss', 3.8102232336997988), ('n_updates', 680999), ('average_entropy', -1.0523009), ('temperature', 0.5040005445480347)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:692000 episode:33536 last_R: 51.312443017959595 average_R:621.0701580929756
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.685416), ('average_q2', 13.518834), ('average_q_func1_loss', 3.745958709716797), ('average_q_func2_loss', 3.7525314235687257), ('n_updates', 681999), ('average_entropy', -1.0382935), ('temperature', 0.5011717081069946)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:693000 episode:33538 last_R: 704.7910852432251 average_R:627.5444128346443
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.781926), ('average_q2', 13.832248), ('average_q_func1_loss', 3.820606288909912), ('average_q_func2_loss', 3.811488854885101), ('n_updates', 682999), ('average_entropy', -1.0023786), ('temperature', 0.5013483166694641)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:694000 episode:33539 last_R: 711.4118113517761 average_R:633.9535374331474
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.378785), ('average_q2', 13.523469), ('average_q_func1_loss', 3.815131230354309), ('average_q_func2_loss', 3.80278124332428), ('n_updates', 683999), ('average_entropy', -0.99975306), ('temperature', 0.5058419704437256)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:695000 episode:33539 last_R: 711.4118113517761 average_R:633.9535374331474
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.253332), ('average_q2', 14.1689825), ('average_q_func1_loss', 3.8050433707237246), ('average_q_func2_loss', 3.792117953300476), ('n_updates', 684999), ('average_entropy', -0.99718153), ('temperature', 0.4974581003189087)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:696000 episode:33540 last_R: 682.8422381877899 average_R:633.59374989748
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.453488), ('average_q2', 14.592873), ('average_q_func1_loss', 3.825894787311554), ('average_q_func2_loss', 3.826394877433777), ('n_updates', 685999), ('average_entropy', -0.9746455), ('temperature', 0.5021349191665649)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:697000 episode:33542 last_R: 717.4392709732056 average_R:640.4143491363525
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.051019), ('average_q2', 14.132836), ('average_q_func1_loss', 3.8162251329421997), ('average_q_func2_loss', 3.814275507926941), ('n_updates', 686999), ('average_entropy', -1.0483294), ('temperature', 0.5031965970993042)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:698000 episode:33543 last_R: 696.2289328575134 average_R:640.0549808216095
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.280543), ('average_q2', 14.282086), ('average_q_func1_loss', 3.8535418033599855), ('average_q_func2_loss', 3.862416706085205), ('n_updates', 687999), ('average_entropy', -1.0332662), ('temperature', 0.5007474422454834)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:699000 episode:33543 last_R: 696.2289328575134 average_R:640.0549808216095
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.845085), ('average_q2', 13.984168), ('average_q_func1_loss', 3.9079852509498596), ('average_q_func2_loss', 3.920111472606659), ('n_updates', 688999), ('average_entropy', -1.0598115), ('temperature', 0.5045426487922668)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:700000 episode:33544 last_R: 683.7342698574066 average_R:643.4438619589805
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.441664), ('average_q2', 13.469758), ('average_q_func1_loss', 3.919189307689667), ('average_q_func2_loss', 3.9120071744918823), ('n_updates', 689999), ('average_entropy', -0.98404527), ('temperature', 0.5084120035171509)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([15,  8, 27, 10], device='cuda:0')
INFO:diayn_sim:disc z: tensor([15, 47, 26, 41])
INFO:diayn_sim:disc loss: 2.582385778427124
INFO:diayn_sim:top extrinsic: [1000. 1000. 1000. 1000.]
INFO:diayn_sim:last intrinsic: [1.3987789 1.4095759 1.1893711 1.3206227]
INFO:pfrl.experiments.train_agent_batch:The best score is updated 997.0 -> 1000.0
INFO:pfrl.experiments.train_agent_batch:Saved the agent to results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a/best
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:701000 episode:33546 last_R: 665.6800763607025 average_R:643.3880811619758
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.675936), ('average_q2', 13.630634), ('average_q_func1_loss', 3.7542433547973633), ('average_q_func2_loss', 3.741979348659515), ('n_updates', 690999), ('average_entropy', -0.9594491), ('temperature', 0.5010748505592346)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:702000 episode:33547 last_R: 653.5905306339264 average_R:642.7088059878349
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.125581), ('average_q2', 14.032986), ('average_q_func1_loss', 3.7756169271469116), ('average_q_func2_loss', 3.7602069568634033), ('n_updates', 691999), ('average_entropy', -1.0733143), ('temperature', 0.5021054744720459)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:703000 episode:33547 last_R: 653.5905306339264 average_R:642.7088059878349
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.651222), ('average_q2', 13.6694), ('average_q_func1_loss', 3.8250840878486634), ('average_q_func2_loss', 3.8173027276992797), ('n_updates', 692999), ('average_entropy', -1.0019569), ('temperature', 0.5004235506057739)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:704000 episode:33548 last_R: 646.427197933197 average_R:642.3057528018951
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.358058), ('average_q2', 13.275283), ('average_q_func1_loss', 3.7800089430809023), ('average_q_func2_loss', 3.7888861894607544), ('n_updates', 693999), ('average_entropy', -0.9629533), ('temperature', 0.4980327785015106)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:705000 episode:33550 last_R: 700.7195482254028 average_R:644.9101869106292
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.30992), ('average_q2', 14.494752), ('average_q_func1_loss', 3.7933374357223513), ('average_q_func2_loss', 3.8006145012378694), ('n_updates', 694999), ('average_entropy', -0.99911594), ('temperature', 0.4934369921684265)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:706000 episode:33551 last_R: 748.7222242355347 average_R:645.6458174109459
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.272778), ('average_q2', 14.250785), ('average_q_func1_loss', 3.855774359703064), ('average_q_func2_loss', 3.8470638585090637), ('n_updates', 695999), ('average_entropy', -1.0026945), ('temperature', 0.5020855069160461)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:707000 episode:33551 last_R: 748.7222242355347 average_R:645.6458174109459
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.699407), ('average_q2', 13.751385), ('average_q_func1_loss', 3.777746248245239), ('average_q_func2_loss', 3.751612536907196), ('n_updates', 696999), ('average_entropy', -1.0230907), ('temperature', 0.5053223371505737)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:708000 episode:33552 last_R: 761.5639657974243 average_R:645.900852637291
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.631774), ('average_q2', 13.575484), ('average_q_func1_loss', 3.7693464231491087), ('average_q_func2_loss', 3.769437913894653), ('n_updates', 697999), ('average_entropy', -1.045198), ('temperature', 0.5010546445846558)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:709000 episode:33554 last_R: 700.3884963989258 average_R:645.8594898629188
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.505326), ('average_q2', 14.670984), ('average_q_func1_loss', 3.71807133436203), ('average_q_func2_loss', 3.7005247235298158), ('n_updates', 698999), ('average_entropy', -0.981428), ('temperature', 0.5039474964141846)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:710000 episode:33555 last_R: 709.3168818950653 average_R:652.5364440512657
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.923586), ('average_q2', 14.1521), ('average_q_func1_loss', 3.682451751232147), ('average_q_func2_loss', 3.668510639667511), ('n_updates', 699999), ('average_entropy', -1.0018271), ('temperature', 0.49656885862350464)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:711000 episode:33555 last_R: 709.3168818950653 average_R:652.5364440512657
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.730986), ('average_q2', 13.760268), ('average_q_func1_loss', 3.727287805080414), ('average_q_func2_loss', 3.7359455823898315), ('n_updates', 700999), ('average_entropy', -1.0027645), ('temperature', 0.5031370520591736)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:712000 episode:33556 last_R: 760.7061951160431 average_R:652.8373659849167
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.110388), ('average_q2', 14.004528), ('average_q_func1_loss', 3.855793161392212), ('average_q_func2_loss', 3.8615617465972902), ('n_updates', 701999), ('average_entropy', -0.9804542), ('temperature', 0.5023795366287231)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:713000 episode:33558 last_R: 732.2314174175262 average_R:658.4928892612458
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.707675), ('average_q2', 13.826937), ('average_q_func1_loss', 3.694332408905029), ('average_q_func2_loss', 3.693988754749298), ('n_updates', 702999), ('average_entropy', -1.0294898), ('temperature', 0.5049989223480225)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:714000 episode:33559 last_R: 696.103467464447 average_R:663.4822089099885
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.800348), ('average_q2', 13.880105), ('average_q_func1_loss', 3.7608384251594544), ('average_q_func2_loss', 3.767938642501831), ('n_updates', 703999), ('average_entropy', -1.0010294), ('temperature', 0.5004395842552185)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:715000 episode:33559 last_R: 696.103467464447 average_R:663.4822089099885
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.369637), ('average_q2', 14.303226), ('average_q_func1_loss', 3.775619878768921), ('average_q_func2_loss', 3.771971135139465), ('n_updates', 704999), ('average_entropy', -1.0797944), ('temperature', 0.5016917586326599)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:716000 episode:33560 last_R: 716.4834110736847 average_R:663.7178064918518
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.325371), ('average_q2', 14.222799), ('average_q_func1_loss', 3.7476969599723815), ('average_q_func2_loss', 3.7385316991806032), ('n_updates', 705999), ('average_entropy', -1.0082694), ('temperature', 0.5024804472923279)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:717000 episode:33562 last_R: 716.8086831569672 average_R:668.7185627174377
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.887708), ('average_q2', 13.881539), ('average_q_func1_loss', 3.773977286815643), ('average_q_func2_loss', 3.7730322456359864), ('n_updates', 706999), ('average_entropy', -1.0093243), ('temperature', 0.5001362562179565)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:718000 episode:33563 last_R: 699.3228726387024 average_R:673.2736278414726
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.340183), ('average_q2', 14.452384), ('average_q_func1_loss', 3.719346213340759), ('average_q_func2_loss', 3.719669563770294), ('n_updates', 707999), ('average_entropy', -1.004227), ('temperature', 0.5018160939216614)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:719000 episode:33563 last_R: 699.3228726387024 average_R:673.2736278414726
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.035175), ('average_q2', 13.985), ('average_q_func1_loss', 3.590928992033005), ('average_q_func2_loss', 3.5948450684547426), ('n_updates', 708999), ('average_entropy', -0.98424685), ('temperature', 0.4920693337917328)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:720000 episode:33564 last_R: 701.9839506149292 average_R:673.4088370203972
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.091617), ('average_q2', 14.092036), ('average_q_func1_loss', 3.7799706745147703), ('average_q_func2_loss', 3.783330305814743), ('n_updates', 709999), ('average_entropy', -0.93786633), ('temperature', 0.5008004307746887)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:721000 episode:33566 last_R: 715.1842737197876 average_R:679.2332945632935
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.460085), ('average_q2', 14.299961), ('average_q_func1_loss', 3.641604585647583), ('average_q_func2_loss', 3.6440802335739138), ('n_updates', 710999), ('average_entropy', -1.0140268), ('temperature', 0.5021698474884033)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:722000 episode:33567 last_R: 710.2595739364624 average_R:679.2840922284126
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.721723), ('average_q2', 14.67506), ('average_q_func1_loss', 3.8832154750823973), ('average_q_func2_loss', 3.873891460895538), ('n_updates', 711999), ('average_entropy', -1.0431043), ('temperature', 0.5014215111732483)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:723000 episode:33567 last_R: 710.2595739364624 average_R:679.2840922284126
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.752723), ('average_q2', 14.766807), ('average_q_func1_loss', 3.77464341878891), ('average_q_func2_loss', 3.7957357954978943), ('n_updates', 712999), ('average_entropy', -0.9749579), ('temperature', 0.5080345869064331)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:724000 episode:33568 last_R: 717.8044588565826 average_R:679.7263033151627
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.085172), ('average_q2', 14.170062), ('average_q_func1_loss', 3.7092789578437806), ('average_q_func2_loss', 3.7021620082855224), ('n_updates', 713999), ('average_entropy', -0.9316998), ('temperature', 0.5024850368499756)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:725000 episode:33570 last_R: 731.2641816139221 average_R:680.2712970018387
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.369916), ('average_q2', 14.288965), ('average_q_func1_loss', 3.628446660041809), ('average_q_func2_loss', 3.622495355606079), ('n_updates', 714999), ('average_entropy', -1.024698), ('temperature', 0.5019423365592957)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([13,  6, 42, 42], device='cuda:0')
INFO:diayn_sim:disc z: tensor([35, 44, 43,  9])
INFO:diayn_sim:disc loss: 2.5336344242095947
INFO:diayn_sim:top extrinsic: [1000. 1000. 1000. 1000.]
INFO:diayn_sim:last intrinsic: [1.2631817 1.3830254 1.384434  1.4827135]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:726000 episode:33571 last_R: 689.3180415630341 average_R:680.2196988892555
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 13.813234), ('average_q2', 14.18736), ('average_q_func1_loss', 3.77327508687973), ('average_q_func2_loss', 3.765807375907898), ('n_updates', 715999), ('average_entropy', -1.0061452), ('temperature', 0.49773940443992615)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:727000 episode:33571 last_R: 689.3180415630341 average_R:680.2196988892555
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.216279), ('average_q2', 14.409562), ('average_q_func1_loss', 3.777730257511139), ('average_q_func2_loss', 3.7856215023994446), ('n_updates', 716999), ('average_entropy', -0.9455439), ('temperature', 0.5003511905670166)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:728000 episode:33572 last_R: 655.509281873703 average_R:684.0600852036476
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.6942425), ('average_q2', 14.680352), ('average_q_func1_loss', 3.8127767562866213), ('average_q_func2_loss', 3.8296285271644592), ('n_updates', 717999), ('average_entropy', -0.97189695), ('temperature', 0.5002727508544922)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:729000 episode:33574 last_R: 607.0261075496674 average_R:682.1095541286469
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.694172), ('average_q2', 14.770086), ('average_q_func1_loss', 3.776239049434662), ('average_q_func2_loss', 3.764087001085281), ('n_updates', 718999), ('average_entropy', -1.0823368), ('temperature', 0.501461923122406)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:730000 episode:33575 last_R: 672.7475426197052 average_R:681.3714759230613
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.825721), ('average_q2', 14.695004), ('average_q_func1_loss', 3.739690556526184), ('average_q_func2_loss', 3.726723372936249), ('n_updates', 719999), ('average_entropy', -1.0103599), ('temperature', 0.5013606548309326)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:731000 episode:33575 last_R: 672.7475426197052 average_R:681.3714759230613
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.197622), ('average_q2', 14.322811), ('average_q_func1_loss', 3.8370891571044923), ('average_q_func2_loss', 3.8298359084129334), ('n_updates', 720999), ('average_entropy', -1.0148151), ('temperature', 0.5050156116485596)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:732000 episode:33577 last_R: 558.1929948329926 average_R:679.1311673045159
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.512371), ('average_q2', 14.550325), ('average_q_func1_loss', 3.8054548931121825), ('average_q_func2_loss', 3.802111806869507), ('n_updates', 721999), ('average_entropy', -1.0601348), ('temperature', 0.5006207823753357)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:733000 episode:33578 last_R: 706.5431976318359 average_R:679.110962190628
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.175696), ('average_q2', 14.312647), ('average_q_func1_loss', 3.69011828660965), ('average_q_func2_loss', 3.693716402053833), ('n_updates', 722999), ('average_entropy', -0.9701841), ('temperature', 0.49984097480773926)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:734000 episode:33579 last_R: 680.2404489517212 average_R:682.1939337086677
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.312819), ('average_q2', 14.158558), ('average_q_func1_loss', 3.715169377326965), ('average_q_func2_loss', 3.730848093032837), ('n_updates', 723999), ('average_entropy', -1.0075428), ('temperature', 0.5010488629341125)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:735000 episode:33579 last_R: 680.2404489517212 average_R:682.1939337086677
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.582199), ('average_q2', 14.854101), ('average_q_func1_loss', 3.6194863629341127), ('average_q_func2_loss', 3.6239964032173155), ('n_updates', 724999), ('average_entropy', -0.9967291), ('temperature', 0.50631183385849)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:736000 episode:33581 last_R: 667.852532863617 average_R:682.1882396054268
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.531704), ('average_q2', 14.549857), ('average_q_func1_loss', 3.769493293762207), ('average_q_func2_loss', 3.7479187130928038), ('n_updates', 725999), ('average_entropy', -0.9677132), ('temperature', 0.4983769655227661)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:737000 episode:33582 last_R: 698.1974136829376 average_R:682.1398422122002
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.483227), ('average_q2', 14.585049), ('average_q_func1_loss', 3.6805561637878417), ('average_q_func2_loss', 3.6767560982704164), ('n_updates', 726999), ('average_entropy', -1.046021), ('temperature', 0.5032485723495483)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:738000 episode:33583 last_R: 680.6261830329895 average_R:681.6685463714599
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.44877), ('average_q2', 14.415457), ('average_q_func1_loss', 3.6475490617752073), ('average_q_func2_loss', 3.6428154563903807), ('n_updates', 727999), ('average_entropy', -0.9233119), ('temperature', 0.5069804191589355)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:739000 episode:33583 last_R: 680.6261830329895 average_R:681.6685463714599
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.527824), ('average_q2', 14.538647), ('average_q_func1_loss', 3.8658820104599), ('average_q_func2_loss', 3.8577464032173157), ('n_updates', 728999), ('average_entropy', -1.1162649), ('temperature', 0.5001057386398315)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:740000 episode:33585 last_R: 711.2461240291595 average_R:681.7751224255562
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.763109), ('average_q2', 14.753002), ('average_q_func1_loss', 3.7673731684684753), ('average_q_func2_loss', 3.7786083102226256), ('n_updates', 729999), ('average_entropy', -0.9391471), ('temperature', 0.4964079260826111)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:741000 episode:33586 last_R: 732.9303731918335 average_R:681.8013598251342
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.003841), ('average_q2', 15.067825), ('average_q_func1_loss', 3.768641333580017), ('average_q_func2_loss', 3.7693793320655824), ('n_updates', 730999), ('average_entropy', -1.0520874), ('temperature', 0.4925735592842102)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:742000 episode:33587 last_R: 698.831659078598 average_R:681.879308526516
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.024608), ('average_q2', 14.98058), ('average_q_func1_loss', 3.753366768360138), ('average_q_func2_loss', 3.7447353386878968), ('n_updates', 731999), ('average_entropy', -1.0345867), ('temperature', 0.49921301007270813)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:743000 episode:33587 last_R: 698.831659078598 average_R:681.879308526516
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.610926), ('average_q2', 14.566606), ('average_q_func1_loss', 3.6992286682128905), ('average_q_func2_loss', 3.692283020019531), ('n_updates', 732999), ('average_entropy', -0.96282274), ('temperature', 0.5022999048233032)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:744000 episode:33589 last_R: 732.1130058765411 average_R:683.8795894765854
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.654103), ('average_q2', 14.700404), ('average_q_func1_loss', 3.7239811325073244), ('average_q_func2_loss', 3.7058508801460266), ('n_updates', 733999), ('average_entropy', -1.0183327), ('temperature', 0.4934924840927124)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:745000 episode:33590 last_R: 703.3003001213074 average_R:683.8545384120941
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.520076), ('average_q2', 14.529476), ('average_q_func1_loss', 3.7762096238136293), ('average_q_func2_loss', 3.7682682418823243), ('n_updates', 734999), ('average_entropy', -1.0335716), ('temperature', 0.506456732749939)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:746000 episode:33591 last_R: 730.0139334201813 average_R:684.0511063814163
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.849164), ('average_q2', 14.877149), ('average_q_func1_loss', 3.71824102640152), ('average_q_func2_loss', 3.7250528168678283), ('n_updates', 735999), ('average_entropy', -1.0265949), ('temperature', 0.5043855309486389)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:747000 episode:33591 last_R: 730.0139334201813 average_R:684.0511063814163
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.68221), ('average_q2', 14.608507), ('average_q_func1_loss', 3.8167108583450315), ('average_q_func2_loss', 3.8110234045982363), ('n_updates', 736999), ('average_entropy', -0.9842123), ('temperature', 0.5107895135879517)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:748000 episode:33593 last_R: 725.9104325771332 average_R:684.2471015357971
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.7453985), ('average_q2', 14.639231), ('average_q_func1_loss', 3.7355458617210386), ('average_q_func2_loss', 3.7421024227142334), ('n_updates', 737999), ('average_entropy', -1.0581387), ('temperature', 0.496454656124115)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:749000 episode:33594 last_R: 722.3639063835144 average_R:684.4724230027199
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.788889), ('average_q2', 14.848307), ('average_q_func1_loss', 3.725392439365387), ('average_q_func2_loss', 3.728127839565277), ('n_updates', 738999), ('average_entropy', -1.0831385), ('temperature', 0.5027486085891724)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:750000 episode:33595 last_R: 719.9568347930908 average_R:684.793320119381
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.876339), ('average_q2', 15.019391), ('average_q_func1_loss', 3.6873946046829222), ('average_q_func2_loss', 3.697943751811981), ('n_updates', 739999), ('average_entropy', -1.0166475), ('temperature', 0.5012048482894897)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 50 R: 50.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([29, 29, 15, 29], device='cuda:0')
INFO:diayn_sim:disc z: tensor([19, 26, 15, 22])
INFO:diayn_sim:disc loss: 2.580519914627075
INFO:diayn_sim:top extrinsic: [1000. 1000. 1000. 1050.]
INFO:diayn_sim:last intrinsic: [1.4637418 1.2083497 1.4401631 1.213558 ]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:751000 episode:33595 last_R: 719.9568347930908 average_R:684.793320119381
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.448748), ('average_q2', 14.412762), ('average_q_func1_loss', 3.6360430407524107), ('average_q_func2_loss', 3.619396207332611), ('n_updates', 740999), ('average_entropy', -1.0391052), ('temperature', 0.5039839744567871)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:752000 episode:33597 last_R: 683.5989663600922 average_R:691.2564948534965
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.076338), ('average_q2', 15.029854), ('average_q_func1_loss', 3.6757868337631225), ('average_q_func2_loss', 3.6711889839172365), ('n_updates', 741999), ('average_entropy', -0.9606776), ('temperature', 0.4934951961040497)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:753000 episode:33598 last_R: 675.9559268951416 average_R:691.6021078848839
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.836801), ('average_q2', 14.807444), ('average_q_func1_loss', 3.920388834476471), ('average_q_func2_loss', 3.91775639295578), ('n_updates', 742999), ('average_entropy', -0.9128876), ('temperature', 0.4975917935371399)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:754000 episode:33599 last_R: 635.2553000450134 average_R:691.0561399769783
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.391248), ('average_q2', 15.343848), ('average_q_func1_loss', 3.774041953086853), ('average_q_func2_loss', 3.7572952723503112), ('n_updates', 743999), ('average_entropy', -1.038383), ('temperature', 0.49891582131385803)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:755000 episode:33599 last_R: 635.2553000450134 average_R:691.0561399769783
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.415327), ('average_q2', 14.2765), ('average_q_func1_loss', 3.5660178732872008), ('average_q_func2_loss', 3.5516467261314393), ('n_updates', 744999), ('average_entropy', -0.9559669), ('temperature', 0.5039676427841187)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:756000 episode:33601 last_R: 689.3430588245392 average_R:691.0008171200752
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.555774), ('average_q2', 15.717877), ('average_q_func1_loss', 3.7368674421310426), ('average_q_func2_loss', 3.744184536933899), ('n_updates', 745999), ('average_entropy', -0.993805), ('temperature', 0.5098063349723816)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:757000 episode:33602 last_R: 686.3365595340729 average_R:690.53868724823
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.196248), ('average_q2', 15.331047), ('average_q_func1_loss', 3.740882921218872), ('average_q_func2_loss', 3.7430138611793518), ('n_updates', 746999), ('average_entropy', -0.9201384), ('temperature', 0.506385326385498)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:758000 episode:33603 last_R: 686.2095372676849 average_R:690.5410465264321
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.933277), ('average_q2', 14.891965), ('average_q_func1_loss', 3.6672168707847597), ('average_q_func2_loss', 3.6551183223724366), ('n_updates', 747999), ('average_entropy', -0.98443025), ('temperature', 0.5040244460105896)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:759000 episode:33603 last_R: 686.2095372676849 average_R:690.5410465264321
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.9743185), ('average_q2', 14.961082), ('average_q_func1_loss', 3.710903160572052), ('average_q_func2_loss', 3.699435315132141), ('n_updates', 748999), ('average_entropy', -1.0134993), ('temperature', 0.5078442096710205)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:760000 episode:33605 last_R: 731.2960293292999 average_R:690.5005824780465
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.99959), ('average_q2', 14.885779), ('average_q_func1_loss', 3.745358099937439), ('average_q_func2_loss', 3.7434855818748476), ('n_updates', 749999), ('average_entropy', -0.971486), ('temperature', 0.5044158697128296)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:761000 episode:33606 last_R: 745.8908960819244 average_R:690.957241885662
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.860654), ('average_q2', 14.955365), ('average_q_func1_loss', 3.73494989156723), ('average_q_func2_loss', 3.7006975650787353), ('n_updates', 750999), ('average_entropy', -1.0381869), ('temperature', 0.4969908595085144)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:762000 episode:33607 last_R: 720.7491340637207 average_R:695.3004077148438
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.492655), ('average_q2', 14.5168495), ('average_q_func1_loss', 3.779395751953125), ('average_q_func2_loss', 3.7885764956474306), ('n_updates', 751999), ('average_entropy', -0.99381095), ('temperature', 0.5028470158576965)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:763000 episode:33607 last_R: 720.7491340637207 average_R:695.3004077148438
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.414535), ('average_q2', 14.354856), ('average_q_func1_loss', 3.5738059735298155), ('average_q_func2_loss', 3.5750522208213806), ('n_updates', 752999), ('average_entropy', -0.9409361), ('temperature', 0.49976828694343567)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:764000 episode:33609 last_R: 707.7577543258667 average_R:695.2011815547943
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.962872), ('average_q2', 15.019594), ('average_q_func1_loss', 3.531661252975464), ('average_q_func2_loss', 3.535166554450989), ('n_updates', 753999), ('average_entropy', -1.0183706), ('temperature', 0.49835777282714844)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:765000 episode:33610 last_R: 665.9448149204254 average_R:694.5753557348252
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.611744), ('average_q2', 14.64741), ('average_q_func1_loss', 3.7958523654937744), ('average_q_func2_loss', 3.8014032578468324), ('n_updates', 754999), ('average_entropy', -0.9909506), ('temperature', 0.5012267231941223)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:766000 episode:33611 last_R: 647.4590756893158 average_R:693.7878197669983
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.127898), ('average_q2', 15.307903), ('average_q_func1_loss', 3.7158277225494385), ('average_q_func2_loss', 3.706558723449707), ('n_updates', 755999), ('average_entropy', -1.0082006), ('temperature', 0.5034745335578918)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:767000 episode:33611 last_R: 647.4590756893158 average_R:693.7878197669983
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.857255), ('average_q2', 14.871149), ('average_q_func1_loss', 3.8456028294563294), ('average_q_func2_loss', 3.8448186707496643), ('n_updates', 756999), ('average_entropy', -0.9519908), ('temperature', 0.5013598799705505)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:768000 episode:33613 last_R: 715.8731989860535 average_R:693.4550411343574
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.75074), ('average_q2', 14.597196), ('average_q_func1_loss', 3.78057080745697), ('average_q_func2_loss', 3.764894437789917), ('n_updates', 757999), ('average_entropy', -0.95705026), ('temperature', 0.510188102722168)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:769000 episode:33614 last_R: 691.4221029281616 average_R:693.2543491148949
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.176623), ('average_q2', 14.248955), ('average_q_func1_loss', 3.7919388246536254), ('average_q_func2_loss', 3.804747657775879), ('n_updates', 758999), ('average_entropy', -1.0076525), ('temperature', 0.5046678185462952)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:770000 episode:33615 last_R: 748.4029378890991 average_R:693.6694596719742
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.386775), ('average_q2', 15.376471), ('average_q_func1_loss', 3.773054609298706), ('average_q_func2_loss', 3.764188539981842), ('n_updates', 759999), ('average_entropy', -1.0455322), ('temperature', 0.513147234916687)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:771000 episode:33615 last_R: 748.4029378890991 average_R:693.6694596719742
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.806438), ('average_q2', 14.701531), ('average_q_func1_loss', 3.7575189232826234), ('average_q_func2_loss', 3.759429223537445), ('n_updates', 760999), ('average_entropy', -0.999171), ('temperature', 0.505032479763031)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:772000 episode:33617 last_R: 737.2005999088287 average_R:694.2012239480018
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.223687), ('average_q2', 15.1989765), ('average_q_func1_loss', 3.7833883786201477), ('average_q_func2_loss', 3.7727343940734865), ('n_updates', 761999), ('average_entropy', -1.022368), ('temperature', 0.5022941827774048)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:773000 episode:33618 last_R: 684.692999124527 average_R:693.8234821605682
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.7532425), ('average_q2', 15.565107), ('average_q_func1_loss', 3.7027234864234924), ('average_q_func2_loss', 3.7082002449035643), ('n_updates', 762999), ('average_entropy', -1.0051031), ('temperature', 0.5101625919342041)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:774000 episode:33619 last_R: 727.0173518657684 average_R:694.2299187207223
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.547188), ('average_q2', 15.577242), ('average_q_func1_loss', 3.6609998869895937), ('average_q_func2_loss', 3.655313732624054), ('n_updates', 763999), ('average_entropy', -1.0028313), ('temperature', 0.5042117238044739)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:775000 episode:33619 last_R: 727.0173518657684 average_R:694.2299187207223
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.640864), ('average_q2', 15.537408), ('average_q_func1_loss', 3.66405428647995), ('average_q_func2_loss', 3.662948534488678), ('n_updates', 764999), ('average_entropy', -0.99579346), ('temperature', 0.5106534957885742)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([ 7, 30, 31,  9], device='cuda:0')
INFO:diayn_sim:disc z: tensor([ 7, 31, 23, 49])
INFO:diayn_sim:disc loss: 2.5399885177612305
INFO:diayn_sim:top extrinsic: [1000. 1000. 1000. 1000.]
INFO:diayn_sim:last intrinsic: [1.7652407 1.2313433 0.9375496 1.5538042]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:776000 episode:33621 last_R: 644.0091106891632 average_R:693.7348255419731
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.678761), ('average_q2', 14.687116), ('average_q_func1_loss', 3.687022569179535), ('average_q_func2_loss', 3.695215632915497), ('n_updates', 765999), ('average_entropy', -0.9793009), ('temperature', 0.5047138333320618)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:777000 episode:33622 last_R: 675.1392726898193 average_R:693.8338412690163
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.387066), ('average_q2', 15.475995), ('average_q_func1_loss', 3.6513227462768554), ('average_q_func2_loss', 3.6456461906433106), ('n_updates', 766999), ('average_entropy', -1.0527241), ('temperature', 0.49640512466430664)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:778000 episode:33623 last_R: 633.9070694446564 average_R:693.4758916687965
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.989272), ('average_q2', 15.034096), ('average_q_func1_loss', 3.7908457064628602), ('average_q_func2_loss', 3.7945401644706727), ('n_updates', 767999), ('average_entropy', -1.0418241), ('temperature', 0.5041276216506958)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:779000 episode:33623 last_R: 633.9070694446564 average_R:693.4758916687965
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.1248455), ('average_q2', 15.026615), ('average_q_func1_loss', 3.568340462446213), ('average_q_func2_loss', 3.5596316123008727), ('n_updates', 768999), ('average_entropy', -1.016937), ('temperature', 0.5077139735221863)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:780000 episode:33625 last_R: 634.2679693698883 average_R:693.1322760105134
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.4523735), ('average_q2', 15.496166), ('average_q_func1_loss', 3.5653888392448425), ('average_q_func2_loss', 3.55320520401001), ('n_updates', 769999), ('average_entropy', -0.96871203), ('temperature', 0.5120440721511841)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:781000 episode:33626 last_R: 648.8910028934479 average_R:692.373400015831
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.319008), ('average_q2', 15.368287), ('average_q_func1_loss', 3.6528714179992674), ('average_q_func2_loss', 3.6504636430740356), ('n_updates', 770999), ('average_entropy', -1.0221373), ('temperature', 0.5040668249130249)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:782000 episode:33627 last_R: 685.6839833259583 average_R:692.32342846632
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.755677), ('average_q2', 15.554015), ('average_q_func1_loss', 3.7253513717651368), ('average_q_func2_loss', 3.7215885853767396), ('n_updates', 771999), ('average_entropy', -1.038195), ('temperature', 0.5065068602561951)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:783000 episode:33627 last_R: 685.6839833259583 average_R:692.32342846632
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.877967), ('average_q2', 14.974723), ('average_q_func1_loss', 3.6476542854309084), ('average_q_func2_loss', 3.6667471957206725), ('n_updates', 772999), ('average_entropy', -1.01788), ('temperature', 0.5047507882118225)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:784000 episode:33630 last_R: 677.6003196239471 average_R:687.7751190567017
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.398974), ('average_q2', 15.536554), ('average_q_func1_loss', 3.72257385969162), ('average_q_func2_loss', 3.7096008491516113), ('n_updates', 773999), ('average_entropy', -0.97284937), ('temperature', 0.5018579959869385)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:785000 episode:33631 last_R: 678.5133562088013 average_R:687.6850607514382
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.418993), ('average_q2', 15.567133), ('average_q_func1_loss', 3.5096092224121094), ('average_q_func2_loss', 3.5041238284111023), ('n_updates', 774999), ('average_entropy', -0.9606133), ('temperature', 0.5027616024017334)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:786000 episode:33631 last_R: 678.5133562088013 average_R:687.6850607514382
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 14.991971), ('average_q2', 15.059812), ('average_q_func1_loss', 3.675999505519867), ('average_q_func2_loss', 3.664410800933838), ('n_updates', 775999), ('average_entropy', -1.0593894), ('temperature', 0.5045484304428101)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:787000 episode:33631 last_R: 678.5133562088013 average_R:687.6850607514382
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.01279), ('average_q2', 16.135996), ('average_q_func1_loss', 3.7048905444145204), ('average_q_func2_loss', 3.7015435004234316), ('n_updates', 776999), ('average_entropy', -0.95616835), ('temperature', 0.4982606768608093)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:788000 episode:33634 last_R: 744.0390613079071 average_R:688.4716175699234
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.888961), ('average_q2', 15.8583355), ('average_q_func1_loss', 3.629586992263794), ('average_q_func2_loss', 3.629948580265045), ('n_updates', 777999), ('average_entropy', -1.0574455), ('temperature', 0.5041146874427795)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:789000 episode:33635 last_R: 700.1298966407776 average_R:688.0082477831841
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.930819), ('average_q2', 15.877024), ('average_q_func1_loss', 3.6883963108062745), ('average_q_func2_loss', 3.689187252521515), ('n_updates', 778999), ('average_entropy', -0.9528182), ('temperature', 0.5122677683830261)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:790000 episode:33635 last_R: 700.1298966407776 average_R:688.0082477831841
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.781764), ('average_q2', 15.684408), ('average_q_func1_loss', 3.5914879488945006), ('average_q_func2_loss', 3.5923110020160673), ('n_updates', 779999), ('average_entropy', -0.942982), ('temperature', 0.5059103965759277)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:791000 episode:33635 last_R: 700.1298966407776 average_R:688.0082477831841
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.967727), ('average_q2', 15.79776), ('average_q_func1_loss', 3.6467414140701293), ('average_q_func2_loss', 3.622929425239563), ('n_updates', 780999), ('average_entropy', -0.98444545), ('temperature', 0.5071325302124023)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:792000 episode:33638 last_R: 736.073853969574 average_R:694.5927531075478
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.528516), ('average_q2', 15.640728), ('average_q_func1_loss', 3.6121727633476257), ('average_q_func2_loss', 3.5961574840545656), ('n_updates', 781999), ('average_entropy', -0.973325), ('temperature', 0.5068343281745911)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:793000 episode:33639 last_R: 708.8837406635284 average_R:694.5674724006653
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.8057575), ('average_q2', 15.85035), ('average_q_func1_loss', 3.665815045833588), ('average_q_func2_loss', 3.662032005786896), ('n_updates', 782999), ('average_entropy', -1.0240777), ('temperature', 0.5030321478843689)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:794000 episode:33639 last_R: 708.8837406635284 average_R:694.5674724006653
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.745894), ('average_q2', 15.780258), ('average_q_func1_loss', 3.5956153774261477), ('average_q_func2_loss', 3.5861194467544557), ('n_updates', 783999), ('average_entropy', -1.0448472), ('temperature', 0.506987452507019)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:795000 episode:33639 last_R: 708.8837406635284 average_R:694.5674724006653
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.577322), ('average_q2', 15.717812), ('average_q_func1_loss', 3.7801622939109802), ('average_q_func2_loss', 3.7635348272323608), ('n_updates', 784999), ('average_entropy', -0.97896016), ('temperature', 0.5066847205162048)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:796000 episode:33642 last_R: 729.228705406189 average_R:694.763578016758
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.084775), ('average_q2', 15.232731), ('average_q_func1_loss', 3.6840788292884827), ('average_q_func2_loss', 3.6856602168083192), ('n_updates', 785999), ('average_entropy', -1.01562), ('temperature', 0.5057547688484192)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:797000 episode:33643 last_R: 720.5689871311188 average_R:695.006978559494
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.321424), ('average_q2', 15.221598), ('average_q_func1_loss', 3.7007584381103515), ('average_q_func2_loss', 3.703670394420624), ('n_updates', 786999), ('average_entropy', -0.9504986), ('temperature', 0.5078853964805603)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:798000 episode:33643 last_R: 720.5689871311188 average_R:695.006978559494
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.707828), ('average_q2', 15.651371), ('average_q_func1_loss', 3.800375952720642), ('average_q_func2_loss', 3.7897234344482422), ('n_updates', 787999), ('average_entropy', -1.022511), ('temperature', 0.5144872665405273)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:799000 episode:33643 last_R: 720.5689871311188 average_R:695.006978559494
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.740518), ('average_q2', 15.652478), ('average_q_func1_loss', 3.7506503677368164), ('average_q_func2_loss', 3.7626334643363952), ('n_updates', 788999), ('average_entropy', -1.0052835), ('temperature', 0.5086036920547485)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:800000 episode:33646 last_R: 741.7157065868378 average_R:696.3182511568069
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.732832), ('average_q2', 15.602387), ('average_q_func1_loss', 3.5874846625328063), ('average_q_func2_loss', 3.5812839579582216), ('n_updates', 789999), ('average_entropy', -1.0198479), ('temperature', 0.5112000107765198)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([39, 14, 30, 19], device='cuda:0')
INFO:diayn_sim:disc z: tensor([16, 14, 33, 19])
INFO:diayn_sim:disc loss: 2.4425406455993652
INFO:diayn_sim:top extrinsic: [1000. 1000. 1000. 1000.]
INFO:diayn_sim:last intrinsic: [1.4431415 1.6198356 1.3319211 1.482831 ]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:801000 episode:33648 last_R: 23.353899478912354 average_R:690.8155373167991
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.008467), ('average_q2', 16.01877), ('average_q_func1_loss', 3.749367332458496), ('average_q_func2_loss', 3.74852680683136), ('n_updates', 790999), ('average_entropy', -1.023034), ('temperature', 0.5159353613853455)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:802000 episode:33648 last_R: 23.353899478912354 average_R:690.8155373167991
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.4631195), ('average_q2', 15.498003), ('average_q_func1_loss', 3.7020879006385803), ('average_q_func2_loss', 3.683357586860657), ('n_updates', 791999), ('average_entropy', -1.0189892), ('temperature', 0.5048201680183411)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:803000 episode:33648 last_R: 23.353899478912354 average_R:690.8155373167991
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.636662), ('average_q2', 15.676613), ('average_q_func1_loss', 3.621374807357788), ('average_q_func2_loss', 3.618174388408661), ('n_updates', 792999), ('average_entropy', -1.005038), ('temperature', 0.49889683723449707)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:804000 episode:33651 last_R: 697.0755863189697 average_R:688.6860854125023
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.964238), ('average_q2', 15.866117), ('average_q_func1_loss', 3.667741231918335), ('average_q_func2_loss', 3.6576341915130617), ('n_updates', 793999), ('average_entropy', -0.949713), ('temperature', 0.5149502158164978)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:805000 episode:33652 last_R: 644.2100021839142 average_R:687.5125457763672
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.243056), ('average_q2', 15.125934), ('average_q_func1_loss', 3.765099904537201), ('average_q_func2_loss', 3.7498496782779696), ('n_updates', 794999), ('average_entropy', -1.0264443), ('temperature', 0.5104362368583679)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:806000 episode:33652 last_R: 644.2100021839142 average_R:687.5125457763672
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.047689), ('average_q2', 14.961057), ('average_q_func1_loss', 3.6273945641517638), ('average_q_func2_loss', 3.6197097969055174), ('n_updates', 795999), ('average_entropy', -1.0320342), ('temperature', 0.5083828568458557)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:807000 episode:33652 last_R: 644.2100021839142 average_R:687.5125457763672
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.650443), ('average_q2', 15.600146), ('average_q_func1_loss', 3.7706059789657593), ('average_q_func2_loss', 3.7717180037498474), ('n_updates', 796999), ('average_entropy', -1.0007284), ('temperature', 0.5075352191925049)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:808000 episode:33655 last_R: 692.3302803039551 average_R:687.3467048573494
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.863328), ('average_q2', 15.995186), ('average_q_func1_loss', 3.7199677419662476), ('average_q_func2_loss', 3.71367972612381), ('n_updates', 797999), ('average_entropy', -1.0073985), ('temperature', 0.5068439245223999)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:809000 episode:33656 last_R: 676.2933387756348 average_R:686.5025762939454
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.483883), ('average_q2', 15.412924), ('average_q_func1_loss', 3.602779128551483), ('average_q_func2_loss', 3.58850759267807), ('n_updates', 798999), ('average_entropy', -1.0153083), ('temperature', 0.510260820388794)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:810000 episode:33656 last_R: 676.2933387756348 average_R:686.5025762939454
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.373053), ('average_q2', 16.133326), ('average_q_func1_loss', 3.652350866794586), ('average_q_func2_loss', 3.641631987094879), ('n_updates', 799999), ('average_entropy', -1.0070769), ('temperature', 0.5069061517715454)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:811000 episode:33656 last_R: 676.2933387756348 average_R:686.5025762939454
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.909334), ('average_q2', 15.984285), ('average_q_func1_loss', 3.557217562198639), ('average_q_func2_loss', 3.5584124636650087), ('n_updates', 800999), ('average_entropy', -1.0013986), ('temperature', 0.5089572072029114)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:812000 episode:33659 last_R: 741.75643491745 average_R:685.9987808465958
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.05378), ('average_q2', 16.083998), ('average_q_func1_loss', 3.6366632914543153), ('average_q_func2_loss', 3.6368227767944337), ('n_updates', 801999), ('average_entropy', -0.9717119), ('temperature', 0.5031459927558899)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:813000 episode:33660 last_R: 716.7232012748718 average_R:686.0011787486077
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.03391), ('average_q2', 15.990933), ('average_q_func1_loss', 3.535457453727722), ('average_q_func2_loss', 3.5288457703590392), ('n_updates', 802999), ('average_entropy', -1.0416313), ('temperature', 0.5060368180274963)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:814000 episode:33660 last_R: 716.7232012748718 average_R:686.0011787486077
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.681537), ('average_q2', 15.562983), ('average_q_func1_loss', 3.582991592884064), ('average_q_func2_loss', 3.580010175704956), ('n_updates', 803999), ('average_entropy', -1.0348909), ('temperature', 0.5093674063682556)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:815000 episode:33660 last_R: 716.7232012748718 average_R:686.0011787486077
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.192405), ('average_q2', 15.25732), ('average_q_func1_loss', 3.604213514328003), ('average_q_func2_loss', 3.612276756763458), ('n_updates', 804999), ('average_entropy', -0.9682546), ('temperature', 0.5075576901435852)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:816000 episode:33663 last_R: 688.4047753810883 average_R:686.828674197197
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.068617), ('average_q2', 15.977143), ('average_q_func1_loss', 3.595287823677063), ('average_q_func2_loss', 3.5890075874328615), ('n_updates', 805999), ('average_entropy', -1.0549842), ('temperature', 0.5035476088523865)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:817000 episode:33664 last_R: 721.0639464855194 average_R:687.0194741559029
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.949422), ('average_q2', 16.095737), ('average_q_func1_loss', 3.7323183822631836), ('average_q_func2_loss', 3.717749662399292), ('n_updates', 806999), ('average_entropy', -1.0553291), ('temperature', 0.5131375193595886)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:818000 episode:33664 last_R: 721.0639464855194 average_R:687.0194741559029
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.687754), ('average_q2', 15.7342825), ('average_q_func1_loss', 3.53805960893631), ('average_q_func2_loss', 3.547484211921692), ('n_updates', 807999), ('average_entropy', -1.0234985), ('temperature', 0.5080005526542664)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:819000 episode:33664 last_R: 721.0639464855194 average_R:687.0194741559029
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.476873), ('average_q2', 16.368694), ('average_q_func1_loss', 3.7182536792755125), ('average_q_func2_loss', 3.7089694952964782), ('n_updates', 808999), ('average_entropy', -1.0501199), ('temperature', 0.5119274854660034)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:820000 episode:33667 last_R: 714.6989793777466 average_R:687.5258801865577
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.321666), ('average_q2', 15.429771), ('average_q_func1_loss', 3.6039613318443298), ('average_q_func2_loss', 3.5820878839492796), ('n_updates', 809999), ('average_entropy', -1.0840605), ('temperature', 0.5064598917961121)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:821000 episode:33668 last_R: 714.579567193985 average_R:687.4936312699318
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.701216), ('average_q2', 15.832246), ('average_q_func1_loss', 3.4866484785079956), ('average_q_func2_loss', 3.4954087495803834), ('n_updates', 810999), ('average_entropy', -1.0367323), ('temperature', 0.5088555216789246)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:822000 episode:33668 last_R: 714.579567193985 average_R:687.4936312699318
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.06815), ('average_q2', 16.007318), ('average_q_func1_loss', 3.5022200965881347), ('average_q_func2_loss', 3.4944610595703125), ('n_updates', 811999), ('average_entropy', -0.9967331), ('temperature', 0.505395770072937)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:823000 episode:33668 last_R: 714.579567193985 average_R:687.4936312699318
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.984727), ('average_q2', 15.927315), ('average_q_func1_loss', 3.5556548440456393), ('average_q_func2_loss', 3.5454061150550844), ('n_updates', 812999), ('average_entropy', -0.97190535), ('temperature', 0.5083404779434204)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:824000 episode:33671 last_R: 740.7157745361328 average_R:687.5660210967064
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.052393), ('average_q2', 15.842577), ('average_q_func1_loss', 3.6397041630744935), ('average_q_func2_loss', 3.6383664059638976), ('n_updates', 813999), ('average_entropy', -0.9694757), ('temperature', 0.5074419379234314)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:825000 episode:33672 last_R: 706.2376379966736 average_R:688.0733046579361
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.513842), ('average_q2', 15.389673), ('average_q_func1_loss', 3.6808633470535277), ('average_q_func2_loss', 3.666779832839966), ('n_updates', 814999), ('average_entropy', -1.0032549), ('temperature', 0.500527560710907)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([28, 10,  8, 30], device='cuda:0')
INFO:diayn_sim:disc z: tensor([27, 10,  8, 25])
INFO:diayn_sim:disc loss: 2.8111233711242676
INFO:diayn_sim:top extrinsic: [1000. 1000. 1000. 1000.]
INFO:diayn_sim:last intrinsic: [ 1.4091694   1.4464872   1.7064393  -0.15869713]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:826000 episode:33672 last_R: 706.2376379966736 average_R:688.0733046579361
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.8050375), ('average_q2', 15.908866), ('average_q_func1_loss', 3.532787435054779), ('average_q_func2_loss', 3.52368483543396), ('n_updates', 815999), ('average_entropy', -1.0334818), ('temperature', 0.5078595876693726)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:827000 episode:33672 last_R: 706.2376379966736 average_R:688.0733046579361
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.313887), ('average_q2', 17.155472), ('average_q_func1_loss', 3.513180456161499), ('average_q_func2_loss', 3.514005813598633), ('n_updates', 816999), ('average_entropy', -1.0301636), ('temperature', 0.50709468126297)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:828000 episode:33675 last_R: 653.7174768447876 average_R:688.9526401329041
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.345152), ('average_q2', 16.292116), ('average_q_func1_loss', 3.576581366062164), ('average_q_func2_loss', 3.58207612991333), ('n_updates', 817999), ('average_entropy', -1.0282607), ('temperature', 0.5095012187957764)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:829000 episode:33676 last_R: 650.4701902866364 average_R:689.1193833231926
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.39973), ('average_q2', 16.566547), ('average_q_func1_loss', 3.6757357358932494), ('average_q_func2_loss', 3.665562298297882), ('n_updates', 818999), ('average_entropy', -1.0247239), ('temperature', 0.5039424300193787)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:830000 episode:33676 last_R: 650.4701902866364 average_R:689.1193833231926
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.187233), ('average_q2', 16.240923), ('average_q_func1_loss', 3.586987943649292), ('average_q_func2_loss', 3.5933448028564454), ('n_updates', 819999), ('average_entropy', -0.99192464), ('temperature', 0.5095515847206116)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:831000 episode:33676 last_R: 650.4701902866364 average_R:689.1193833231926
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.144789), ('average_q2', 16.095905), ('average_q_func1_loss', 3.659130733013153), ('average_q_func2_loss', 3.662310018539429), ('n_updates', 820999), ('average_entropy', -1.0278699), ('temperature', 0.5056354999542236)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:832000 episode:33679 last_R: 707.4417419433594 average_R:690.9423347258568
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.011246), ('average_q2', 16.005335), ('average_q_func1_loss', 3.6611564135551453), ('average_q_func2_loss', 3.65633193731308), ('n_updates', 821999), ('average_entropy', -0.981709), ('temperature', 0.5076687335968018)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:833000 episode:33680 last_R: 698.038595199585 average_R:690.4255077648163
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.04433), ('average_q2', 15.922697), ('average_q_func1_loss', 3.699141335487366), ('average_q_func2_loss', 3.6862527441978457), ('n_updates', 822999), ('average_entropy', -0.92766345), ('temperature', 0.506925642490387)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:834000 episode:33680 last_R: 698.038595199585 average_R:690.4255077648163
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.849856), ('average_q2', 15.778128), ('average_q_func1_loss', 3.6653563666343687), ('average_q_func2_loss', 3.6786302375793456), ('n_updates', 823999), ('average_entropy', -0.97444564), ('temperature', 0.5053777694702148)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:835000 episode:33680 last_R: 698.038595199585 average_R:690.4255077648163
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.112034), ('average_q2', 15.968755), ('average_q_func1_loss', 3.580529568195343), ('average_q_func2_loss', 3.5657637882232667), ('n_updates', 824999), ('average_entropy', -1.0326222), ('temperature', 0.5054200887680054)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:836000 episode:33683 last_R: 656.3477330207825 average_R:690.8678791618347
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.02706), ('average_q2', 15.923836), ('average_q_func1_loss', 3.6121922850608827), ('average_q_func2_loss', 3.620374677181244), ('n_updates', 825999), ('average_entropy', -0.98285496), ('temperature', 0.5085828900337219)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:837000 episode:33684 last_R: 726.7551398277283 average_R:690.4717190170288
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.414307), ('average_q2', 16.472109), ('average_q_func1_loss', 3.6324635100364686), ('average_q_func2_loss', 3.630467460155487), ('n_updates', 826999), ('average_entropy', -0.9637336), ('temperature', 0.5005598664283752)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:838000 episode:33684 last_R: 726.7551398277283 average_R:690.4717190170288
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.963522), ('average_q2', 16.075632), ('average_q_func1_loss', 3.606263041496277), ('average_q_func2_loss', 3.5891764879226686), ('n_updates', 827999), ('average_entropy', -0.98874855), ('temperature', 0.5029624700546265)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:839000 episode:33684 last_R: 726.7551398277283 average_R:690.4717190170288
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.134214), ('average_q2', 16.18881), ('average_q_func1_loss', 3.6345744013786314), ('average_q_func2_loss', 3.646846387386322), ('n_updates', 828999), ('average_entropy', -1.0165128), ('temperature', 0.5039238333702087)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:840000 episode:33687 last_R: 777.3932113647461 average_R:690.956474339962
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.544966), ('average_q2', 16.713238), ('average_q_func1_loss', 3.614376232624054), ('average_q_func2_loss', 3.611262233257294), ('n_updates', 829999), ('average_entropy', -0.9699977), ('temperature', 0.508531928062439)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:841000 episode:33688 last_R: 679.0737447738647 average_R:690.373042640686
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.86672), ('average_q2', 15.7961235), ('average_q_func1_loss', 3.608290686607361), ('average_q_func2_loss', 3.613621084690094), ('n_updates', 830999), ('average_entropy', -0.99052733), ('temperature', 0.5116880536079407)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:842000 episode:33688 last_R: 679.0737447738647 average_R:690.373042640686
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.354347), ('average_q2', 16.09197), ('average_q_func1_loss', 3.6060367250442504), ('average_q_func2_loss', 3.5869482469558718), ('n_updates', 831999), ('average_entropy', -0.9670362), ('temperature', 0.5100169777870178)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:843000 episode:33688 last_R: 679.0737447738647 average_R:690.373042640686
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.360975), ('average_q2', 16.494663), ('average_q_func1_loss', 3.5905631017684936), ('average_q_func2_loss', 3.576026084423065), ('n_updates', 832999), ('average_entropy', -1.0163376), ('temperature', 0.5117269158363342)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:844000 episode:33691 last_R: 716.4477441310883 average_R:690.4522332644462
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.543774), ('average_q2', 16.573862), ('average_q_func1_loss', 3.467370643615723), ('average_q_func2_loss', 3.4579374814033508), ('n_updates', 833999), ('average_entropy', -1.1003555), ('temperature', 0.505829930305481)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:845000 episode:33692 last_R: 756.8689756393433 average_R:690.994671061039
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.813364), ('average_q2', 15.703588), ('average_q_func1_loss', 3.576969847679138), ('average_q_func2_loss', 3.578351101875305), ('n_updates', 834999), ('average_entropy', -1.060928), ('temperature', 0.5067942142486572)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:846000 episode:33692 last_R: 756.8689756393433 average_R:690.994671061039
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.958027), ('average_q2', 16.980148), ('average_q_func1_loss', 3.5034193897247317), ('average_q_func2_loss', 3.4939651679992676), ('n_updates', 835999), ('average_entropy', -1.0641894), ('temperature', 0.503462553024292)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:847000 episode:33692 last_R: 756.8689756393433 average_R:690.994671061039
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.477615), ('average_q2', 16.533882), ('average_q_func1_loss', 3.4982766377925874), ('average_q_func2_loss', 3.49274707198143), ('n_updates', 836999), ('average_entropy', -1.0445822), ('temperature', 0.51091068983078)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:848000 episode:33695 last_R: 750.5269703865051 average_R:691.5694435119628
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.75301), ('average_q2', 16.62775), ('average_q_func1_loss', 3.5916785430908202), ('average_q_func2_loss', 3.5928879415988924), ('n_updates', 837999), ('average_entropy', -1.0217557), ('temperature', 0.5057806968688965)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:849000 episode:33696 last_R: 771.1323854923248 average_R:692.7252867150306
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.081446), ('average_q2', 16.228508), ('average_q_func1_loss', 3.4562034583091736), ('average_q_func2_loss', 3.4596260988712313), ('n_updates', 838999), ('average_entropy', -1.033669), ('temperature', 0.5144151449203491)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:850000 episode:33696 last_R: 771.1323854923248 average_R:692.7252867150306
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.195526), ('average_q2', 16.148914), ('average_q_func1_loss', 3.4577715158462525), ('average_q_func2_loss', 3.4584617447853088), ('n_updates', 839999), ('average_entropy', -0.9287531), ('temperature', 0.517995297908783)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([28, 30, 29,  9], device='cuda:0')
INFO:diayn_sim:disc z: tensor([29, 34, 21,  9])
INFO:diayn_sim:disc loss: 2.607672691345215
INFO:diayn_sim:top extrinsic: [1000. 1000. 1000. 1000.]
INFO:diayn_sim:last intrinsic: [1.2182455 1.044213  1.3695552 1.5851867]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:851000 episode:33696 last_R: 771.1323854923248 average_R:692.7252867150306
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.253386), ('average_q2', 16.206175), ('average_q_func1_loss', 3.4367025470733643), ('average_q_func2_loss', 3.433620846271515), ('n_updates', 840999), ('average_entropy', -1.0595651), ('temperature', 0.5151868462562561)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:852000 episode:33699 last_R: 702.9255557060242 average_R:693.3762643527984
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.130264), ('average_q2', 16.068998), ('average_q_func1_loss', 3.507785005569458), ('average_q_func2_loss', 3.50180495262146), ('n_updates', 841999), ('average_entropy', -0.9398008), ('temperature', 0.5083438158035278)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:853000 episode:33700 last_R: 683.4136757850647 average_R:693.1809811353684
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.151066), ('average_q2', 16.217802), ('average_q_func1_loss', 3.528402259349823), ('average_q_func2_loss', 3.5067931175231934), ('n_updates', 842999), ('average_entropy', -0.9874327), ('temperature', 0.5132759213447571)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:854000 episode:33700 last_R: 683.4136757850647 average_R:693.1809811353684
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 15.889916), ('average_q2', 16.056793), ('average_q_func1_loss', 3.632615888118744), ('average_q_func2_loss', 3.6270571184158324), ('n_updates', 843999), ('average_entropy', -0.94400966), ('temperature', 0.5233479142189026)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:855000 episode:33700 last_R: 683.4136757850647 average_R:693.1809811353684
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.806225), ('average_q2', 16.874321), ('average_q_func1_loss', 3.585357267856598), ('average_q_func2_loss', 3.5723267543315886), ('n_updates', 844999), ('average_entropy', -1.0190532), ('temperature', 0.51714026927948)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:856000 episode:33703 last_R: 708.2386100292206 average_R:693.967234711647
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.622995), ('average_q2', 16.592743), ('average_q_func1_loss', 3.5416544485092163), ('average_q_func2_loss', 3.547310461997986), ('n_updates', 845999), ('average_entropy', -1.0009525), ('temperature', 0.5138760209083557)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:857000 episode:33704 last_R: 677.100501537323 average_R:693.5521915841102
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.486362), ('average_q2', 16.45472), ('average_q_func1_loss', 3.530211179256439), ('average_q_func2_loss', 3.5350112819671633), ('n_updates', 846999), ('average_entropy', -0.97274023), ('temperature', 0.5043240189552307)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:858000 episode:33704 last_R: 677.100501537323 average_R:693.5521915841102
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.277372), ('average_q2', 16.316866), ('average_q_func1_loss', 3.4667850017547606), ('average_q_func2_loss', 3.4540190041065215), ('n_updates', 847999), ('average_entropy', -0.97478), ('temperature', 0.5100785493850708)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:859000 episode:33704 last_R: 677.100501537323 average_R:693.5521915841102
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.360794), ('average_q2', 16.376297), ('average_q_func1_loss', 3.571993383169174), ('average_q_func2_loss', 3.552907874584198), ('n_updates', 848999), ('average_entropy', -1.0012493), ('temperature', 0.5121012926101685)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:860000 episode:33707 last_R: 752.9069275856018 average_R:693.147202694416
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.5943), ('average_q2', 16.75837), ('average_q_func1_loss', 3.4642480301856993), ('average_q_func2_loss', 3.4813545298576356), ('n_updates', 849999), ('average_entropy', -0.9772603), ('temperature', 0.5073272585868835)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:861000 episode:33708 last_R: 697.9680695533752 average_R:693.0712459707261
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.01269), ('average_q2', 16.080393), ('average_q_func1_loss', 3.496166677474976), ('average_q_func2_loss', 3.488972885608673), ('n_updates', 850999), ('average_entropy', -1.0160185), ('temperature', 0.511336088180542)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:862000 episode:33708 last_R: 697.9680695533752 average_R:693.0712459707261
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.056023), ('average_q2', 15.983778), ('average_q_func1_loss', 3.4919170260429384), ('average_q_func2_loss', 3.48574879527092), ('n_updates', 851999), ('average_entropy', -1.0290853), ('temperature', 0.5115911960601807)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:863000 episode:33708 last_R: 697.9680695533752 average_R:693.0712459707261
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.120846), ('average_q2', 16.121752), ('average_q_func1_loss', 3.583833134174347), ('average_q_func2_loss', 3.581316683292389), ('n_updates', 852999), ('average_entropy', -1.0612894), ('temperature', 0.5140291452407837)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:864000 episode:33711 last_R: 704.057742357254 average_R:694.4534211683273
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.248882), ('average_q2', 16.260473), ('average_q_func1_loss', 3.6112289595603944), ('average_q_func2_loss', 3.6079692530632017), ('n_updates', 853999), ('average_entropy', -0.9819386), ('temperature', 0.5072661638259888)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:865000 episode:33712 last_R: 728.8515639305115 average_R:694.7130037140846
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.646584), ('average_q2', 16.85746), ('average_q_func1_loss', 3.521806516647339), ('average_q_func2_loss', 3.50609858751297), ('n_updates', 854999), ('average_entropy', -1.072478), ('temperature', 0.5115723013877869)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:866000 episode:33712 last_R: 728.8515639305115 average_R:694.7130037140846
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.71856), ('average_q2', 16.590958), ('average_q_func1_loss', 3.457963619232178), ('average_q_func2_loss', 3.4519453692436217), ('n_updates', 855999), ('average_entropy', -0.934315), ('temperature', 0.5132908225059509)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:867000 episode:33712 last_R: 728.8515639305115 average_R:694.7130037140846
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.36396), ('average_q2', 16.380337), ('average_q_func1_loss', 3.5802705478668213), ('average_q_func2_loss', 3.601856405735016), ('n_updates', 856999), ('average_entropy', -1.0434253), ('temperature', 0.5045652985572815)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:868000 episode:33715 last_R: 734.6615436077118 average_R:695.0877942109108
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.395416), ('average_q2', 16.39578), ('average_q_func1_loss', 3.6266261172294616), ('average_q_func2_loss', 3.64782568693161), ('n_updates', 857999), ('average_entropy', -0.89886546), ('temperature', 0.5110371708869934)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:869000 episode:33716 last_R: 729.9576375484467 average_R:694.8977454185485
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.094204), ('average_q2', 17.111168), ('average_q_func1_loss', 3.3511382651329042), ('average_q_func2_loss', 3.3528690767288207), ('n_updates', 858999), ('average_entropy', -1.0413872), ('temperature', 0.5186008810997009)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:870000 episode:33716 last_R: 729.9576375484467 average_R:694.8977454185485
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.156008), ('average_q2', 16.182943), ('average_q_func1_loss', 3.5804314184188843), ('average_q_func2_loss', 3.5760426259040834), ('n_updates', 859999), ('average_entropy', -1.0658199), ('temperature', 0.5110886096954346)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:871000 episode:33716 last_R: 729.9576375484467 average_R:694.8977454185485
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.834621), ('average_q2', 16.909992), ('average_q_func1_loss', 3.4872604417800903), ('average_q_func2_loss', 3.4961941194534303), ('n_updates', 860999), ('average_entropy', -0.9681985), ('temperature', 0.5116937160491943)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:872000 episode:33719 last_R: 728.9980382919312 average_R:695.0640949511528
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.43305), ('average_q2', 16.395609), ('average_q_func1_loss', 3.337307481765747), ('average_q_func2_loss', 3.3294087147712705), ('n_updates', 861999), ('average_entropy', -1.0659417), ('temperature', 0.510413646697998)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:873000 episode:33720 last_R: 753.5017709732056 average_R:696.023175752163
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.885916), ('average_q2', 16.96534), ('average_q_func1_loss', 3.5301925802230834), ('average_q_func2_loss', 3.533181219100952), ('n_updates', 862999), ('average_entropy', -0.98712295), ('temperature', 0.5117546916007996)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:874000 episode:33720 last_R: 753.5017709732056 average_R:696.023175752163
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.977331), ('average_q2', 16.972403), ('average_q_func1_loss', 3.5383307123184204), ('average_q_func2_loss', 3.52213223695755), ('n_updates', 863999), ('average_entropy', -1.0557705), ('temperature', 0.5054627656936646)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:875000 episode:33720 last_R: 753.5017709732056 average_R:696.023175752163
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.13277), ('average_q2', 17.183834), ('average_q_func1_loss', 3.501332750320435), ('average_q_func2_loss', 3.5145504021644594), ('n_updates', 864999), ('average_entropy', -0.97202045), ('temperature', 0.5170379877090454)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([36, 18, 45,  6], device='cuda:0')
INFO:diayn_sim:disc z: tensor([36, 18, 46,  6])
INFO:diayn_sim:disc loss: 2.3470706939697266
INFO:diayn_sim:top extrinsic: [1000. 1000. 1000. 1000.]
INFO:diayn_sim:last intrinsic: [1.4829698 1.4161134 1.4814534 1.8790724]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:876000 episode:33723 last_R: 672.4151237010956 average_R:697.1715669035912
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.41384), ('average_q2', 16.352348), ('average_q_func1_loss', 3.452532569169998), ('average_q_func2_loss', 3.4369204354286196), ('n_updates', 865999), ('average_entropy', -1.009775), ('temperature', 0.5076408982276917)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:877000 episode:33724 last_R: 685.9942071437836 average_R:697.7335407590866
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.486677), ('average_q2', 16.594213), ('average_q_func1_loss', 3.579703392982483), ('average_q_func2_loss', 3.570584099292755), ('n_updates', 866999), ('average_entropy', -0.9626822), ('temperature', 0.5190734267234802)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:878000 episode:33724 last_R: 685.9942071437836 average_R:697.7335407590866
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.7184), ('average_q2', 16.787222), ('average_q_func1_loss', 3.350631582736969), ('average_q_func2_loss', 3.340042495727539), ('n_updates', 867999), ('average_entropy', -1.0195897), ('temperature', 0.5080991983413696)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:879000 episode:33724 last_R: 685.9942071437836 average_R:697.7335407590866
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.843), ('average_q2', 16.854418), ('average_q_func1_loss', 3.4388156795501708), ('average_q_func2_loss', 3.435642614364624), ('n_updates', 868999), ('average_entropy', -1.0123063), ('temperature', 0.505761981010437)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:880000 episode:33727 last_R: 680.7184245586395 average_R:697.9760255718231
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.51245), ('average_q2', 16.64711), ('average_q_func1_loss', 3.4857828545570375), ('average_q_func2_loss', 3.476563947200775), ('n_updates', 869999), ('average_entropy', -1.0379701), ('temperature', 0.515692412853241)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:881000 episode:33728 last_R: 704.235399723053 average_R:697.925740160942
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.087936), ('average_q2', 17.271755), ('average_q_func1_loss', 3.4573375749588013), ('average_q_func2_loss', 3.4667357110977175), ('n_updates', 870999), ('average_entropy', -1.0325408), ('temperature', 0.5203392505645752)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:882000 episode:33728 last_R: 704.235399723053 average_R:697.925740160942
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.13771), ('average_q2', 17.160889), ('average_q_func1_loss', 3.3356220078468324), ('average_q_func2_loss', 3.3367180263996126), ('n_updates', 871999), ('average_entropy', -0.9670035), ('temperature', 0.5123022198677063)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:883000 episode:33728 last_R: 704.235399723053 average_R:697.925740160942
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.212122), ('average_q2', 16.23263), ('average_q_func1_loss', 3.525482828617096), ('average_q_func2_loss', 3.511648817062378), ('n_updates', 872999), ('average_entropy', -1.0415422), ('temperature', 0.508345901966095)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:884000 episode:33731 last_R: 715.0942330360413 average_R:702.0984443950653
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.31044), ('average_q2', 16.327301), ('average_q_func1_loss', 3.5858957099914552), ('average_q_func2_loss', 3.5779238176345824), ('n_updates', 873999), ('average_entropy', -1.0327419), ('temperature', 0.5082440376281738)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:885000 episode:33732 last_R: 706.7675530910492 average_R:701.8014827418327
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.885466), ('average_q2', 16.85685), ('average_q_func1_loss', 3.508435450792313), ('average_q_func2_loss', 3.509338960647583), ('n_updates', 874999), ('average_entropy', -0.9809158), ('temperature', 0.5093019604682922)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:886000 episode:33732 last_R: 706.7675530910492 average_R:701.8014827418327
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.407804), ('average_q2', 16.36308), ('average_q_func1_loss', 3.4841443157196044), ('average_q_func2_loss', 3.480176956653595), ('n_updates', 875999), ('average_entropy', -0.9693644), ('temperature', 0.5112087726593018)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:887000 episode:33732 last_R: 706.7675530910492 average_R:701.8014827418327
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.941355), ('average_q2', 16.994257), ('average_q_func1_loss', 3.40378187417984), ('average_q_func2_loss', 3.4063579654693603), ('n_updates', 876999), ('average_entropy', -1.0205059), ('temperature', 0.5034945011138916)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:888000 episode:33735 last_R: 687.3186912536621 average_R:701.5411186599731
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.517262), ('average_q2', 16.472775), ('average_q_func1_loss', 3.5294607210159303), ('average_q_func2_loss', 3.531046267747879), ('n_updates', 877999), ('average_entropy', -0.9906675), ('temperature', 0.5109311938285828)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:889000 episode:33736 last_R: 702.1690101623535 average_R:701.5691263103486
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.632269), ('average_q2', 16.650503), ('average_q_func1_loss', 3.539096339941025), ('average_q_func2_loss', 3.5258013784885405), ('n_updates', 878999), ('average_entropy', -1.0187347), ('temperature', 0.5060922503471375)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:890000 episode:33736 last_R: 702.1690101623535 average_R:701.5691263103486
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.75373), ('average_q2', 16.737106), ('average_q_func1_loss', 3.4613992834091185), ('average_q_func2_loss', 3.4615071773529054), ('n_updates', 879999), ('average_entropy', -0.97584313), ('temperature', 0.5093462467193604)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:891000 episode:33736 last_R: 702.1690101623535 average_R:701.5691263103486
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.808613), ('average_q2', 16.858294), ('average_q_func1_loss', 3.449181492328644), ('average_q_func2_loss', 3.445783619880676), ('n_updates', 880999), ('average_entropy', -0.94744116), ('temperature', 0.5149633884429932)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:892000 episode:33739 last_R: 684.0752792358398 average_R:701.6863798618317
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.192026), ('average_q2', 17.123674), ('average_q_func1_loss', 3.5037119293212893), ('average_q_func2_loss', 3.504779872894287), ('n_updates', 881999), ('average_entropy', -1.0215758), ('temperature', 0.5075213313102722)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:893000 episode:33740 last_R: 741.4712460041046 average_R:701.9996875286103
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.770657), ('average_q2', 16.739458), ('average_q_func1_loss', 3.3644899106025696), ('average_q_func2_loss', 3.3650186145305634), ('n_updates', 882999), ('average_entropy', -1.0682454), ('temperature', 0.5038968920707703)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:894000 episode:33740 last_R: 741.4712460041046 average_R:701.9996875286103
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.521626), ('average_q2', 16.593601), ('average_q_func1_loss', 3.4000800895690917), ('average_q_func2_loss', 3.3902464938163757), ('n_updates', 883999), ('average_entropy', -0.9709501), ('temperature', 0.5152489542961121)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:895000 episode:33740 last_R: 741.4712460041046 average_R:701.9996875286103
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.581024), ('average_q2', 16.521421), ('average_q_func1_loss', 3.4302793383598327), ('average_q_func2_loss', 3.4277682590484617), ('n_updates', 884999), ('average_entropy', -1.0178729), ('temperature', 0.5123114585876465)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:896000 episode:33743 last_R: 780.1299786567688 average_R:702.6521533799172
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.9856), ('average_q2', 17.022198), ('average_q_func1_loss', 3.3422944593429564), ('average_q_func2_loss', 3.3303458559513093), ('n_updates', 885999), ('average_entropy', -1.0330077), ('temperature', 0.5081016421318054)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:897000 episode:33744 last_R: 744.5707547664642 average_R:702.8484266376495
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.749283), ('average_q2', 16.871258), ('average_q_func1_loss', 3.472373809814453), ('average_q_func2_loss', 3.4471292686462403), ('n_updates', 886999), ('average_entropy', -1.0526528), ('temperature', 0.5102678537368774)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:898000 episode:33744 last_R: 744.5707547664642 average_R:702.8484266376495
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.387499), ('average_q2', 17.358145), ('average_q_func1_loss', 3.471515040397644), ('average_q_func2_loss', 3.460768723487854), ('n_updates', 887999), ('average_entropy', -1.0032431), ('temperature', 0.5104137659072876)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:899000 episode:33744 last_R: 744.5707547664642 average_R:702.8484266376495
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.666395), ('average_q2', 16.707945), ('average_q_func1_loss', 3.444697206020355), ('average_q_func2_loss', 3.4408560156822205), ('n_updates', 888999), ('average_entropy', -0.9796468), ('temperature', 0.5080190896987915)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:900000 episode:33747 last_R: 738.6861217021942 average_R:703.2442546844483
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.05404), ('average_q2', 17.032385), ('average_q_func1_loss', 3.475039207935333), ('average_q_func2_loss', 3.4705167424678804), ('n_updates', 889999), ('average_entropy', -1.1318396), ('temperature', 0.515018105506897)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([ 4, 49, 17,  2], device='cuda:0')
INFO:diayn_sim:disc z: tensor([ 4, 47, 17,  1])
INFO:diayn_sim:disc loss: 2.4826536178588867
INFO:diayn_sim:top extrinsic: [1000. 1000. 1000. 1000.]
INFO:diayn_sim:last intrinsic: [1.430958  1.3693008 1.4861722 1.4308457]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:901000 episode:33748 last_R: 707.5090386867523 average_R:710.0858060765266
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.545677), ('average_q2', 16.65399), ('average_q_func1_loss', 3.4509368681907655), ('average_q_func2_loss', 3.4497386050224303), ('n_updates', 890999), ('average_entropy', -0.9832294), ('temperature', 0.5078602433204651)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:902000 episode:33748 last_R: 707.5090386867523 average_R:710.0858060765266
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.559875), ('average_q2', 16.540298), ('average_q_func1_loss', 3.20059819817543), ('average_q_func2_loss', 3.209324474334717), ('n_updates', 891999), ('average_entropy', -0.9705515), ('temperature', 0.5075303912162781)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:903000 episode:33748 last_R: 707.5090386867523 average_R:710.0858060765266
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.043968), ('average_q2', 16.99802), ('average_q_func1_loss', 3.3127472853660582), ('average_q_func2_loss', 3.310098248720169), ('n_updates', 892999), ('average_entropy', -0.9373055), ('temperature', 0.516834020614624)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:904000 episode:33751 last_R: 667.6316392421722 average_R:710.4098998737335
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.249563), ('average_q2', 16.352922), ('average_q_func1_loss', 3.4557639479637148), ('average_q_func2_loss', 3.4651926875114443), ('n_updates', 893999), ('average_entropy', -0.8691588), ('temperature', 0.5049738883972168)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:905000 episode:33752 last_R: 691.7273325920105 average_R:710.8850731778144
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.562752), ('average_q2', 17.536152), ('average_q_func1_loss', 3.4767513918876647), ('average_q_func2_loss', 3.4749915528297426), ('n_updates', 894999), ('average_entropy', -1.032597), ('temperature', 0.5068848729133606)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:906000 episode:33752 last_R: 691.7273325920105 average_R:710.8850731778144
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.723156), ('average_q2', 17.658663), ('average_q_func1_loss', 3.4704638075828553), ('average_q_func2_loss', 3.4650671243667603), ('n_updates', 895999), ('average_entropy', -0.9955474), ('temperature', 0.5126908421516418)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:907000 episode:33752 last_R: 691.7273325920105 average_R:710.8850731778144
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.260733), ('average_q2', 17.22058), ('average_q_func1_loss', 3.37749857544899), ('average_q_func2_loss', 3.381472170352936), ('n_updates', 896999), ('average_entropy', -1.0803599), ('temperature', 0.5126672387123108)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:908000 episode:33755 last_R: 701.7562961578369 average_R:711.0697026252747
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.257736), ('average_q2', 17.317926), ('average_q_func1_loss', 3.4933821415901183), ('average_q_func2_loss', 3.488517689704895), ('n_updates', 897999), ('average_entropy', -0.9917372), ('temperature', 0.5026532411575317)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:909000 episode:33756 last_R: 712.1690237522125 average_R:711.4284594750404
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.374464), ('average_q2', 16.397125), ('average_q_func1_loss', 3.375780804157257), ('average_q_func2_loss', 3.3906100606918335), ('n_updates', 898999), ('average_entropy', -1.0416676), ('temperature', 0.5132721066474915)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:910000 episode:33756 last_R: 712.1690237522125 average_R:711.4284594750404
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.32978), ('average_q2', 17.357727), ('average_q_func1_loss', 3.439484882354736), ('average_q_func2_loss', 3.446415603160858), ('n_updates', 899999), ('average_entropy', -0.9861121), ('temperature', 0.5095571279525757)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:911000 episode:33756 last_R: 712.1690237522125 average_R:711.4284594750404
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.41972), ('average_q2', 16.426851), ('average_q_func1_loss', 3.4321070098876953), ('average_q_func2_loss', 3.430134619474411), ('n_updates', 900999), ('average_entropy', -0.96878916), ('temperature', 0.5039944648742676)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:912000 episode:33759 last_R: 725.4208235740662 average_R:712.1444212412835
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.747652), ('average_q2', 16.875296), ('average_q_func1_loss', 3.405373694896698), ('average_q_func2_loss', 3.390589756965637), ('n_updates', 901999), ('average_entropy', -1.0578814), ('temperature', 0.5141814947128296)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:913000 episode:33760 last_R: 708.441980600357 average_R:712.0616090345383
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.738165), ('average_q2', 17.72612), ('average_q_func1_loss', 3.3825057792663573), ('average_q_func2_loss', 3.3802484345436095), ('n_updates', 902999), ('average_entropy', -0.92230856), ('temperature', 0.5135877132415771)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:914000 episode:33760 last_R: 708.441980600357 average_R:712.0616090345383
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.061625), ('average_q2', 17.124538), ('average_q_func1_loss', 3.4520430755615235), ('average_q_func2_loss', 3.441632239818573), ('n_updates', 903999), ('average_entropy', -1.0109746), ('temperature', 0.5124847888946533)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:915000 episode:33760 last_R: 708.441980600357 average_R:712.0616090345383
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.342955), ('average_q2', 16.399366), ('average_q_func1_loss', 3.3611602878570555), ('average_q_func2_loss', 3.363801279067993), ('n_updates', 904999), ('average_entropy', -0.9878011), ('temperature', 0.5057938694953918)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:916000 episode:33763 last_R: 721.6771302223206 average_R:712.7518496918678
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.122818), ('average_q2', 17.098696), ('average_q_func1_loss', 3.4110392260551454), ('average_q_func2_loss', 3.398469908237457), ('n_updates', 905999), ('average_entropy', -1.0005575), ('temperature', 0.5121349096298218)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:917000 episode:33764 last_R: 704.372992515564 average_R:712.5849401521683
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.661324), ('average_q2', 16.71118), ('average_q_func1_loss', 3.4299897599220275), ('average_q_func2_loss', 3.432348803281784), ('n_updates', 906999), ('average_entropy', -1.0183898), ('temperature', 0.5122247338294983)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:918000 episode:33764 last_R: 704.372992515564 average_R:712.5849401521683
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.809786), ('average_q2', 16.894573), ('average_q_func1_loss', 3.441721773147583), ('average_q_func2_loss', 3.432448389530182), ('n_updates', 907999), ('average_entropy', -0.9081725), ('temperature', 0.5042154788970947)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:919000 episode:33764 last_R: 704.372992515564 average_R:712.5849401521683
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.189846), ('average_q2', 17.105562), ('average_q_func1_loss', 3.3364962673187257), ('average_q_func2_loss', 3.3479326438903807), ('n_updates', 908999), ('average_entropy', -0.979131), ('temperature', 0.5040594339370728)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:920000 episode:33767 last_R: 704.6958649158478 average_R:711.7327821969986
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.67713), ('average_q2', 17.662102), ('average_q_func1_loss', 3.3684008884429932), ('average_q_func2_loss', 3.347155315876007), ('n_updates', 909999), ('average_entropy', -0.9995572), ('temperature', 0.5046902894973755)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:921000 episode:33768 last_R: 746.3442938327789 average_R:712.0504294633865
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.173212), ('average_q2', 17.113588), ('average_q_func1_loss', 3.4389554047584534), ('average_q_func2_loss', 3.44234601020813), ('n_updates', 910999), ('average_entropy', -1.009686), ('temperature', 0.4963683485984802)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:922000 episode:33768 last_R: 746.3442938327789 average_R:712.0504294633865
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.138195), ('average_q2', 17.083733), ('average_q_func1_loss', 3.3953724551200866), ('average_q_func2_loss', 3.390559356212616), ('n_updates', 911999), ('average_entropy', -0.9751483), ('temperature', 0.5095478296279907)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:923000 episode:33768 last_R: 746.3442938327789 average_R:712.0504294633865
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.062193), ('average_q2', 17.05599), ('average_q_func1_loss', 3.4594462084770203), ('average_q_func2_loss', 3.468527903556824), ('n_updates', 912999), ('average_entropy', -1.0077268), ('temperature', 0.5163356065750122)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:924000 episode:33771 last_R: 726.0593476295471 average_R:712.9311206698418
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.765234), ('average_q2', 16.812), ('average_q_func1_loss', 3.417960205078125), ('average_q_func2_loss', 3.40705269575119), ('n_updates', 913999), ('average_entropy', -1.0423062), ('temperature', 0.502322793006897)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:925000 episode:33772 last_R: 735.2164216041565 average_R:713.2209085059166
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.173273), ('average_q2', 17.244738), ('average_q_func1_loss', 3.580464391708374), ('average_q_func2_loss', 3.578684344291687), ('n_updates', 914999), ('average_entropy', -0.99803483), ('temperature', 0.5096105933189392)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([ 2, 29,  6, 28], device='cuda:0')
INFO:diayn_sim:disc z: tensor([ 0, 27, 47, 32])
INFO:diayn_sim:disc loss: 2.5671873092651367
INFO:diayn_sim:top extrinsic: [1000. 1000. 1000. 1000.]
INFO:diayn_sim:last intrinsic: [1.4262304 1.4650807 1.427537  1.0602944]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:926000 episode:33772 last_R: 735.2164216041565 average_R:713.2209085059166
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.32693), ('average_q2', 17.429926), ('average_q_func1_loss', 3.379597523212433), ('average_q_func2_loss', 3.381350600719452), ('n_updates', 915999), ('average_entropy', -1.028358), ('temperature', 0.5001881122589111)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:927000 episode:33772 last_R: 735.2164216041565 average_R:713.2209085059166
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.997627), ('average_q2', 17.02002), ('average_q_func1_loss', 3.464876947402954), ('average_q_func2_loss', 3.4644988274574278), ('n_updates', 916999), ('average_entropy', -1.019025), ('temperature', 0.5083747506141663)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:928000 episode:33775 last_R: 638.5588328838348 average_R:712.8312710022926
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.832487), ('average_q2', 17.833815), ('average_q_func1_loss', 3.605425179004669), ('average_q_func2_loss', 3.594604768753052), ('n_updates', 917999), ('average_entropy', -1.0118804), ('temperature', 0.510554313659668)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:929000 episode:33776 last_R: 668.2417078018188 average_R:713.0089861774445
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.277374), ('average_q2', 17.212585), ('average_q_func1_loss', 3.450173091888428), ('average_q_func2_loss', 3.4476093554496767), ('n_updates', 918999), ('average_entropy', -1.0348682), ('temperature', 0.5071247816085815)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:930000 episode:33776 last_R: 668.2417078018188 average_R:713.0089861774445
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.489399), ('average_q2', 17.493624), ('average_q_func1_loss', 3.402106701135635), ('average_q_func2_loss', 3.430493624210358), ('n_updates', 919999), ('average_entropy', -0.99019235), ('temperature', 0.5079266428947449)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:931000 episode:33776 last_R: 668.2417078018188 average_R:713.0089861774445
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.720085), ('average_q2', 16.789225), ('average_q_func1_loss', 3.4888509249687196), ('average_q_func2_loss', 3.4908195877075197), ('n_updates', 920999), ('average_entropy', -1.0123688), ('temperature', 0.5178064107894897)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:932000 episode:33779 last_R: 706.3975744247437 average_R:712.4195917153359
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.348873), ('average_q2', 17.356396), ('average_q_func1_loss', 3.4138671135902405), ('average_q_func2_loss', 3.3982867336273195), ('n_updates', 921999), ('average_entropy', -0.9498157), ('temperature', 0.5088847875595093)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:933000 episode:33780 last_R: 709.4659485816956 average_R:712.533865249157
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.587774), ('average_q2', 17.538418), ('average_q_func1_loss', 3.30959690451622), ('average_q_func2_loss', 3.31348162651062), ('n_updates', 922999), ('average_entropy', -1.0465903), ('temperature', 0.5081604719161987)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:934000 episode:33780 last_R: 709.4659485816956 average_R:712.533865249157
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.198454), ('average_q2', 17.246895), ('average_q_func1_loss', 3.3129830169677734), ('average_q_func2_loss', 3.310484817028046), ('n_updates', 923999), ('average_entropy', -0.98589545), ('temperature', 0.5180881023406982)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:935000 episode:33780 last_R: 709.4659485816956 average_R:712.533865249157
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.149748), ('average_q2', 16.987547), ('average_q_func1_loss', 3.4068455362319945), ('average_q_func2_loss', 3.400305197238922), ('n_updates', 924999), ('average_entropy', -0.97948337), ('temperature', 0.5090399384498596)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:936000 episode:33783 last_R: 734.3163702487946 average_R:713.55703540802
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.15275), ('average_q2', 18.093039), ('average_q_func1_loss', 3.4700098991394044), ('average_q_func2_loss', 3.4503072023391725), ('n_updates', 925999), ('average_entropy', -1.0012512), ('temperature', 0.5147138833999634)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:937000 episode:33784 last_R: 732.8066804409027 average_R:713.6175508141517
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.81864), ('average_q2', 17.66063), ('average_q_func1_loss', 3.423175097703934), ('average_q_func2_loss', 3.42454558134079), ('n_updates', 926999), ('average_entropy', -1.0058811), ('temperature', 0.5112212896347046)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:938000 episode:33784 last_R: 732.8066804409027 average_R:713.6175508141517
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.243538), ('average_q2', 17.28047), ('average_q_func1_loss', 3.3507016599178314), ('average_q_func2_loss', 3.346881340742111), ('n_updates', 927999), ('average_entropy', -0.9862936), ('temperature', 0.5197900533676147)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:939000 episode:33784 last_R: 732.8066804409027 average_R:713.6175508141517
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.47906), ('average_q2', 17.39341), ('average_q_func1_loss', 3.3923701882362365), ('average_q_func2_loss', 3.3921790671348573), ('n_updates', 928999), ('average_entropy', -1.0655321), ('temperature', 0.5132954716682434)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:940000 episode:33787 last_R: 716.3962957859039 average_R:713.3564790201187
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.823223), ('average_q2', 16.751312), ('average_q_func1_loss', 3.4390863251686095), ('average_q_func2_loss', 3.430746419429779), ('n_updates', 929999), ('average_entropy', -1.0188912), ('temperature', 0.5151468515396118)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:941000 episode:33788 last_R: 710.0076620578766 average_R:713.6658181929588
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.566383), ('average_q2', 17.538246), ('average_q_func1_loss', 3.427292859554291), ('average_q_func2_loss', 3.4370348191261293), ('n_updates', 930999), ('average_entropy', -0.92497545), ('temperature', 0.520171046257019)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:942000 episode:33788 last_R: 710.0076620578766 average_R:713.6658181929588
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.569862), ('average_q2', 16.648216), ('average_q_func1_loss', 3.378119955062866), ('average_q_func2_loss', 3.3887672209739685), ('n_updates', 931999), ('average_entropy', -1.071002), ('temperature', 0.5111386775970459)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:943000 episode:33788 last_R: 710.0076620578766 average_R:713.6658181929588
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.945805), ('average_q2', 17.076958), ('average_q_func1_loss', 3.4561459183692933), ('average_q_func2_loss', 3.43978755235672), ('n_updates', 932999), ('average_entropy', -0.9746958), ('temperature', 0.511086642742157)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:944000 episode:33791 last_R: 746.9187676906586 average_R:714.0282966566086
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.019419), ('average_q2', 17.09993), ('average_q_func1_loss', 3.3427400541305543), ('average_q_func2_loss', 3.3352414071559906), ('n_updates', 933999), ('average_entropy', -1.0642637), ('temperature', 0.5130776166915894)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:945000 episode:33792 last_R: 708.0708436965942 average_R:713.5403153371811
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.697054), ('average_q2', 17.59337), ('average_q_func1_loss', 3.374075422286987), ('average_q_func2_loss', 3.379072560071945), ('n_updates', 934999), ('average_entropy', -0.9600499), ('temperature', 0.5155410766601562)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:946000 episode:33792 last_R: 708.0708436965942 average_R:713.5403153371811
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.410364), ('average_q2', 18.433186), ('average_q_func1_loss', 3.3496681475639343), ('average_q_func2_loss', 3.3398655915260314), ('n_updates', 935999), ('average_entropy', -1.0441192), ('temperature', 0.5084125995635986)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:947000 episode:33792 last_R: 708.0708436965942 average_R:713.5403153371811
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.35259), ('average_q2', 17.351065), ('average_q_func1_loss', 3.307984272241592), ('average_q_func2_loss', 3.311331080198288), ('n_updates', 936999), ('average_entropy', -0.98063385), ('temperature', 0.5118615031242371)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:948000 episode:33795 last_R: 745.9392621517181 average_R:713.4244077754021
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.089378), ('average_q2', 18.02671), ('average_q_func1_loss', 3.357610672712326), ('average_q_func2_loss', 3.3513380348682404), ('n_updates', 937999), ('average_entropy', -1.0352471), ('temperature', 0.5097633004188538)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:949000 episode:33796 last_R: 752.3786406517029 average_R:713.2368703269958
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.587553), ('average_q2', 17.585657), ('average_q_func1_loss', 3.2823670649528505), ('average_q_func2_loss', 3.286264238357544), ('n_updates', 938999), ('average_entropy', -1.0301925), ('temperature', 0.50688236951828)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:950000 episode:33796 last_R: 752.3786406517029 average_R:713.2368703269958
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.46976), ('average_q2', 17.471205), ('average_q_func1_loss', 3.546072311401367), ('average_q_func2_loss', 3.536313121318817), ('n_updates', 939999), ('average_entropy', -0.91974586), ('temperature', 0.5170876383781433)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([ 5,  5, 29,  7], device='cuda:0')
INFO:diayn_sim:disc z: tensor([ 4,  5, 23, 46])
INFO:diayn_sim:disc loss: 2.486816883087158
INFO:diayn_sim:top extrinsic: [1000. 1000. 1000. 1000.]
INFO:diayn_sim:last intrinsic: [1.5127783 1.5507073 1.3081548 1.3289831]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:951000 episode:33796 last_R: 752.3786406517029 average_R:713.2368703269958
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.328232), ('average_q2', 17.33891), ('average_q_func1_loss', 3.345506236553192), ('average_q_func2_loss', 3.3269275963306426), ('n_updates', 940999), ('average_entropy', -1.015617), ('temperature', 0.5148580074310303)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:952000 episode:33799 last_R: 689.2748906612396 average_R:713.5556311964989
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.175943), ('average_q2', 17.151182), ('average_q_func1_loss', 3.34293860912323), ('average_q_func2_loss', 3.361096104383469), ('n_updates', 941999), ('average_entropy', -1.004297), ('temperature', 0.5007655620574951)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:953000 episode:33800 last_R: 717.1509220600128 average_R:713.8930036592484
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.994438), ('average_q2', 16.997509), ('average_q_func1_loss', 3.321380338668823), ('average_q_func2_loss', 3.3139285790920257), ('n_updates', 942999), ('average_entropy', -0.95101774), ('temperature', 0.5058065056800842)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:954000 episode:33800 last_R: 717.1509220600128 average_R:713.8930036592484
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.813597), ('average_q2', 17.753338), ('average_q_func1_loss', 3.340684721469879), ('average_q_func2_loss', 3.340626142024994), ('n_updates', 943999), ('average_entropy', -0.9607417), ('temperature', 0.5096811652183533)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:955000 episode:33800 last_R: 717.1509220600128 average_R:713.8930036592484
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.301695), ('average_q2', 17.448622), ('average_q_func1_loss', 3.337196342945099), ('average_q_func2_loss', 3.337097713947296), ('n_updates', 944999), ('average_entropy', -0.91050124), ('temperature', 0.5099532604217529)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:956000 episode:33803 last_R: 740.3089709281921 average_R:714.1658453297615
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 16.938406), ('average_q2', 17.085018), ('average_q_func1_loss', 3.4156999826431274), ('average_q_func2_loss', 3.419164056777954), ('n_updates', 945999), ('average_entropy', -0.97363305), ('temperature', 0.5181515216827393)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:957000 episode:33804 last_R: 729.4958567619324 average_R:714.6897988820076
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.712976), ('average_q2', 17.714394), ('average_q_func1_loss', 3.359596024751663), ('average_q_func2_loss', 3.3364661991596223), ('n_updates', 946999), ('average_entropy', -1.0204325), ('temperature', 0.50739985704422)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:958000 episode:33804 last_R: 729.4958567619324 average_R:714.6897988820076
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.464443), ('average_q2', 17.518969), ('average_q_func1_loss', 3.407796714305878), ('average_q_func2_loss', 3.4223368406295775), ('n_updates', 947999), ('average_entropy', -0.96022207), ('temperature', 0.5096799731254578)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:959000 episode:33804 last_R: 729.4958567619324 average_R:714.6897988820076
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.441809), ('average_q2', 18.401665), ('average_q_func1_loss', 3.4663691759109496), ('average_q_func2_loss', 3.4739829969406126), ('n_updates', 948999), ('average_entropy', -1.0013918), ('temperature', 0.5081839561462402)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:960000 episode:33807 last_R: 752.6004819869995 average_R:715.9862888121605
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.693695), ('average_q2', 17.632126), ('average_q_func1_loss', 3.398484102487564), ('average_q_func2_loss', 3.394729118347168), ('n_updates', 949999), ('average_entropy', -0.98443407), ('temperature', 0.5104299187660217)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:961000 episode:33808 last_R: 728.4676773548126 average_R:716.2912848901749
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.964296), ('average_q2', 18.016045), ('average_q_func1_loss', 3.2825171041488646), ('average_q_func2_loss', 3.2663809168338775), ('n_updates', 950999), ('average_entropy', -1.0184389), ('temperature', 0.5154233574867249)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:962000 episode:33808 last_R: 728.4676773548126 average_R:716.2912848901749
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.38541), ('average_q2', 17.411673), ('average_q_func1_loss', 3.3052813243865966), ('average_q_func2_loss', 3.2915990221500397), ('n_updates', 951999), ('average_entropy', -0.96489114), ('temperature', 0.5127356052398682)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:963000 episode:33808 last_R: 728.4676773548126 average_R:716.2912848901749
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.833454), ('average_q2', 17.798244), ('average_q_func1_loss', 3.393495066165924), ('average_q_func2_loss', 3.3991522765159607), ('n_updates', 952999), ('average_entropy', -0.9549492), ('temperature', 0.5141443610191345)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:964000 episode:33811 last_R: 689.5568044185638 average_R:716.3498643898964
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.503), ('average_q2', 17.44655), ('average_q_func1_loss', 3.3466547417640684), ('average_q_func2_loss', 3.3403274261951448), ('n_updates', 953999), ('average_entropy', -1.0373274), ('temperature', 0.5184024572372437)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:965000 episode:33812 last_R: 738.134256362915 average_R:716.4426913142204
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.085108), ('average_q2', 17.018007), ('average_q_func1_loss', 3.2689285361766816), ('average_q_func2_loss', 3.2888639092445375), ('n_updates', 954999), ('average_entropy', -1.0229228), ('temperature', 0.5094127058982849)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:966000 episode:33812 last_R: 738.134256362915 average_R:716.4426913142204
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.131512), ('average_q2', 18.240816), ('average_q_func1_loss', 3.3540580606460573), ('average_q_func2_loss', 3.3428683924674987), ('n_updates', 955999), ('average_entropy', -0.9948545), ('temperature', 0.5068445801734924)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:967000 episode:33812 last_R: 738.134256362915 average_R:716.4426913142204
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.783112), ('average_q2', 17.71552), ('average_q_func1_loss', 3.300834195613861), ('average_q_func2_loss', 3.313148832321167), ('n_updates', 956999), ('average_entropy', -0.9960834), ('temperature', 0.5146721601486206)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:968000 episode:33815 last_R: 718.8471081256866 average_R:716.3465811371804
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.818277), ('average_q2', 17.745258), ('average_q_func1_loss', 3.392326047420502), ('average_q_func2_loss', 3.3925615096092225), ('n_updates', 957999), ('average_entropy', -0.93712574), ('temperature', 0.5151839256286621)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:969000 episode:33816 last_R: 694.3773720264435 average_R:715.9907784819603
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.794075), ('average_q2', 17.869024), ('average_q_func1_loss', 3.263654685020447), ('average_q_func2_loss', 3.251089017391205), ('n_updates', 958999), ('average_entropy', -0.9140806), ('temperature', 0.5135960578918457)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:970000 episode:33816 last_R: 694.3773720264435 average_R:715.9907784819603
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.080448), ('average_q2', 17.30718), ('average_q_func1_loss', 3.36576501250267), ('average_q_func2_loss', 3.3585060918331147), ('n_updates', 959999), ('average_entropy', -0.96417916), ('temperature', 0.522973895072937)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:971000 episode:33816 last_R: 694.3773720264435 average_R:715.9907784819603
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.382118), ('average_q2', 17.421398), ('average_q_func1_loss', 3.2609007787704467), ('average_q_func2_loss', 3.2548410391807554), ('n_updates', 960999), ('average_entropy', -0.9673916), ('temperature', 0.5145828127861023)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:972000 episode:33819 last_R: 709.0860221385956 average_R:716.3305101132393
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.550209), ('average_q2', 17.436699), ('average_q_func1_loss', 3.3315050339698793), ('average_q_func2_loss', 3.3337260520458223), ('n_updates', 961999), ('average_entropy', -1.0337862), ('temperature', 0.5156394243240356)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:973000 episode:33820 last_R: 742.6877644062042 average_R:716.2223700475693
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.572037), ('average_q2', 17.497562), ('average_q_func1_loss', 3.2065501725673675), ('average_q_func2_loss', 3.1998318207263945), ('n_updates', 962999), ('average_entropy', -0.98006827), ('temperature', 0.5105842351913452)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:974000 episode:33820 last_R: 742.6877644062042 average_R:716.2223700475693
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.447624), ('average_q2', 17.442698), ('average_q_func1_loss', 3.2783711898326873), ('average_q_func2_loss', 3.291523725986481), ('n_updates', 963999), ('average_entropy', -1.0541017), ('temperature', 0.5132235884666443)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:975000 episode:33820 last_R: 742.6877644062042 average_R:716.2223700475693
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.46615), ('average_q2', 17.465351), ('average_q_func1_loss', 3.332129383087158), ('average_q_func2_loss', 3.334181559085846), ('n_updates', 964999), ('average_entropy', -0.99188375), ('temperature', 0.520992636680603)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([16,  5,  4, 18], device='cuda:0')
INFO:diayn_sim:disc z: tensor([16, 45, 49, 36])
INFO:diayn_sim:disc loss: 2.3845102787017822
INFO:diayn_sim:top extrinsic: [1000. 1000. 1000. 1000.]
INFO:diayn_sim:last intrinsic: [1.6095347 1.5488026 1.512269  1.4392447]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:976000 episode:33823 last_R: 727.191773891449 average_R:716.4841844201088
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.060537), ('average_q2', 18.09116), ('average_q_func1_loss', 3.1445118594169617), ('average_q_func2_loss', 3.1456046152114867), ('n_updates', 965999), ('average_entropy', -0.93577343), ('temperature', 0.51157546043396)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:977000 episode:33824 last_R: 650.2012112140656 average_R:716.1262544608117
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.197626), ('average_q2', 18.235582), ('average_q_func1_loss', 3.3855644416809083), ('average_q_func2_loss', 3.390110889673233), ('n_updates', 966999), ('average_entropy', -1.0000399), ('temperature', 0.5125601887702942)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:978000 episode:33824 last_R: 650.2012112140656 average_R:716.1262544608117
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.39458), ('average_q2', 17.398333), ('average_q_func1_loss', 3.360470519065857), ('average_q_func2_loss', 3.342813587188721), ('n_updates', 967999), ('average_entropy', -0.96796143), ('temperature', 0.5195636749267578)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:979000 episode:33824 last_R: 650.2012112140656 average_R:716.1262544608117
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.324669), ('average_q2', 17.273434), ('average_q_func1_loss', 3.3614351606369017), ('average_q_func2_loss', 3.34085773229599), ('n_updates', 968999), ('average_entropy', -0.98319703), ('temperature', 0.5169644951820374)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:980000 episode:33827 last_R: 696.6826810836792 average_R:716.4397371697426
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.803066), ('average_q2', 17.708202), ('average_q_func1_loss', 3.2675951611995697), ('average_q_func2_loss', 3.2656822347640992), ('n_updates', 969999), ('average_entropy', -1.0153614), ('temperature', 0.5161500573158264)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:981000 episode:33828 last_R: 718.076354265213 average_R:716.5781467151642
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.808743), ('average_q2', 17.854197), ('average_q_func1_loss', 3.20293615937233), ('average_q_func2_loss', 3.192000629901886), ('n_updates', 970999), ('average_entropy', -1.0367578), ('temperature', 0.5104166865348816)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:982000 episode:33828 last_R: 718.076354265213 average_R:716.5781467151642
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.40359), ('average_q2', 18.369226), ('average_q_func1_loss', 3.3170255041122436), ('average_q_func2_loss', 3.3221310806274413), ('n_updates', 971999), ('average_entropy', -0.96339023), ('temperature', 0.514623761177063)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:983000 episode:33828 last_R: 718.076354265213 average_R:716.5781467151642
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.259645), ('average_q2', 18.22768), ('average_q_func1_loss', 3.3398664355278016), ('average_q_func2_loss', 3.3445445728302), ('n_updates', 972999), ('average_entropy', -1.0230434), ('temperature', 0.5111512541770935)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:984000 episode:33831 last_R: 756.5215876102448 average_R:717.7171889448166
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.22262), ('average_q2', 18.357552), ('average_q_func1_loss', 3.3438760805130006), ('average_q_func2_loss', 3.352503433227539), ('n_updates', 973999), ('average_entropy', -0.99154246), ('temperature', 0.5186416506767273)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:985000 episode:33832 last_R: 714.9039404392242 average_R:717.7985528182984
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.748804), ('average_q2', 17.744608), ('average_q_func1_loss', 3.418967719078064), ('average_q_func2_loss', 3.4183995938301086), ('n_updates', 974999), ('average_entropy', -0.94227225), ('temperature', 0.5212699174880981)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:986000 episode:33832 last_R: 714.9039404392242 average_R:717.7985528182984
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.362368), ('average_q2', 18.353983), ('average_q_func1_loss', 3.2424526381492615), ('average_q_func2_loss', 3.2263789117336272), ('n_updates', 975999), ('average_entropy', -1.0214263), ('temperature', 0.5195367932319641)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:987000 episode:33832 last_R: 714.9039404392242 average_R:717.7985528182984
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.886906), ('average_q2', 17.913404), ('average_q_func1_loss', 3.35533612370491), ('average_q_func2_loss', 3.3518569111824035), ('n_updates', 976999), ('average_entropy', -0.9950904), ('temperature', 0.5251973867416382)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:988000 episode:33835 last_R: 716.4606575965881 average_R:718.4704347801209
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.07364), ('average_q2', 18.095652), ('average_q_func1_loss', 3.2070099973678587), ('average_q_func2_loss', 3.2082339584827424), ('n_updates', 977999), ('average_entropy', -0.9988713), ('temperature', 0.5256878733634949)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:989000 episode:33836 last_R: 764.5519342422485 average_R:719.0942640209198
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.741526), ('average_q2', 17.739887), ('average_q_func1_loss', 3.263968651294708), ('average_q_func2_loss', 3.2711043548583985), ('n_updates', 978999), ('average_entropy', -0.9539673), ('temperature', 0.5206287503242493)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:990000 episode:33836 last_R: 764.5519342422485 average_R:719.0942640209198
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.568922), ('average_q2', 18.519054), ('average_q_func1_loss', 3.247318869829178), ('average_q_func2_loss', 3.2468910384178162), ('n_updates', 979999), ('average_entropy', -1.0974709), ('temperature', 0.5178492665290833)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:991000 episode:33836 last_R: 764.5519342422485 average_R:719.0942640209198
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.129429), ('average_q2', 17.229725), ('average_q_func1_loss', 3.2021959090232848), ('average_q_func2_loss', 3.202102290391922), ('n_updates', 980999), ('average_entropy', -1.0414988), ('temperature', 0.5140778422355652)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:992000 episode:33839 last_R: 723.1689946651459 average_R:719.3655344247818
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.421614), ('average_q2', 17.462605), ('average_q_func1_loss', 3.2196660792827605), ('average_q_func2_loss', 3.220997339487076), ('n_updates', 981999), ('average_entropy', -0.9753727), ('temperature', 0.5197954773902893)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:993000 episode:33840 last_R: 744.4096145629883 average_R:719.3949181103707
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.413086), ('average_q2', 17.407217), ('average_q_func1_loss', 3.3206230902671816), ('average_q_func2_loss', 3.316276934146881), ('n_updates', 982999), ('average_entropy', -0.97897893), ('temperature', 0.5168038606643677)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:994000 episode:33840 last_R: 744.4096145629883 average_R:719.3949181103707
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.98754), ('average_q2', 17.910852), ('average_q_func1_loss', 3.2677897810935974), ('average_q_func2_loss', 3.261415331363678), ('n_updates', 983999), ('average_entropy', -0.9815365), ('temperature', 0.5236904621124268)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:995000 episode:33840 last_R: 744.4096145629883 average_R:719.3949181103707
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.446148), ('average_q2', 17.302523), ('average_q_func1_loss', 3.199055207967758), ('average_q_func2_loss', 3.2034331870079042), ('n_updates', 984999), ('average_entropy', -0.9774841), ('temperature', 0.5210627317428589)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:996000 episode:33843 last_R: 735.0418429374695 average_R:719.9442203187942
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.524624), ('average_q2', 17.619938), ('average_q_func1_loss', 3.2746538805961607), ('average_q_func2_loss', 3.2829546725749967), ('n_updates', 985999), ('average_entropy', -1.02812), ('temperature', 0.5176060795783997)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:997000 episode:33844 last_R: 718.3708462715149 average_R:719.6822212338448
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.499218), ('average_q2', 18.481758), ('average_q_func1_loss', 3.4041559529304504), ('average_q_func2_loss', 3.4139107990264894), ('n_updates', 986999), ('average_entropy', -0.9289115), ('temperature', 0.5228754878044128)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:998000 episode:33844 last_R: 718.3708462715149 average_R:719.6822212338448
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.10882), ('average_q2', 17.974836), ('average_q_func1_loss', 3.1687496089935303), ('average_q_func2_loss', 3.1651311564445495), ('n_updates', 987999), ('average_entropy', -1.0028257), ('temperature', 0.5191305875778198)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:999000 episode:33845 last_R: 647.8504452705383 average_R:718.6494962120056
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.20473), ('average_q2', 18.204441), ('average_q_func1_loss', 3.254744348526001), ('average_q_func2_loss', 3.262088243961334), ('n_updates', 988999), ('average_entropy', -1.0329878), ('temperature', 0.5142877697944641)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1000000 episode:33847 last_R: 754.9499740600586 average_R:718.6452997112274
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.957859), ('average_q2', 17.921196), ('average_q_func1_loss', 3.1520492529869077), ('average_q_func2_loss', 3.158082522153854), ('n_updates', 989999), ('average_entropy', -0.9690602), ('temperature', 0.5153142809867859)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([30,  4, 13, 17], device='cuda:0')
INFO:diayn_sim:disc z: tensor([25, 48, 13, 17])
INFO:diayn_sim:disc loss: 2.9820213317871094
INFO:diayn_sim:top extrinsic: [1000. 1000. 1000. 1000.]
INFO:diayn_sim:last intrinsic: [-0.5516348  1.1930661  1.530241   1.5481341]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1001000 episode:33848 last_R: 719.8960480690002 average_R:718.7691698050498
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.423922), ('average_q2', 18.315453), ('average_q_func1_loss', 3.2624966323375704), ('average_q_func2_loss', 3.2696264457702635), ('n_updates', 990999), ('average_entropy', -0.9314122), ('temperature', 0.5252625346183777)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1002000 episode:33848 last_R: 719.8960480690002 average_R:718.7691698050498
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.946886), ('average_q2', 18.042683), ('average_q_func1_loss', 3.1388127756118775), ('average_q_func2_loss', 3.134397743940353), ('n_updates', 991999), ('average_entropy', -0.9990604), ('temperature', 0.5245341658592224)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1003000 episode:33849 last_R: 679.8221957683563 average_R:719.0351728034019
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.16483), ('average_q2', 18.206766), ('average_q_func1_loss', 3.096328104734421), ('average_q_func2_loss', 3.0948881125450134), ('n_updates', 992999), ('average_entropy', -0.9701663), ('temperature', 0.5247650742530823)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1004000 episode:33851 last_R: 680.2472302913666 average_R:718.7087982559204
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.074501), ('average_q2', 18.070671), ('average_q_func1_loss', 3.2103621339797974), ('average_q_func2_loss', 3.2232926297187805), ('n_updates', 993999), ('average_entropy', -1.0366924), ('temperature', 0.5184504985809326)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1005000 episode:33852 last_R: 692.6722135543823 average_R:718.7182470655441
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.306469), ('average_q2', 17.465103), ('average_q_func1_loss', 3.2590668773651124), ('average_q_func2_loss', 3.273706033229828), ('n_updates', 994999), ('average_entropy', -0.94386816), ('temperature', 0.5124707818031311)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1006000 episode:33852 last_R: 692.6722135543823 average_R:718.7182470655441
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.365301), ('average_q2', 18.452719), ('average_q_func1_loss', 3.171634913682938), ('average_q_func2_loss', 3.1642532885074615), ('n_updates', 995999), ('average_entropy', -0.98221886), ('temperature', 0.5080216526985168)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1007000 episode:33853 last_R: 743.9407296180725 average_R:718.8659127545357
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 17.653084), ('average_q2', 17.653927), ('average_q_func1_loss', 3.2306876373291016), ('average_q_func2_loss', 3.2177048861980437), ('n_updates', 996999), ('average_entropy', -1.0098993), ('temperature', 0.508072555065155)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1008000 episode:33855 last_R: 722.399739742279 average_R:718.6140184307098
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.286232), ('average_q2', 18.220926), ('average_q_func1_loss', 3.083158540725708), ('average_q_func2_loss', 3.0745507872104643), ('n_updates', 997999), ('average_entropy', -1.061201), ('temperature', 0.509720504283905)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1009000 episode:33856 last_R: 739.9595265388489 average_R:718.8919234585762
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.182137), ('average_q2', 18.207952), ('average_q_func1_loss', 3.152460547685623), ('average_q_func2_loss', 3.145928137302399), ('n_updates', 998999), ('average_entropy', -0.95880425), ('temperature', 0.5097014904022217)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1010000 episode:33856 last_R: 739.9595265388489 average_R:718.8919234585762
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.269293), ('average_q2', 18.195515), ('average_q_func1_loss', 3.1165174412727357), ('average_q_func2_loss', 3.105370934009552), ('n_updates', 999999), ('average_entropy', -0.97380745), ('temperature', 0.5112655162811279)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1011000 episode:33857 last_R: 735.4218099117279 average_R:719.1723913645744
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.197004), ('average_q2', 18.176981), ('average_q_func1_loss', 3.2173622834682463), ('average_q_func2_loss', 3.220363154411316), ('n_updates', 1000999), ('average_entropy', -0.98167133), ('temperature', 0.5191241502761841)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1012000 episode:33859 last_R: 722.4760220050812 average_R:719.2507465147972
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.512259), ('average_q2', 18.476686), ('average_q_func1_loss', 3.0477134442329405), ('average_q_func2_loss', 3.046961851119995), ('n_updates', 1001999), ('average_entropy', -1.036482), ('temperature', 0.5078380107879639)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1013000 episode:33860 last_R: 758.9557058811188 average_R:719.7558837676048
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.387785), ('average_q2', 18.44417), ('average_q_func1_loss', 3.056285047531128), ('average_q_func2_loss', 3.045559003353119), ('n_updates', 1002999), ('average_entropy', -1.045587), ('temperature', 0.5066884756088257)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1014000 episode:33860 last_R: 758.9557058811188 average_R:719.7558837676048
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.838356), ('average_q2', 18.814003), ('average_q_func1_loss', 3.1480751967430116), ('average_q_func2_loss', 3.1509208416938783), ('n_updates', 1003999), ('average_entropy', -1.0205694), ('temperature', 0.5059807300567627)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1015000 episode:33861 last_R: 767.9725589752197 average_R:719.9707068920136
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 19.161997), ('average_q2', 19.126877), ('average_q_func1_loss', 3.0739391040802), ('average_q_func2_loss', 3.071222630739212), ('n_updates', 1004999), ('average_entropy', -0.9604094), ('temperature', 0.5095203518867493)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1016000 episode:33863 last_R: 745.8738749027252 average_R:720.1071104192733
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.65016), ('average_q2', 18.710436), ('average_q_func1_loss', 3.089540113210678), ('average_q_func2_loss', 3.0945646500587465), ('n_updates', 1005999), ('average_entropy', -0.9843092), ('temperature', 0.5087002515792847)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1017000 episode:33864 last_R: 709.2715888023376 average_R:720.1560963821411
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.795263), ('average_q2', 18.925138), ('average_q_func1_loss', 3.0526216888427733), ('average_q_func2_loss', 3.0691086578369142), ('n_updates', 1006999), ('average_entropy', -1.0284902), ('temperature', 0.5069655179977417)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1018000 episode:33864 last_R: 709.2715888023376 average_R:720.1560963821411
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.292324), ('average_q2', 18.251814), ('average_q_func1_loss', 3.064916520118713), ('average_q_func2_loss', 3.073291358947754), ('n_updates', 1007999), ('average_entropy', -0.9235493), ('temperature', 0.5121825337409973)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1019000 episode:33865 last_R: 794.8149571418762 average_R:721.0646208906173
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.98582), ('average_q2', 18.935928), ('average_q_func1_loss', 3.0216125535964964), ('average_q_func2_loss', 3.017627273797989), ('n_updates', 1008999), ('average_entropy', -1.0104836), ('temperature', 0.5050188899040222)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1020000 episode:33867 last_R: 768.6135821342468 average_R:722.200525329113
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.685446), ('average_q2', 18.726318), ('average_q_func1_loss', 3.0981831765174865), ('average_q_func2_loss', 3.0921349704265593), ('n_updates', 1009999), ('average_entropy', -1.0405413), ('temperature', 0.5037460327148438)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1021000 episode:33868 last_R: 761.0269999504089 average_R:722.3473523902893
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 19.068834), ('average_q2', 19.073097), ('average_q_func1_loss', 3.137560330629349), ('average_q_func2_loss', 3.1390361857414244), ('n_updates', 1010999), ('average_entropy', -0.99722975), ('temperature', 0.5043032169342041)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1022000 episode:33868 last_R: 761.0269999504089 average_R:722.3473523902893
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.988401), ('average_q2', 18.895668), ('average_q_func1_loss', 3.098043129444122), ('average_q_func2_loss', 3.1065623366832735), ('n_updates', 1011999), ('average_entropy', -0.97471935), ('temperature', 0.49916931986808777)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1023000 episode:33869 last_R: 742.7820763587952 average_R:722.3731009984017
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 19.39811), ('average_q2', 19.396538), ('average_q_func1_loss', 2.829371362924576), ('average_q_func2_loss', 2.8326259219646452), ('n_updates', 1012999), ('average_entropy', -1.0450406), ('temperature', 0.4962266981601715)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1024000 episode:33871 last_R: 763.9737203121185 average_R:723.0570904445648
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.926504), ('average_q2', 18.975822), ('average_q_func1_loss', 2.966238386631012), ('average_q_func2_loss', 2.9639991796016694), ('n_updates', 1013999), ('average_entropy', -0.97435087), ('temperature', 0.49465063214302063)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1025000 episode:33872 last_R: 774.3250818252563 average_R:723.4481770467759
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.597054), ('average_q2', 18.62716), ('average_q_func1_loss', 2.990245704650879), ('average_q_func2_loss', 2.99531152009964), ('n_updates', 1014999), ('average_entropy', -0.9710872), ('temperature', 0.5016184449195862)]
INFO:pfrl.experiments.train_agent_batch:evaluation episode 0 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 1 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 2 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 3 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 4 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 5 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 6 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 7 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 8 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 9 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 10 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 11 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 12 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 13 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 14 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 15 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 16 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 17 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 18 length: 1000 R: 1000.0
INFO:pfrl.experiments.train_agent_batch:evaluation episode 19 length: 1000 R: 1000.0
INFO:diayn_sim:true z: tensor([ 2, 14, 13, 28], device='cuda:0')
INFO:diayn_sim:disc z: tensor([ 0, 14, 40, 22])
INFO:diayn_sim:disc loss: 2.4942548274993896
INFO:diayn_sim:top extrinsic: [1000. 1000. 1000. 1000.]
INFO:diayn_sim:last intrinsic: [1.4308438 1.4890466 1.4882236 1.262759 ]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1026000 episode:33872 last_R: 774.3250818252563 average_R:723.4481770467759
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 19.233109), ('average_q2', 19.275692), ('average_q_func1_loss', 2.905212160348892), ('average_q_func2_loss', 2.9037175297737123), ('n_updates', 1015999), ('average_entropy', -0.9909295), ('temperature', 0.5000918507575989)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1027000 episode:33873 last_R: 704.0473742485046 average_R:723.8745187807083
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 19.02147), ('average_q2', 18.990772), ('average_q_func1_loss', 2.9907730841636657), ('average_q_func2_loss', 2.996315883398056), ('n_updates', 1016999), ('average_entropy', -1.0677611), ('temperature', 0.5044214725494385)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1028000 episode:33875 last_R: 648.9026293754578 average_R:723.9377732563019
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 18.972443), ('average_q2', 18.993332), ('average_q_func1_loss', 2.941761130094528), ('average_q_func2_loss', 2.944833307266235), ('n_updates', 1017999), ('average_entropy', -0.9720208), ('temperature', 0.49948057532310486)]
INFO:pfrl.experiments.train_agent_batch:outdir:results/ce0204ef6a9ce4f1946e6e412fb4480cab8e5655-00000000-2194753a step:1029000 episode:33876 last_R: 673.6200711727142 average_R:723.9915568900109
INFO:pfrl.experiments.train_agent_batch:statistics: [('average_q1', 19.252718), ('average_q2', 19.288153), ('average_q_func1_loss', 2.8819705235958097), ('average_q_func2_loss', 2.8749758970737456), ('n_updates', 1018999), ('average_entropy', -0.92864376), ('temperature', 0.5071050524711609)]
